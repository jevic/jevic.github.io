<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="http://0.0.0.0/feed.xml" rel="self" type="application/atom+xml" /><link href="http://0.0.0.0/" rel="alternate" type="text/html" /><updated>2019-02-21T17:30:54+08:00</updated><id>http://0.0.0.0/</id><title type="html">Jevic</title><subtitle>......</subtitle><author><name>Jevic</name></author><entry><title type="html">JVM 内存监控</title><link href="http://0.0.0.0/2019/02/15/java-jvm/" rel="alternate" type="text/html" title="JVM 内存监控" /><published>2019-02-15T18:10:46+08:00</published><updated>2019-02-15T18:10:46+08:00</updated><id>http://0.0.0.0/2019/02/15/java-jvm</id><content type="html" xml:base="http://0.0.0.0/2019/02/15/java-jvm/">&lt;blockquote&gt;
  &lt;p&gt;系统内存并不能反应JVM内存情况，经常碰到JVM内存满掉而系统内存大量空余的情况,或者是由于没有对JVM内存进行有效的监控导致无法及时获取应用最新使用状态；&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;jstat&quot;&gt;jstat&lt;/h2&gt;
&lt;h3 id=&quot;gcutil&quot;&gt;gcutil&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;$JAVA_HOME/bin/jstat -gcutil VMID interval count&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;每隔1毫秒输出&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$JAVA_HOME&lt;/span&gt;/bin/jstat &lt;span class=&quot;nt&quot;&gt;-gcutil&lt;/span&gt; 3548 1    
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;每隔1秒输出,且统计五次&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$JAVA_HOME&lt;/span&gt;/bin/jstat &lt;span class=&quot;nt&quot;&gt;-gcutil&lt;/span&gt; 3548 1000 5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;➜  ~ &lt;span class=&quot;nv&quot;&gt;$JAVA_HOME&lt;/span&gt;/bin/jstat &lt;span class=&quot;nt&quot;&gt;-gcutil&lt;/span&gt; 3548
  S0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT
  0.00 100.00  34.69  78.45  96.39  91.25 881491 30503.989     9  350.987 30854.976
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;取heap-size-已使用量百分比值&quot;&gt;取heap size 已使用量百分比值&lt;/h4&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;➜  ~ &lt;span class=&quot;nv&quot;&gt;$JAVA_HOME&lt;/span&gt;/bin/jstat &lt;span class=&quot;nt&quot;&gt;-gcutil&lt;/span&gt; 3548|awk &lt;span class=&quot;s1&quot;&gt;'NR==2 {print $3}'&lt;/span&gt;
63.28
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;gccause&quot;&gt;gccause&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$JAVA_HOME/bin/jstat -gccause VMID interval count
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;gccapacity&quot;&gt;gccapacity&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$JAVA_HOME/bin/jstat -gccapacity VMID interval count
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;jconsole&quot;&gt;Jconsole&lt;/h2&gt;
&lt;h3 id=&quot;认证连接&quot;&gt;认证连接&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_OPTS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=21812 &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
-Dcom.sun.management.jmxremote.authenticate=true &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
-Dcom.sun.management.jmxremote.password.file=/etc/jmx/jmx-spark.password &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
-Dcom.sun.management.jmxremote.access.file=/etc/jmx/jmx-spark.access &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
-Dcom.sun.management.jmxremote.ssl=false&quot;&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;密码文件示例：
$JAVA_HOME/jre/lib/management&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;无认证连接&quot;&gt;无认证连接&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_OPTS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-Dcom.sun.management.jmxremote.port=8999 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.manageme
nt.jmxremote.ssl=false&quot;&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;客户端&quot;&gt;客户端&lt;/h3&gt;
&lt;p&gt;Mac &amp;amp; Windowns 安装配置jdk 后执行jsconsole 即可&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">系统内存并不能反应JVM内存情况，经常碰到JVM内存满掉而系统内存大量空余的情况,或者是由于没有对JVM内存进行有效的监控导致无法及时获取应用最新使用状态；</summary></entry><entry><title type="html">helm 私有仓库</title><link href="http://0.0.0.0/2019/01/10/helm-repo/" rel="alternate" type="text/html" title="helm 私有仓库" /><published>2019-01-10T20:35:46+08:00</published><updated>2019-01-10T20:35:46+08:00</updated><id>http://0.0.0.0/2019/01/10/helm-repo</id><content type="html" xml:base="http://0.0.0.0/2019/01/10/helm-repo/">&lt;blockquote&gt;
  &lt;p&gt;helm 私有本地仓库配置&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;关于helm 安装配置参考&lt;a href=&quot;https://www.jevic.cn/2018/10/13/helm/&quot;&gt;Kubernetes helm 包管理工具&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;开启服务&quot;&gt;开启服务&lt;/h4&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mkdir /opt/helm/charts
helm serve &lt;span class=&quot;nt&quot;&gt;--address&lt;/span&gt; helm.jevic.cn:8879 &lt;span class=&quot;nt&quot;&gt;--repo-path&lt;/span&gt; /opt/helm/charts &amp;amp;&amp;gt;/dev/null &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;添加仓库&quot;&gt;添加仓库:&lt;/h4&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;helm repo add jevic http://hub.jevic.cn:8879
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;查看仓库列表&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;helm repo list

NAME     	URL
&lt;span class=&quot;nb&quot;&gt;local    	&lt;/span&gt;http://127.0.0.1:8879
incubator	https://aliacs-app-catalog.oss-cn-hangzhou.aliyuncs.com/charts-incubator/
stable   	https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts
aliyun   	https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts-incubator/
jevic    	http://helm.jevic.cn:8879
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;应用上传&quot;&gt;应用上传&lt;/h4&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;c&quot;&gt;## 打包应用&lt;/span&gt;
cp &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; demoapp /opt/helm/charts
&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /opt/helm/charts
helm package demoapp &lt;span class=&quot;nt&quot;&gt;--save&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;## 更新索引&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /opt/helm/charts
helm repo index &lt;span class=&quot;nt&quot;&gt;--url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;http://helm.jevic.cn:8879 &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
helm repo update
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;部署&quot;&gt;部署&lt;/h4&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;## search&lt;/span&gt;
helm search demo

NAME         	CHART VERSION	APP VERSION	DESCRIPTION
jevic/demoapp	0.3.0        	1.0        	A Helm chart DemoApp &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;Kubernetes


&lt;span class=&quot;c&quot;&gt;## install&lt;/span&gt;
helm install &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; appv3 jevic/demoapp

&lt;span class=&quot;c&quot;&gt;## get pods&lt;/span&gt;
kubectl get pods |grep appv3

appv3-demoapp-79b7f754d5-zbkvd                   1/1     Running   0          91s

&lt;span class=&quot;c&quot;&gt;## list &lt;/span&gt;
helm &lt;span class=&quot;nb&quot;&gt;ls&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Jevic</name></author><summary type="html">helm 私有本地仓库配置</summary></entry><entry><title type="html">grafana html 请求显示docker镜像信息</title><link href="http://0.0.0.0/2018/11/27/grafana-text-html/" rel="alternate" type="text/html" title="grafana html 请求显示docker镜像信息" /><published>2018-11-27T19:56:06+08:00</published><updated>2018-11-27T19:56:06+08:00</updated><id>http://0.0.0.0/2018/11/27/grafana-text-html</id><content type="html" xml:base="http://0.0.0.0/2018/11/27/grafana-text-html/">&lt;blockquote&gt;
  &lt;p&gt;通过grafana 请求应用接口显示Docker镜像的构建版本信息..&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;图例&quot;&gt;图例&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/other/grafana-text-version01.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/other/grafana-text-version02.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;api&quot;&gt;api&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -sL http://192.168.2.146:9010/version |python -mjson.tool
{
    &quot;data&quot;: {
        &quot;buildtime&quot;: &quot;2018-11-27_17:25:43&quot;,
        &quot;hash&quot;: &quot;7cd3a541053a9d67eee1706d380af3fe&quot;,
        &quot;version&quot;: &quot;fa92b4d&quot;
    },
    &quot;ok&quot;: true
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;html-代码&quot;&gt;html 代码&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;div class=&quot;version&quot;&amp;gt;

&amp;lt;/div&amp;gt;

&amp;lt;style&amp;gt;
    .version ul{
        list-style:none;
        padding:0px;
        margin:0px;
        width:590px;
        height:20px;
        line-height:20px;
        font-size:12px;
    }
    .version ul li{
        display:block;
        width:33%;
        float:left;
        text-indent:2em
    }
    .version .th{
        background:&quot;gray&quot;;
        font-weight:bold;
        border-top:0px
    }
&amp;lt;/style&amp;gt;

&amp;lt;script&amp;gt;
    var hosts = [&quot;192.168.2.2&quot;,&quot;192.168.2.27&quot;,&quot;192.168.2.23&quot;,&quot;192.168.2.25&quot;];
    var port = 6010;

    function fetch(host,port) {
        $.ajax({
            type: &quot;GET&quot;,
            url: &quot;http://&quot;+host+&quot;:&quot;+port+&quot;/version&quot;,
            dataType: &quot;json&quot;,
            success: function(data){
                var id = &quot;seg-&quot;+host.replace(/\./g,&quot;&quot;)+port;
                $(&quot;#&quot;+id+&quot;&amp;gt;.version&quot;).text(data[&quot;data&quot;][&quot;version&quot;])
                $(&quot;#&quot;+id+&quot;&amp;gt;.buildtime&quot;).text(data[&quot;data&quot;][&quot;buildtime&quot;])
            }
        });
    }

    function renderFrame(hosts, port) {
        var header = &quot;&amp;lt;ul class=\&quot;th\&quot;&amp;gt;\n&quot; +
            &quot;        &amp;lt;li&amp;gt;Host&amp;lt;/li&amp;gt;\n&quot; +
            &quot;        &amp;lt;li&amp;gt;版本号&amp;lt;/li&amp;gt;\n&quot; +
            &quot;        &amp;lt;li&amp;gt;构建时间&amp;lt;/li&amp;gt;\n&quot; +
            &quot;    &amp;lt;/ul&amp;gt;&quot;;
        var template = &quot;&amp;lt;ul id=\&quot;\&quot;&amp;gt;\n&quot; +
            &quot;        &amp;lt;li&amp;gt;&amp;lt;/li&amp;gt;\n&quot; +
            &quot;        &amp;lt;li class=\&quot;version\&quot;&amp;gt;&amp;lt;/li&amp;gt;\n&quot; +
            &quot;        &amp;lt;li class=\&quot;buildtime\&quot;&amp;gt;&amp;lt;/li&amp;gt;\n&quot; +
            &quot;    &amp;lt;/ul&amp;gt;&quot;;

        var frame = header;
        for(var i = 0; i &amp;lt; hosts.length; i++){
            var host = hosts[i];
            var id = &quot;seg-&quot;+host.replace(/\./g,&quot;&quot;)+port;
            var item = template.replace(&quot;&quot;,id).replace(&quot;&quot;,host+&quot;:&quot;+port);
            frame += item
        }

        $(&quot;.version&quot;).append(frame);
    }

    $(document).ready(function () {
        renderFrame(hosts, port);

        for(var i = 0; i &amp;lt; hosts.length; i++){
            var host = hosts[i];
            window.setInterval(function (host) {
                fetch(host,port)
            },10000,host)
        }

    })
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Jevic</name></author><summary type="html">通过grafana 请求应用接口显示Docker镜像的构建版本信息..</summary></entry><entry><title type="html">Rancher Dashboard 管理kubernetes集群</title><link href="http://0.0.0.0/2018/11/25/rancher-dashboard-kubernetes/" rel="alternate" type="text/html" title="Rancher Dashboard 管理kubernetes集群" /><published>2018-11-25T20:35:46+08:00</published><updated>2018-11-25T20:35:46+08:00</updated><id>http://0.0.0.0/2018/11/25/rancher-dashboard-kubernetes</id><content type="html" xml:base="http://0.0.0.0/2018/11/25/rancher-dashboard-kubernetes/">&lt;blockquote&gt;
  &lt;p&gt;相比kubernetes Dashboard 
Rancher管理面板简化了很多相对比较&lt;code class=&quot;highlighter-rouge&quot;&gt;复杂&lt;/code&gt;的操作;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;导入kubernetes-集群&quot;&gt;导入kubernetes 集群&lt;/h2&gt;
&lt;p&gt;这里直接给出截图操作示例&lt;/p&gt;

&lt;p&gt;点击导入集群
配置集群名称,Roles 默认即可,然后点击 Create&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/kubernetes/rancher-kubernetes-cluster01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/kubernetes/rancher-kubernetes-cluster02.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;授权用户:
根据提示获取kubelet configuration file 中的用户名称&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# cat ~/.kube/config|grep user ## /etc/kubernetes/kubelet.kubeconfig
    user: default-auth
users:
  user:
  
# kubectl create clusterrolebinding cluster-admin-binding --clusterrole cluster-admin --user default-auth
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;部署rancher agent&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;需要注意的是,如果配置了SSL 认证,则最好使用第二条命令，否则可以使用第一条命令执行部署&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;此次使用第二条命令,以免出现证书不可用时忽略报错&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl --insecure -sfL https://192.168.2.218:8443/v3/import/wrmxhfxc7vcfznb9hssmqt9llx278ljqgfj49k5sxhtszrs68r6lmd.yaml | kubectl apply -f -
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;最后只需要等待agent 部署成功即可&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/kubernetes/rancher-kubernetes-cluster04.png&quot; alt=&quot;&quot; /&gt;
 &lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/kubernetes/rancher-kubernetes-cluster03.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">相比kubernetes Dashboard Rancher管理面板简化了很多相对比较复杂的操作;</summary></entry><entry><title type="html">Elastic Stack 6.4数据探索可视化 Demo</title><link href="http://0.0.0.0/2018/11/23/elastic-stack-6.4-demo/" rel="alternate" type="text/html" title="Elastic Stack 6.4数据探索可视化 Demo" /><published>2018-11-23T19:56:06+08:00</published><updated>2018-11-23T19:56:06+08:00</updated><id>http://0.0.0.0/2018/11/23/elastic-stack-6.4-demo</id><content type="html" xml:base="http://0.0.0.0/2018/11/23/elastic-stack-6.4-demo/">&lt;blockquote&gt;
  &lt;p&gt;基础安装配置请参考官网或者&lt;a href=&quot;https://www.jevic.cn/categories/#ELK&quot;&gt;ELK 分类&lt;/a&gt;下其他教程示例&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;nginx&quot;&gt;nginx&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;nginx.conf&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;指定日志格式如下:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;http {
    log_format  main  '$remote_addr - $remote_user [$time_local] &quot;$request&quot; '
                      '$status $body_bytes_sent &quot;$http_referer&quot; '
                      '&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;';

    log_format jsonTest '{&quot;@timestamp&quot;:&quot;$time_iso8601&quot;,'
                  '&quot;host&quot;:&quot;$server_addr&quot;,'
                  '&quot;service&quot;:&quot;nginxTest&quot;,'
                  '&quot;trace&quot;:&quot;$upstream_http_ctx_transaction_id&quot;,'
                  '&quot;log&quot;:&quot;log&quot;,'
                  '&quot;clientip&quot;:&quot;$remote_addr&quot;,'
                  '&quot;remote_user&quot;:&quot;$remote_user&quot;,'
                  '&quot;request&quot;:&quot;$request&quot;,'
                  '&quot;http_user_agent&quot;:&quot;$http_user_agent&quot;,'
                  '&quot;size&quot;:$body_bytes_sent,'
                  '&quot;responsetime&quot;:$request_time,'
                  '&quot;upstreamtime&quot;:&quot;$upstream_response_time&quot;,'
                  '&quot;upstreamhost&quot;:&quot;$upstream_addr&quot;,'
                  '&quot;http_host&quot;:&quot;$host&quot;,'
                  '&quot;url&quot;:&quot;$uri&quot;,'
                  '&quot;domain&quot;:&quot;$host&quot;,'
                  '&quot;xff&quot;:&quot;$http_x_forwarded_for&quot;,'
                  '&quot;referer&quot;:&quot;$http_referer&quot;,'
                  '&quot;status&quot;:&quot;$status&quot;}';

    access_log  /var/log/nginx/access.log  jsonTest;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;elasticsearch&quot;&gt;elasticsearch&lt;/h2&gt;
&lt;h3 id=&quot;模板配置&quot;&gt;模板配置&lt;/h3&gt;

&lt;h4 id=&quot;template01&quot;&gt;template01&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;没有配置mapping 不指定字段类型&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
  &quot;order&quot;: 0,
  &quot;index_patterns&quot;: [
    &quot;nginxlog-*&quot;
  ],
  &quot;settings&quot;: {
    &quot;index&quot;: {
      &quot;refresh_interval&quot;: &quot;60s&quot;,
      &quot;number_of_shards&quot;: &quot;1&quot;,
      &quot;auto_expand_replicas&quot;: &quot;0-1&quot;,
      &quot;number_of_replicas&quot;: &quot;1&quot;
    }
  },
  &quot;mappings&quot;: {},
  &quot;aliases&quot;: {}
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;template02&quot;&gt;template02&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;配置mapping 指定字段类型&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
  &quot;order&quot;: 0,
  &quot;index_patterns&quot;: [
    &quot;testnginxlog-*&quot;
  ],
  &quot;settings&quot;: {
    &quot;index&quot;: {
      &quot;number_of_shards&quot;: &quot;1&quot;,
      &quot;auto_expand_replicas&quot;: &quot;0-1&quot;,
      &quot;refresh_interval&quot;: &quot;60s&quot;
    }
  },
  &quot;mappings&quot;: {
    &quot;doc&quot;: {
    &quot;dynamic&quot;:true,
      &quot;properties&quot;: {
        &quot;clientip&quot;: {
          &quot;type&quot;: &quot;ip&quot;
        },
        &quot;host&quot;: {
          &quot;type&quot;: &quot;ip&quot;
        },
        &quot;responsetime&quot;: {
          &quot;type&quot;: &quot;float&quot;
        },
        &quot;size&quot;: {
          &quot;type&quot;: &quot;long&quot;
        },
        &quot;status&quot;: {
          &quot;type&quot;: &quot;long&quot;
        },
        &quot;upstreamtime&quot;: {
          &quot;type&quot;: &quot;float&quot;,
          &quot;index&quot;: false
        }
      }
    }
  },
  &quot;aliases&quot;: {}
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;通过dynamic 参数来控制字段的新增
    &lt;ul&gt;
      &lt;li&gt;true(默认) 允许自动新增字段&lt;/li&gt;
      &lt;li&gt;false 不允许新增字段,但文档可以正常写入,但无法对字段进行查询等操作&lt;/li&gt;
      &lt;li&gt;strict 文档不能写入,报错&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;index
    &lt;ul&gt;
      &lt;li&gt;控制当前字段是否索引,默认为true,记录索引,false不记录,不可搜索&lt;/li&gt;
      &lt;li&gt;当索引的某些字段不需要被查询搜索时可标记index 为false,以此来减少存储空间(没有倒排索引)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/elasticsearch/elasticsearch-template02.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;logstash&quot;&gt;logstash&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;示例中给出了两个索引名称,分别为:
    &lt;ul&gt;
      &lt;li&gt;nginxlog_*&lt;/li&gt;
      &lt;li&gt;testnginxlog-*&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;创建两个配置文件,修改对应的索引名称即可&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;input {
   file {
    type =&amp;gt; &quot;proxys&quot;
    path =&amp;gt; [&quot;/var/log/nginx/access.log&quot;]
    add_field =&amp;gt; { &quot;sip&quot; =&amp;gt; &quot;192.168.2.243&quot; }
    ## 是否从头读取数据这里注释掉只读取最新数据
#    start_position =&amp;gt; &quot;beginning&quot;
#    sincedb_path =&amp;gt; &quot;/dev/null&quot;
#    ignore_older =&amp;gt; &quot;99999999999&quot;
    codec =&amp;gt; &quot;json&quot;
  }
}

filter {
date {
        match =&amp;gt; [&quot;timestamp&quot;,&quot;UNIX&quot;]
        target =&amp;gt; &quot;@timestamp&quot;
 }
#mutate {
#        remove_field =&amp;gt; [&quot;path&quot;,&quot;host&quot;,&quot;tags&quot;,&quot;message&quot;]
#}
}

output{
        elasticsearch {
        hosts =&amp;gt; [&quot;http://192.168.2.221:9200&quot;]
        #index =&amp;gt; &quot;nginxlog_%{+YYYY.MM.dd}&quot;
        index =&amp;gt; &quot;testnginxlog-%{+YYYY.MM.dd}&quot;
    }
 #      stdout {
 #           codec =&amp;gt; rubydebug
 #      }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;启动进程&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$LOGSTAH_PATH/bin/logstash -f nginxlog.conf --log.level=info --path.data=/tmp/nginxlog

$LOGSTAH_PATH/bin/logstash -f testnginxlog.conf --log.level=info --path.data=/tmp/testnginxlog
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;查看索引mapping&quot;&gt;查看索引mapping&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;在 elasticsearch 2.x 版本，字符串数据只有string类型
更新到5.x版本后，取消了string 数据类型，代替它的是 keyword 和 text 数据类型&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Mapping 类似数据库中的表结构定义,主要作用如下:
    &lt;ul&gt;
      &lt;li&gt;定义index 下的字段名(Field Name)&lt;/li&gt;
      &lt;li&gt;定义字段的类型,比如: 数值型、字符串型、布尔型等&lt;/li&gt;
      &lt;li&gt;定义倒排索引相关配置,比如是否索引、记录position等&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;默认: “key”:”value” 格式的都默认为text类型
而对于”key”: value 格式的会根据数值类型进行格式匹配&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;例如:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
....
&quot;responsetime&quot;: 0.001, 
&quot;upstreamtime&quot;: &quot;0.001&quot;,
...
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;responsetime: 匹配为fload 类型&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;upstreamtime: 匹配为text类型,此时如果想要做聚合查询以及计算数值需要配置mapping 指定字段类型&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;text类型：会分词，先把对象进行分词处理，然后再再存入到es中。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当使用多个单词进行查询的时候，当然查不到已经分词过的内容！&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;keyword：不分词，没有把es中的对象进行分词处理，而是存入了整个对象！&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这时候当然可以进行完整地查询！默认是256个字符！&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;“ignore_above”: 256  详情查看&lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/6.5/ignore-above.html&quot;&gt;官网文档&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;nginxlog_&quot;&gt;nginxlog_*&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/elasticsearch/index-mapping01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;testnginxlog-&quot;&gt;testnginxlog-*&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/elasticsearch/index-mapping-02.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;kibana&quot;&gt;kibana&lt;/h2&gt;
&lt;h3 id=&quot;添加索引&quot;&gt;添加索引&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/elasticsearch/kibana-add-index01.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/elasticsearch/kibana-add-index02.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/elasticsearch/kibana-add-index03.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;监控图表&quot;&gt;监控图表&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/elasticsearch/kibana-monitoring.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;grafana&quot;&gt;grafana&lt;/h2&gt;

&lt;h3 id=&quot;runing-of-docker&quot;&gt;runing of docker&lt;/h3&gt;
&lt;p&gt;默认用户名密码: admin:admin&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker run -d \
--name grafana \
-p 3000:3000 \
-v /var/lib/grafana:/var/lib/grafana
-v /etc/grafana:/etc/grafana
-v /etc/localtime:/etc/localtime
grafana/grafana
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;数据源&quot;&gt;数据源&lt;/h3&gt;
&lt;p&gt;这里ES 版本选择5.6+即可&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/elasticsearch/grafana-datasource01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;demo&quot;&gt;demo&lt;/h3&gt;
&lt;p&gt;需要注意的是: 对于nginxlog_* 这个索引. Group by 时写入的是 clientip.keyword;
因为没有指定字段类型,如果直接写入 clientip 则会报错无法显示;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/elasticsearch/grafana-nginx-demo01.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/elasticsearch/grafana-nginx-demo02.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/elasticsearch/grafana-nginx-demo03.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;变量&quot;&gt;变量&lt;/h3&gt;

&lt;p&gt;配置完成后,点击add 添加即可&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/elasticsearch/grafana-variables01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/elasticsearch/grafana-var-nodeip.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;变量引用,和shell 变量调用方式一样使用 ${变量名}即可&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;clientip: $ip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;注意: 这里Group by 时状态码字段 直接指定为: status 即可
因为根据前面我们的配置,对testnginxlog-* 索引模板中指定了字段类型&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/elasticsearch/grafana-testnginxlog.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;图表展示:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/elasticsearch/grafana-demo-last.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">基础安装配置请参考官网或者ELK 分类下其他教程示例</summary></entry><entry><title type="html">elastic-stack 6.5</title><link href="http://0.0.0.0/2018/11/22/elastic-stack-6.5/" rel="alternate" type="text/html" title="elastic-stack 6.5" /><published>2018-11-22T19:56:06+08:00</published><updated>2018-11-22T19:56:06+08:00</updated><id>http://0.0.0.0/2018/11/22/elastic-stack-6.5</id><content type="html" xml:base="http://0.0.0.0/2018/11/22/elastic-stack-6.5/">&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;在以往的旧版本(2.x,5.x) 每个索引可以存储不同类型的文档,
      &lt;ul&gt;
        &lt;li&gt;类比MySQL
          &lt;ul&gt;
            &lt;li&gt;index == database&lt;/li&gt;
            &lt;li&gt;_type == table&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;6.x 版本开始 移除了_type  也就是每个索引只有一种类型！！！&lt;/li&gt;
    &lt;li&gt;x-pack 从6.3版本开始已经内置在elasticsearch,kibana 当中无需另行安装!&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;elasticsearch&quot;&gt;elasticsearch&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.elastic.co/downloads&quot;&gt;官网下载&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;下载解压&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;配置基础环境&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# cat /etc/security/limit.conf
* soft nofile 65536
* hard nofile 65536
* soft nproc unlimited
* hard nproc unlimited
es soft memlock unlimited
es hard memlock unlimited
  
# cat /etc/sysctl.conf
vm.swappiness = 1
vm.max_map_count=262144
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;添加 es 用户并授权&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;启动&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;授权 license （30天试用版）&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;证书申请: https://register.elastic.co/marvel_register&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -H &quot;Content-Type:application/json&quot; -XPOST  http://192.168.2.221:9200/_xpack/license/start_trial?acknowledge=true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;x-pack-开启认证&quot;&gt;x-pack 开启认证&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;配置用户名密码:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;$ES_PATH:/bin/elasticsearch-setup-passwords interactive&lt;/li&gt;
      &lt;li&gt;根据提示一步步设置密码即可&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改 elasticsearch 配置文件&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# tail elasticsearch.yml -n 1
xpack.security.enabled: true  ## 开启认证
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;重启ES，再次访问则需要输入用户名密码&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改密码&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -H &quot;Content-Type:application/json&quot; -XPOST -u elastic 'http://192.168.2.221:9200/_xpack/security/user/elastic/_password' -d '{ &quot;password&quot; : &quot;123456&quot; }'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;kibana&quot;&gt;kibana&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;配置对应的用户名密码以及 ES 链接地址&lt;/li&gt;
  &lt;li&gt;配置文件添加此配置:
    &lt;ul&gt;
      &lt;li&gt;xpack.security.enabled: true&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;启动即可&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;cerebro&quot;&gt;cerebro&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/lmenezes/cerebro&quot;&gt;github&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;具体步骤查看文档即可&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sql-插件&quot;&gt;sql 插件&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/NLPchina/elasticsearch-sql&quot;&gt;github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;转载请注明出处，本文采用 &lt;a href=&quot;http://creativecommons.org/licenses/by-nc-nd/4.0/&quot;&gt;CC4.0&lt;/a&gt; 协议授权&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">在以往的旧版本(2.x,5.x) 每个索引可以存储不同类型的文档, 类比MySQL index == database _type == table 6.x 版本开始 移除了_type 也就是每个索引只有一种类型！！！ x-pack 从6.3版本开始已经内置在elasticsearch,kibana 当中无需另行安装!</summary></entry><entry><title type="html">kubernetes nginx-ingress and traefik</title><link href="http://0.0.0.0/2018/10/25/ingresss-traefik/" rel="alternate" type="text/html" title="kubernetes nginx-ingress and traefik" /><published>2018-10-25T22:35:46+08:00</published><updated>2018-10-25T22:35:46+08:00</updated><id>http://0.0.0.0/2018/10/25/ingresss-traefik</id><content type="html" xml:base="http://0.0.0.0/2018/10/25/ingresss-traefik/">&lt;p&gt;在Kubernetes中，服务和Pod的IP地址仅可以在集群网络内部使用，对于集群外的应用是不可见的。为了使外部的应用能够访问集群内的服务，在Kubernetes中可以通过NodePort和LoadBalancer这两种类型的服务，或者使用Ingress。Ingress本质是通过http代理服务器将外部的http请求转发到集群内部的后端服务。&lt;/p&gt;

&lt;h2 id=&quot;一-证书可选配置&quot;&gt;一. 证书(可选配置)&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;使用已购买的证书&lt;/li&gt;
  &lt;li&gt;配置自签名证书&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# openssl genrsa -out jevic_key.pem 4096
Generating RSA private key, 4096 bit long modulus
.....................++
.....++
e is 65537 (0x10001)
[root@master219 ssl]# openssl req -new -x509 -key jevic_key.pem -out root.crt -days 3650
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter '.', the field will be left blank.
-----
Country Name (2 letter code) [XX]:GD
State or Province Name (full name) []:GD
Locality Name (eg, city) [Default City]:SZ
Organization Name (eg, company) [Default Company Ltd]:jevic
Organizational Unit Name (eg, section) []:jevic
Common Name (eg, your name or your server's hostname) []:jevic.cn
Email Address []:admin@jevic.cn
[root@master219 ssl]# ls
jevic_key.pem  root.crt

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;二-nginx-ingress&quot;&gt;二. nginx-ingress&lt;/h2&gt;
&lt;h3 id=&quot;21-部署&quot;&gt;2.1 部署&lt;/h3&gt;
&lt;p&gt;如果kubernetes 集群启用了RBAC，则一定要加rbac.create=true参数
helm 安装请参考&lt;a href=&quot;https://www.jevic.cn/2018/10/13/helm/&quot;&gt;Kubernetes helm 包管理工具&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;helm install stable/nginx-ingress --set controller.hostNetwork=true，rbac.create=true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;查看状态:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# helm list
NAME            	REVISION	UPDATED                 	STATUS  	CHART              	APP VERSION	NAMESPACE
quiet-abalone   	1       	Thu Nov 29 19:55:28 2018	DEPLOYED	nginx-ingress-0.9.5	0.10.2     	default

# kubectl get all --all-namespaces -l app=nginx-ingress
NAMESPACE   NAME                                                               READY     STATUS    RESTARTS   AGE
default     pod/quiet-abalone-nginx-ingress-controller-7b8b745f96-gczjl        1/1       Running   1          5d
default     pod/quiet-abalone-nginx-ingress-default-backend-54f4fb569c-ndh4x   1/1       Running   1          5d

NAMESPACE   NAME                                                  TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE
default     service/quiet-abalone-nginx-ingress-controller        LoadBalancer   10.254.235.53   &amp;lt;pending&amp;gt;     80:45608/TCP,443:40984/TCP   5d
default     service/quiet-abalone-nginx-ingress-default-backend   ClusterIP      10.254.20.221   &amp;lt;none&amp;gt;        80/TCP                       5d

NAMESPACE   NAME                                                          DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
default     deployment.apps/quiet-abalone-nginx-ingress-controller        1         1         1            1           5d
default     deployment.apps/quiet-abalone-nginx-ingress-default-backend   1         1         1            1           5d

NAMESPACE   NAME                                                                     DESIRED   CURRENT   READY     AGE
default     replicaset.apps/quiet-abalone-nginx-ingress-controller-7b8b745f96        1         1         1         5d
default     replicaset.apps/quiet-abalone-nginx-ingress-default-backend-54f4fb569c   1         1         1         5d
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;22-nginx-负载均衡测试&quot;&gt;2.2 nginx 负载均衡测试&lt;/h3&gt;

&lt;h4 id=&quot;221-nginx-demoyaml&quot;&gt;2.2.1 nginx-demo.yaml&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
  name: nginx-demo
  labels:
    app: my-nginx
spec:
  type: NodePort
  ports:
  - port: 80
    protocol: TCP
    name: http
  selector:
    app: my-nginx
---
apiVersion: v1
kind: ReplicationController
metadata:
  name: my-nginx
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: my-nginx
    spec:
      containers:
      - image: nginx/nginx:1.7.9
        name: nginx-demo
        ports:
        - containerPort: 80
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;222-ingress-nginx-demoyaml&quot;&gt;2.2.2 ingress-nginx-demo.yaml&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: nginx-ingress-demo
  namespace: default
#  annotations:
#    kubernetes.io/ingress.class: &quot;public&quot;
#    ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: test.nginx.com
    http:
      paths:
      - backend:
          serviceName: nginx-demo
          servicePort: 80
        path: /
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;三-traefik&quot;&gt;三. traefik&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/containous/traefik/tree/master/examples/k8s&quot;&gt;官网 yaml文档&lt;/a&gt;
&lt;a href=&quot;https://docs.traefik.io/user-guide/kubernetes/&quot;&gt;docs.traefik.io&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;31-traefik-insecureyaml&quot;&gt;3.1 traefik-insecure.yaml&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;只开启了http 请求访问&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: traefik-ingress-controller
rules:
  - apiGroups:
      - &quot;&quot;
    resources:
      - services
      - endpoints
      - secrets
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - extensions
    resources:
      - ingresses
    verbs:
      - get
      - list
      - watch
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: traefik-ingress-controller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: traefik-ingress-controller
subjects:
- kind: ServiceAccount
  name: traefik-ingress-controller
  namespace: kube-system
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: traefik-ingress-controller
  namespace: kube-system
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: traefik-conf
  namespace: kube-system
data:
  traefik.toml: |
    insecureSkipVerify = true
    defaultEntryPoints = [&quot;http&quot;]
    [entryPoints]
      [entryPoints.http]
      address = &quot;:80&quot;
---
kind: DaemonSet
apiVersion: extensions/v1beta1
metadata:
  name: traefik-ingress-controller
  namespace: kube-system
  labels:
    k8s-app: traefik-ingress-lb
spec:
  template:
    metadata:
      labels:
        k8s-app: traefik-ingress-lb
        name: traefik-ingress-lb
    spec:
      serviceAccountName: traefik-ingress-controller
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      terminationGracePeriodSeconds: 60
      hostNetwork: true
      volumes:
      - name: config
        configMap:
          name: traefik-conf
      containers:
      - image: k8s.jevic.cn/kubernetes/traefik:1.7.3
        name: traefik-ingress-lb
        ports:
        - name: http
          containerPort: 80
          hostPort: 80
        - name: admin
          containerPort: 8080
        securityContext:
          privileged: true
        args:
        - --configfile=/config/traefik.toml
        - -d
        - --web
        - --kubernetes
        - --web.address=0.0.0.0:8081
        volumeMounts:
        - mountPath: &quot;/config&quot;
          name: &quot;config&quot;
---
kind: Service
apiVersion: v1
metadata:
  name: traefik-ingress-service
spec:
  selector:
    k8s-app: traefik-ingress-lb
  ports:
    - protocol: TCP
      port: 80
      name: web
    - protocol: TCP
      port: 8080
      name: admin
    - protocol: TCP
      port: 443
      name: https
  type: NodePort
apiVersion: v1
kind: Service
metadata:
  name: traefik-web-ui
  namespace: kube-system
spec:
  selector:
    k8s-app: traefik-ingress-lb
  ports:
  - port: 80
    targetPort: 8080
---
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: traefik-web-ui
  namespace: kube-system
  annotations:
    kubernetes.io/ingress.class: traefik
spec:
  rules:
  - host: ingress.jevic.cn
    http:
      paths:
      - backend:
          serviceName: traefik-web-ui
          servicePort: 80
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create -f traefik-insecure.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;然后等待服务正常启动即可&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# kubectl get pod -n kube-system -l k8s-app=traefik-ingress-lb
NAME                               READY     STATUS    RESTARTS   AGE
traefik-ingress-controller-mv8cg   1/1       Running   0          4d
traefik-ingress-controller-vvfc7   1/1       Running   0          4d
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;32-traefik-httpsyaml&quot;&gt;3.2 traefik-https.yaml&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;开启http 和 https 访问&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;321-创建-secret&quot;&gt;3.2.1 创建 secret&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;这里使用购买的证书,也可以使用自签名证书测试；&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create secret tls ssl --cert=jevic.cert --key=jevic.key -n kube-system
kubectl get secret -n kube-system
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;这里注意namespace 一定要配置为kube-system&lt;/p&gt;

&lt;h4 id=&quot;322-traefik-httpsyaml&quot;&gt;3.2.2 traefik-https.yaml&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: traefik-ingress-controller
rules:
  - apiGroups:
      - &quot;&quot;
    resources:
      - services
      - endpoints
      - secrets
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - extensions
    resources:
      - ingresses
    verbs:
      - get
      - list
      - watch
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: traefik-ingress-controller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: traefik-ingress-controller
subjects:
- kind: ServiceAccount
  name: traefik-ingress-controller
  namespace: kube-system
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: traefik-ingress-controller
  namespace: kube-system
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: traefik-conf
  namespace: kube-system
data:
  traefik.toml: |
    insecureSkipVerify = true
    defaultEntryPoints = [&quot;http&quot;,&quot;https&quot;]
    [entryPoints]
      [entryPoints.http]
      address = &quot;:80&quot;
      [entryPoints.https]
      address = &quot;:443&quot;
        [entryPoints.https.tls]
          [[entryPoints.https.tls.certificates]]
          CertFile = &quot;/ssl/tls.crt&quot;
          KeyFile = &quot;/ssl/tls.key&quot;
---
kind: DaemonSet
apiVersion: extensions/v1beta1
metadata:
  name: traefik-ingress-controller
  namespace: kube-system
  labels:
    k8s-app: traefik-ingress-lb
spec:
  template:
    metadata:
      labels:
        k8s-app: traefik-ingress-lb
        name: traefik-ingress-lb
    spec:
      serviceAccountName: traefik-ingress-controller
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      terminationGracePeriodSeconds: 60
      hostNetwork: true
      volumes:
      - name: ssl
        secret:
          secretName: ssl
      - name: config
        configMap:
          name: traefik-conf
      containers:
      - image: k8s.jevic.cn/kubernetes/traefik:latest
        name: traefik-ingress-lb
        ports:
        - name: http
          containerPort: 80
          hostPort: 80
        - name: admin
          containerPort: 8081
        securityContext:
          privileged: true
        args:
        - --configfile=/config/traefik.toml
        - -d
        - --web
        - --kubernetes
        - --web.address=0.0.0.0:8081
        volumeMounts:
        - mountPath: &quot;/ssl&quot;
          name: &quot;ssl&quot;
        - mountPath: &quot;/config&quot;
          name: &quot;config&quot;
---
kind: Service
apiVersion: v1
metadata:
  name: traefik-ingress-service
spec:
  selector:
    k8s-app: traefik-ingress-lb
  ports:
    - protocol: TCP
      port: 80
      name: web
    - protocol: TCP
      port: 8081
      name: admin
    - protocol: TCP
      port: 443
      name: https
  type: NodePort
apiVersion: v1
kind: Service
metadata:
  name: traefik-web-ui
  namespace: kube-system
spec:
  selector:
    k8s-app: traefik-ingress-lb
  ports:
  - port: 80
    targetPort: 8081
---
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: traefik-web-ui
  namespace: kube-system
  annotations:
    kubernetes.io/ingress.class: traefik
spec:
  rules:
  - host: ingress.jevic.cn
    http:
      paths:
      - backend:
          serviceName: traefik-web-ui
          servicePort: 80
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;默认端口: 8080 这里手动指定了web-ui端口为:8081&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- --web.address=0.0.0.0:8081
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;33-目录结构&quot;&gt;3.3 目录结构&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;├── jevic.cert
├── jevic.key
├── nginx-demo
│   ├── ingress-nginx-traefik.yaml
│   └── nginx-demo.yaml
├── traefik-https.yaml
└── traefik-insecure.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;34-traefik-nginx-demo&quot;&gt;3.4 traefik nginx-demo&lt;/h3&gt;

&lt;h4 id=&quot;nginx-deployment-demoyaml&quot;&gt;nginx-deployment-demo.yaml&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-demo
  labels:
    nginx: nginx-demo
spec:
  replicas: 2
  selector:
    matchLabels:
      nginx: nginx-demo
  template:
    metadata:
      labels:
        nginx: nginx-demo
    spec:
      containers:
      - name: nginx-demo
        image: nginx/nginx:1.7.9
        ports:
        - name: https
          containerPort: 443
        - name: http
          containerPort: 80
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;nginx-svc-demoyaml&quot;&gt;nginx-svc-demo.yaml&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
  name: nginx-demo
  labels:
    nginx: nginx-demo
spec:
  ports:
  - port: 80
    protocol: TCP
    targetPort: 80
    name: http
  - port: 443
    protocol: TCP
    targetPort: 443
    name: https
  selector:
    nginx: nginx-demo
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;ingress-nginx-traefikyaml&quot;&gt;ingress-nginx-traefik.yaml&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: nginx-ingress-demo
  namespace: default
  annotations:
    kubernetes.io/ingress.class: traefik
spec:
  rules:
  - host: nginx.jevic.cn
    http:
      paths:
      - backend:
          serviceName: nginx-demo
          servicePort: 80
        path: /
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;部署&quot;&gt;部署&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# ls
ingress-nginx-traefik.yaml  nginx-deployment-demo.yaml  nginx-rc-demo.yaml  nginx-svc-demo.yaml
# kubectl apply -f nginx-deployment-demo.yaml
deployment.apps &quot;nginx-demo&quot; created
# kubectl create -f nginx-svc-demo.yaml
service &quot;nginx-demo&quot; created
# kubectl create -f ingress-nginx-traefik.yaml
ingress.extensions &quot;nginx-ingress-demo&quot; created
# kubectl get all -l nginx=nginx-demo
NAMESPACE   NAME                            READY     STATUS    RESTARTS   AGE
default     pod/nginx-demo-c8765675-phr2w   1/1       Running   0          1m
default     pod/nginx-demo-c8765675-z7tgn   1/1       Running   0          1m

NAMESPACE   NAME                         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
default     deployment.apps/nginx-demo   2         2         2            2           1m

NAMESPACE   NAME                                  DESIRED   CURRENT   READY     AGE
default     replicaset.apps/nginx-demo-c8765675   2         2         2         1m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/kubernetes/kubernetes-ingress-traefik01.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/kubernetes/kubernetes-ingress-traefik02.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">在Kubernetes中，服务和Pod的IP地址仅可以在集群网络内部使用，对于集群外的应用是不可见的。为了使外部的应用能够访问集群内的服务，在Kubernetes中可以通过NodePort和LoadBalancer这两种类型的服务，或者使用Ingress。Ingress本质是通过http代理服务器将外部的http请求转发到集群内部的后端服务。</summary></entry><entry><title type="html">Kubernetes helm 包管理工具</title><link href="http://0.0.0.0/2018/10/13/helm/" rel="alternate" type="text/html" title="Kubernetes helm 包管理工具" /><published>2018-10-13T20:35:46+08:00</published><updated>2018-10-13T20:35:46+08:00</updated><id>http://0.0.0.0/2018/10/13/helm</id><content type="html" xml:base="http://0.0.0.0/2018/10/13/helm/">&lt;blockquote&gt;
  &lt;p&gt;helm 简介
很多人都使用过Ubuntu下的ap-get或者CentOS下的yum, 这两者都是Linux系统下的包管理工具。采用apt-get/yum,应用开发者可以管理应用包之间的依赖关系，发布应用；用户则可以以简单的方式查找、安装、升级、卸载应用程序。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我们可以将Helm看作Kubernetes下的apt-get/yum。Helm是Deis (https://deis.com/) 开发的一个用于kubernetes的包管理器。每个包称为一个Chart，一个Chart是一个目录（一般情况下会将目录进行打包压缩，形成name-version.tgz格式的单一文件，方便传输和存储）。&lt;/p&gt;

&lt;p&gt;对于应用发布者而言，可以通过Helm打包应用，管理应用依赖关系，管理应用版本并发布应用到软件仓库。&lt;/p&gt;

&lt;p&gt;对于使用者而言，使用Helm后不用需要了解Kubernetes的Yaml语法并编写应用部署文件，可以通过Helm下载并在kubernetes上安装需要的应用。&lt;/p&gt;

&lt;p&gt;除此以外，Helm还提供了kubernetes上的软件部署，删除，升级，回滚应用的强大功能。&lt;/p&gt;

&lt;h2 id=&quot;helm-组件及相关术语&quot;&gt;Helm 组件及相关术语&lt;/h2&gt;
&lt;h3 id=&quot;helm&quot;&gt;Helm&lt;/h3&gt;
&lt;p&gt;Helm 是一个命令行下的客户端工具。主要用于 Kubernetes 应用程序 Chart 的创建、打包、发布以及创建和管理本地和远程的 Chart 仓库。&lt;/p&gt;

&lt;h3 id=&quot;tiller&quot;&gt;Tiller&lt;/h3&gt;
&lt;p&gt;Tiller 是 Helm 的服务端，部署在 Kubernetes 集群中。Tiller 用于接收 Helm 的请求，并根据 Chart 生成 Kubernetes 的部署文件（ Helm 称为 Release ），然后提交给 Kubernetes 创建应用。Tiller 还提供了 Release 的升级、删除、回滚等一系列功能。&lt;/p&gt;

&lt;h3 id=&quot;chart&quot;&gt;Chart&lt;/h3&gt;
&lt;p&gt;Helm 的软件包，采用 TAR 格式。类似于 APT 的 DEB 包或者 YUM 的 RPM 包，其包含了一组定义 Kubernetes 资源相关的 YAML 文件。&lt;/p&gt;

&lt;h3 id=&quot;repoistory&quot;&gt;Repoistory&lt;/h3&gt;
&lt;p&gt;Helm 的软件仓库，Repository 本质上是一个 Web 服务器，该服务器保存了一系列的 Chart 软件包以供用户下载，并且提供了一个该 Repository 的 Chart 包的清单文件以供查询。Helm 可以同时管理多个不同的 Repository。&lt;/p&gt;

&lt;h3 id=&quot;release&quot;&gt;Release&lt;/h3&gt;
&lt;p&gt;使用 helm install 命令在 Kubernetes 集群中部署的 Chart 称为 Release。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;注：需要注意的是：Helm 中提到的 Release 和我们通常概念中的版本有所不同，这里的 Release 可以理解为 Helm 使用 Chart 包部署的一个应用实例。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;helm工作原理&quot;&gt;Helm工作原理&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://www.kubernetes.org.cn/img/2018/05/20180111160842.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;chart-install-过程&quot;&gt;Chart Install 过程：&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;Helm从指定的目录或者tgz文件中解析出Chart结构信息&lt;/li&gt;
  &lt;li&gt;Helm将指定的Chart结构和Values信息通过gRPC传递给Tiller&lt;/li&gt;
  &lt;li&gt;Tiller根据Chart和Values生成一个Release&lt;/li&gt;
  &lt;li&gt;Tiller将Release发送给Kubernetes用于生成Release&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;chart-update过程&quot;&gt;Chart Update过程：&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;Helm从指定的目录或者tgz文件中解析出Chart结构信息&lt;/li&gt;
  &lt;li&gt;Helm将要更新的Release的名称和Chart结构，Values信息传递给Tiller&lt;/li&gt;
  &lt;li&gt;Tiller生成Release并更新指定名称的Release的History&lt;/li&gt;
  &lt;li&gt;Tiller将Release发送给Kubernetes用于更新Release&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;chart-rollback过程&quot;&gt;Chart Rollback过程：&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;Helm将要回滚的Release的名称传递给Tiller&lt;/li&gt;
  &lt;li&gt;Tiller根据Release的名称查找History&lt;/li&gt;
  &lt;li&gt;Tiller从History中获取上一个Release&lt;/li&gt;
  &lt;li&gt;Tiller将上一个Release发送给Kubernetes用于替换当前Release&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;helm部署&quot;&gt;helm部署&lt;/h2&gt;

&lt;h3 id=&quot;一-helm-客户端安装&quot;&gt;一. Helm 客户端安装&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.helm.sh/using_helm/#installing-helm&quot;&gt;官方文档&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;11-脚本一键安装&quot;&gt;1.1 脚本一键安装&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl https://raw.githubusercontent.com/helm/helm/master/scripts/get &amp;gt; get_helm.sh
chmod 700 get_helm.sh
./get_helm.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;12-手动安装&quot;&gt;1.2 手动安装&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tar -zxf helm-v2.11.0-linux-amd64.tar.gz
mv linux-amd64/helm /usr/local/bin/helm
helm help # 验证
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;二-helm-服务端安装tiller&quot;&gt;二. Helm 服务端安装Tiller&lt;/h3&gt;
&lt;h4 id=&quot;21-socat&quot;&gt;2.1 socat&lt;/h4&gt;
&lt;blockquote&gt;
  &lt;p&gt;注意：先在 K8S 集群上每个节点安装 socat 软件&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yum install -y socat
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;22-证书配置&quot;&gt;2.2 证书配置&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.helm.sh/using_helm/#using-ssl-between-helm-and-tiller&quot;&gt;官方文档&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;根据官网文档给出的示例步骤创建证书文件&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# tree /opt/helm/ssl/
/opt/helm/ssl/
├── ca.cert.pem
├── ca.key.pem
├── ca.srl
├── get.sh
├── helm.cert.pem
├── helm.csr.pem
├── helm.key.pem
├── r.sh
├── tiller.cert.pem
├── tiller.csr.pem
└── tiller.key.pem

0 directories, 11 files
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;23-初始化&quot;&gt;2.3 初始化&lt;/h4&gt;
&lt;blockquote&gt;
  &lt;p&gt;Tiller 是以 Deployment 方式部署在 Kubernetes 集群中的；&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;由于 Helm 默认会去 storage.googleapis.com 拉取镜像，如果你当前执行的机器不能访问该域名的话可以使用以下命令来安装：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;helm init --client-only --stable-repo-url https://aliacs-app-catalog.oss-cn-hangzhou.aliyuncs.com/charts/
helm repo add incubator https://aliacs-app-catalog.oss-cn-hangzhou.aliyuncs.com/charts-incubator/
helm repo update
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;231-服务端&quot;&gt;2.3.1 服务端&lt;/h5&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;helm init --service-account tiller --upgrade -i registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.11.0  --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;232-tsl-认证服务端&quot;&gt;2.3.2 TSL 认证服务端&lt;/h5&gt;
&lt;blockquote&gt;
  &lt;p&gt;这里使用TSL 认证服务端配置 helm&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;helm init --service-account tiller --upgrade -i registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.11.0 --tiller-tls --tiller-tls-cert /opt/helm/ssl/tiller.cert.pem --tiller-tls-key /opt/helm/ssl/tiller.key.pem --tiller-tls-verify --tls-ca-cert /opt/helm/ssl/ca.cert.pem --tiller-namespace kube-system --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;-i 指定镜像名称,使用阿里云的.默认google镜像无法访问
镜像版本必须与客户端版本一致&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;三-tiller-授权&quot;&gt;三. Tiller 授权&lt;/h3&gt;
&lt;p&gt;Helm 的服务端 Tiller 是一个部署在 Kubernetes 中 Kube-System Namespace 下 的 Deployment，它会去连接 Kube-Api 在 Kubernetes 里创建和删除应用。&lt;/p&gt;

&lt;p&gt;而从 Kubernetes 1.6 版本开始，API Server 启用了 RBAC 授权。目前的 Tiller 部署时默认没有定义授权的 ServiceAccount，这会导致访问 API Server 时被拒绝。所以我们需要明确为 Tiller 部署添加授权。&lt;/p&gt;

&lt;h4 id=&quot;31-创建-kubernetes-的服务帐号和绑定角色&quot;&gt;3.1 创建 Kubernetes 的服务帐号和绑定角色&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create serviceaccount --namespace kube-system tiller
kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;32-为-tiller-设置帐号&quot;&gt;3.2 为 Tiller 设置帐号&lt;/h4&gt;
&lt;blockquote&gt;
  &lt;p&gt;使用 kubectl patch 更新 API 对象&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl patch deploy --namespace kube-system tiller-deploy -p '{&quot;spec&quot;:{&quot;template&quot;:{&quot;spec&quot;:{&quot;serviceAccount&quot;:&quot;tiller&quot;}}}}'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;33-查看是否授权成功&quot;&gt;3.3 查看是否授权成功&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@master219 ~]# kubectl get deploy --namespace kube-system   tiller-deploy  --output yaml|grep  serviceAccount
      serviceAccount: tiller
      serviceAccountName: tiller
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;34-验证-tiller&quot;&gt;3.4 验证 Tiller&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# kubectl -n kube-system get pods|grep tiller
tiller-deploy-69545986bb-gwlfh             1/1       Running   1          3d


# helm version
Client: &amp;amp;version.Version{SemVer:&quot;v2.11.0&quot;, GitCommit:&quot;2e55dbe1fdb5fdb96b75ff144a339489417b146b&quot;, GitTreeState:&quot;clean&quot;}
Server: &amp;amp;version.Version{SemVer:&quot;v2.11.0&quot;, GitCommit:&quot;2e55dbe1fdb5fdb96b75ff144a339489417b146b&quot;, GitTreeState:&quot;clean&quot;}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;卸载&quot;&gt;卸载&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;helm reset
helm reset --force
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;helm-使用&quot;&gt;helm 使用&lt;/h2&gt;
&lt;h3 id=&quot;仓库配置&quot;&gt;仓库配置&lt;/h3&gt;
&lt;p&gt;使用阿里云仓库&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;helm repo remove stable
helm repo add stable https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts
helm update

# helm repo list
NAME     	URL
stable   	https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts
local    	http://127.0.0.1:8879/charts
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Jevic</name></author><summary type="html">helm 简介 很多人都使用过Ubuntu下的ap-get或者CentOS下的yum, 这两者都是Linux系统下的包管理工具。采用apt-get/yum,应用开发者可以管理应用包之间的依赖关系，发布应用；用户则可以以简单的方式查找、安装、升级、卸载应用程序。</summary></entry><entry><title type="html">二进制手动部署kubernetes 1.10.10</title><link href="http://0.0.0.0/2018/09/23/kuberentes-1.10.10/" rel="alternate" type="text/html" title="二进制手动部署kubernetes 1.10.10" /><published>2018-09-23T20:35:46+08:00</published><updated>2018-09-23T20:35:46+08:00</updated><id>http://0.0.0.0/2018/09/23/kuberentes-1.10.10</id><content type="html" xml:base="http://0.0.0.0/2018/09/23/kuberentes-1.10.10/">&lt;blockquote&gt;
  &lt;p&gt;通读一遍先熟悉了过程在实际操作!!!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;通读一遍先熟悉了过程在实际操作!!!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;通读一遍先熟悉了过程在实际操作!!!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;关于镜像请查看最后的补充说明&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;部署脚本查看&lt;a href=&quot;https://github.com/jevic/kshell.git&quot;&gt;仓库脚本&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;一-系统环境&quot;&gt;一. 系统环境&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;CentOS Linux release 7.2.1511 (Core)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;IP地址&lt;/th&gt;
      &lt;th&gt;主机名&lt;/th&gt;
      &lt;th&gt;Docker 版本&lt;/th&gt;
      &lt;th&gt;kubernetes 版本&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;192.168.2.219&lt;/td&gt;
      &lt;td&gt;master219&lt;/td&gt;
      &lt;td&gt;18.06.0-ce&lt;/td&gt;
      &lt;td&gt;v1.10.10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;192.168.2.220&lt;/td&gt;
      &lt;td&gt;node220&lt;/td&gt;
      &lt;td&gt;18.06.0-ce&lt;/td&gt;
      &lt;td&gt;v1.10.10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;192.168.2.221&lt;/td&gt;
      &lt;td&gt;node221&lt;/td&gt;
      &lt;td&gt;18.06.0-ce&lt;/td&gt;
      &lt;td&gt;v1.10.10&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;初始化&quot;&gt;初始化&lt;/h3&gt;
&lt;h4 id=&quot;11-配置ssh&quot;&gt;1.1 配置ssh&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh-keygen -t rsa
一路回车....

将公钥添加到每个节点
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;批量执行脚本:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@master219 bin]# pwd
/usr/local/bin
[root@master219 bin]# cat cmd
#!/bin/bash
## 批量执行命令
iplist=&quot;node220 node221&quot;

for i in $iplist
do
   echo -e &quot;\033[32mssh $i \&quot;$*\&quot;\033[0m&quot;
   ssh $i &quot;$*&quot;
done
[root@master219 bin]# cat rsy
#!/bin/bash
## 批量同步文件
iplist=&quot;node220 node221&quot;

for i in $iplist
do
   echo -e &quot;\033[32mscp -r $1 $i:$2\033[0m&quot;
   scp -r $1 $i:$2
done

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;12-系统配置&quot;&gt;1.2 系统配置&lt;/h4&gt;
&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;所有节点都需要执行下列操作&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;setenforce 0
sed -i 's/SELINUX=enforcing/SELINUX=disalbe/g' /etc/sysconfig/selinux

cat &amp;gt;&amp;gt; /etc/security/limits.conf &amp;lt;&amp;lt;EOF
* soft nofile 65536
* hard nofile 65536
* soft nproc unlimited
* hard nproc unlimited
EOF

swapoff -a

cat &amp;gt;&amp;gt; /etc/sysctl.conf &amp;lt;&amp;lt;EOF
net.bridge.bridge-nf-call-iptables=1
net.bridge.bridge-nf-call-ip6tables=1
net.ipv4.ip_forward=1
net.ipv4.tcp_tw_recycle=0
vm.swappiness=0
vm.overcommit_memory=1
vm.panic_on_oom=0
fs.inotify.max_user_watches=89100
fs.file-max=52706963
fs.nr_open=52706963
net.ipv6.conf.all.disable_ipv6=1
net.netfilter.nf_conntrack_max=2310720
EOF

systemctl stop firewalld &amp;amp;&amp;amp; systemctl disable firewalld
yum makecache fast
yum install -y epel-release
yum install -y conntrack ipvsadm ipset jq sysstat curl iptables libseccomp ntpdate
ntpdate cn.pool.ntp.org
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;13-install-docker&quot;&gt;1.3 Install Docker&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;参考 &lt;a href=&quot;https://docs.docker.com/install/linux/docker-ce/centos/#install-using-the-repository&quot;&gt;官方文档&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yum install -y yum-utils device-mapper-persistent-data lvm2
yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
yum list docker-ce --showduplicates | sort -r
yum -y install docker-ce-18.06.0.ce
systemctl start docker &amp;amp;&amp;amp; systemctl stop docker
cat &amp;gt; /etc/docker/daemon.json &amp;lt;&amp;lt;EOF
{
  &quot;registry-mirrors&quot;: [&quot;https://dlvqhrac.mirror.aliyuncs.com&quot;]
}
EOF

systemctl daemon-reload
systemctl start docker
systemctl enable docker
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;二-安装cfssl&quot;&gt;二. 安装cfssl&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;https://github.com/cloudflare/cfssl/releases&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;只需要在master节点安装使用即可，后续证书同步到其他节点即可&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tar -zxvf cfssl.tar.gz
mv cfssl cfssljson /usr/local/bin
chmod +x /usr/local/bin/cfssl /usr/local/bin/cfssljson
rm -f cfssl.tar.gz
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;三-etcd&quot;&gt;三. ETCD&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/coreos/etcd/releases/download&quot;&gt;下载链接&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;创建etcd 用户来启动!! 注意用户权限&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;31-证书&quot;&gt;3.1 证书&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;etcd-csr.json&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
  &quot;key&quot;: {
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  },
  &quot;names&quot;: [
    {
      &quot;O&quot;: &quot;etcd&quot;,
      &quot;OU&quot;: &quot;etcd Security&quot;,
      &quot;L&quot;: &quot;Shengzhen&quot;,
      &quot;ST&quot;: &quot;Shengzhen&quot;,
      &quot;C&quot;: &quot;CN&quot;
    }
  ],
  &quot;CN&quot;: &quot;etcd&quot;,
  &quot;hosts&quot;: [
    &quot;127.0.0.1&quot;,
    &quot;localhost&quot;,
    &quot;192.168.2.219&quot;,
    &quot;192.168.2.220&quot;,
    &quot;192.168.2.221&quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;etcd-gencert.json&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
  &quot;signing&quot;: {
    &quot;default&quot;: {
        &quot;usages&quot;: [
          &quot;signing&quot;,
          &quot;key encipherment&quot;,
          &quot;server auth&quot;,
          &quot;client auth&quot;
        ],
        &quot;expiry&quot;: &quot;87600h&quot;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;etcd-root-ca-csr.json&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
  &quot;key&quot;: {
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 4096
  },
  &quot;names&quot;: [
    {
      &quot;O&quot;: &quot;etcd&quot;,
      &quot;OU&quot;: &quot;etcd Security&quot;,
      &quot;L&quot;: &quot;Shengzhen&quot;,
      &quot;ST&quot;: &quot;Shengzhen&quot;,
      &quot;C&quot;: &quot;CN&quot;
    }
  ],
  &quot;CN&quot;: &quot;etcd-root-ca&quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;生成证书&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cfssl gencert --initca=true etcd-root-ca-csr.json | cfssljson --bare etcd-root-ca
cfssl gencert --ca etcd-root-ca.pem --ca-key etcd-root-ca-key.pem --config etcd-gencert.json etcd-csr.json | cfssljson --bare etcd

[root@master219 ssl]# ls
etcd.csr  etcd-csr.json  etcd-gencert.json  etcd-key.pem  etcd.pem  etcd-root-ca.csr  etcd-root-ca-csr.json  etcd-root-ca-key.pem  etcd-root-ca.pem
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;32-etcdconf&quot;&gt;3.2 etcd.conf&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# [member]
ETCD_NAME=etcd1
ETCD_DATA_DIR=&quot;/var/lib/etcd/etcd1.etcd&quot;
ETCD_WAL_DIR=&quot;/var/lib/etcd/wal&quot;
ETCD_SNAPSHOT_COUNT=&quot;100&quot;
ETCD_HEARTBEAT_INTERVAL=&quot;100&quot;
ETCD_ELECTION_TIMEOUT=&quot;1000&quot;
ETCD_LISTEN_PEER_URLS=&quot;https://192.168.2.219:2380&quot;
ETCD_LISTEN_CLIENT_URLS=&quot;https://192.168.2.219:2379,http://127.0.0.1:2379&quot;
ETCD_MAX_SNAPSHOTS=&quot;5&quot;
ETCD_MAX_WALS=&quot;5&quot;
#ETCD_CORS=&quot;&quot;
# [cluster]
ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;https://192.168.2.219:2380&quot;
ETCD_ADVERTISE_CLIENT_URLS=&quot;https://192.168.2.219:2379&quot;
# if you use different ETCD_NAME (e.g. test), set ETCD_INITIAL_CLUSTER value for this name, i.e. &quot;test=http://...&quot;
ETCD_INITIAL_CLUSTER=&quot;etcd1=https://192.168.2.219:2380,etcd2=https://192.168.2.220:2380,etcd3=https://192.168.2.221:2380&quot;
ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;
ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot;
#ETCD_DISCOVERY=&quot;&quot;
#ETCD_DISCOVERY_SRV=&quot;&quot;
#ETCD_DISCOVERY_FALLBACK=&quot;proxy&quot;
#ETCD_DISCOVERY_PROXY=&quot;&quot;
#ETCD_STRICT_RECONFIG_CHECK=&quot;false&quot;
#ETCD_AUTO_COMPACTION_RETENTION=&quot;0&quot;
# [proxy]
#ETCD_PROXY=&quot;off&quot;
#ETCD_PROXY_FAILURE_WAIT=&quot;5000&quot;
#ETCD_PROXY_REFRESH_INTERVAL=&quot;30000&quot;
#ETCD_PROXY_DIAL_TIMEOUT=&quot;1000&quot;
#ETCD_PROXY_WRITE_TIMEOUT=&quot;5000&quot;
#ETCD_PROXY_READ_TIMEOUT=&quot;0&quot;
# [security]
ETCD_CERT_FILE=&quot;/etc/etcd/ssl/etcd.pem&quot;
ETCD_KEY_FILE=&quot;/etc/etcd/ssl/etcd-key.pem&quot;
ETCD_CLIENT_CERT_AUTH=&quot;true&quot;
ETCD_TRUSTED_CA_FILE=&quot;/etc/etcd/ssl/etcd-root-ca.pem&quot;
ETCD_AUTO_TLS=&quot;true&quot;
ETCD_PEER_CERT_FILE=&quot;/etc/etcd/ssl/etcd.pem&quot;
ETCD_PEER_KEY_FILE=&quot;/etc/etcd/ssl/etcd-key.pem&quot;
ETCD_PEER_CLIENT_CERT_AUTH=&quot;true&quot;
ETCD_PEER_TRUSTED_CA_FILE=&quot;/etc/etcd/ssl/etcd-root-ca.pem&quot;
ETCD_PEER_AUTO_TLS=&quot;true&quot;
# [logging]
#ETCD_DEBUG=&quot;false&quot;
# examples for -log-package-levels etcdserver=WARNING,security=DEBUG
#ETCD_LOG_PACKAGE_LEVELS=&quot;&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;33-etcdservice&quot;&gt;3.3 etcd.service&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
Description=Etcd Server
After=network.target
After=network-online.target
Wants=network-online.target
[Service]
Type=notify
WorkingDirectory=/var/lib/etcd/
EnvironmentFile=-/etc/etcd/etcd.conf
User=etcd
# set GOMAXPROCS to number of processors
ExecStart=/bin/bash -c &quot;GOMAXPROCS=$(nproc) /usr/local/bin/etcd --name=\&quot;${ETCD_NAME}\&quot; --data-dir=\&quot;${ETCD_DATA_DIR}\&quot; --listen-client-urls=\&quot;${ETCD_LISTEN_CLIENT_URLS}\&quot;&quot;
Restart=on-failure
LimitNOFILE=65536
[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;34-安装启动&quot;&gt;3.4 安装启动&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;install.sh&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;ETCD_VERSION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;3.2.18&quot;&lt;/span&gt;

preinstall&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    getent group etcd &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;/dev/null &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; groupadd &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; etcd
    getent passwd etcd &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;/dev/null &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; useradd &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-g&lt;/span&gt; etcd &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; /var/lib/etcd &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; /sbin/nologin &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;etcd user&quot;&lt;/span&gt; etcd
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

install&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[32mINFO: Copy etcd...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;tar&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-zxvf&lt;/span&gt; etcd-v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ETCD_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;-linux-amd64&lt;/span&gt;.tar.gz
    cp etcd-v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ETCD_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;-linux-amd64&lt;/span&gt;/etcd&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; /usr/local/bin
    rm &lt;span class=&quot;nt&quot;&gt;-rf&lt;/span&gt; etcd-v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ETCD_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;-linux-amd64&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[32mINFO: Copy etcd config...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
    cp &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; conf /etc/etcd
    chown &lt;span class=&quot;nt&quot;&gt;-R&lt;/span&gt; etcd:etcd /etc/etcd
    chmod &lt;span class=&quot;nt&quot;&gt;-R&lt;/span&gt; 755 /etc/etcd/ssl
    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[32mINFO: Copy etcd systemd config...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
    cp etcd.service /lib/systemd/system
    systemctl daemon-reload
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

postinstall&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/var/lib/etcd&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
        &lt;/span&gt;mkdir /var/lib/etcd
        chown &lt;span class=&quot;nt&quot;&gt;-R&lt;/span&gt; etcd:etcd /var/lib/etcd
    &lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

preinstall
install
postinstall

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;目录结构:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;etcd/
├── conf
│   ├── etcd.conf
│   └── ssl
│       ├── etcd.csr
│       ├── etcd-csr.json
│       ├── etcd-gencert.json
│       ├── etcd-key.pem
│       ├── etcd.pem
│       ├── etcd-root-ca.csr
│       ├── etcd-root-ca-csr.json
│       ├── etcd-root-ca-key.pem
│       └── etcd-root-ca.pem
├── etcd.service
├── etcd-v3.2.18-linux-amd64.tar.gz
└── install.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;创建对应目录以及相关文件，保存 install.sh 脚本;将整个目录同步到各个节点执行即可；
然后在各个节点修改对应的etcd 名称及IP即可；&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;注意:三个节点同时执行此操作否则单个启动会卡死在那里;&lt;/li&gt;
  &lt;li&gt;使用前面配置的&lt;code class=&quot;highlighter-rouge&quot;&gt;cmd&lt;/code&gt; 命令批量执行&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# systemctl start etcd
# cmd systemctl enable etcd
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export ETCDCTL_API=3
etcdctl --cacert=/etc/etcd/ssl/etcd-root-ca.pem --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem --endpoints=https://192.168.2.219:2379,https://192.168.2.220:2379,https://192.168.2.221:2379 endpoint health

https://192.168.2.221:2379 is healthy: successfully committed proposal: took = 2.077429ms
https://192.168.2.219:2379 is healthy: successfully committed proposal: took = 1.421477ms
https://192.168.2.220:2379 is healthy: successfully committed proposal: took = 2.222464ms
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;四-kubernetes&quot;&gt;四. kubernetes&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;基于 hyperkube 二进制手动安装&lt;/li&gt;
  &lt;li&gt;hyperkube是一个集成二进制运行文件&lt;/li&gt;
  &lt;li&gt;可以使用“hyperkube kubelet …”来启动kubelet ，用“hyperkube apiserver …”运行apiserver 等等。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;41-证书&quot;&gt;4.1 证书&lt;/h3&gt;
&lt;p&gt;由于 kubelet 和 kube-proxy 用到的 kubeconfig 配置文件需要借助 kubectl 来生成，所以需要先安装一下 kubectl&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl https://storage.googleapis.com/kubernetes-release/release/v1.10.10/bin/linux/amd64/hyperkube -o hyperkube-1.10.10
chmod +x hyperkube_1.10.10
cp hyperkube_1.10.10 /usr/local/bin/hyperkube
ln -s /usr/local/bin/hyperkube /usr/local/bin/kubectl
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://www.jevic.cn/2018/03/19/shadowsock/&quot;&gt;curl 代理配置&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;admin-csrjson&quot;&gt;admin-csr.json&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
  &quot;CN&quot;: &quot;admin&quot;,
  &quot;hosts&quot;: [],
  &quot;key&quot;: {
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  },
  &quot;names&quot;: [
    {
      &quot;C&quot;: &quot;CN&quot;,
      &quot;ST&quot;: &quot;Shengzhen&quot;,
      &quot;L&quot;: &quot;Shengzhen&quot;,
      &quot;O&quot;: &quot;system:masters&quot;,
      &quot;OU&quot;: &quot;System&quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;k8s-gencertjson&quot;&gt;k8s-gencert.json&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
  &quot;signing&quot;: {
    &quot;default&quot;: {
      &quot;expiry&quot;: &quot;87600h&quot;
    },
    &quot;profiles&quot;: {
      &quot;kubernetes&quot;: {
        &quot;usages&quot;: [
            &quot;signing&quot;,
            &quot;key encipherment&quot;,
            &quot;server auth&quot;,
            &quot;client auth&quot;
        ],
        &quot;expiry&quot;: &quot;87600h&quot;
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;k8s-root-ca-csrjson&quot;&gt;k8s-root-ca-csr.json&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
  &quot;CN&quot;: &quot;kubernetes&quot;,
  &quot;key&quot;: {
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 4096
  },
  &quot;names&quot;: [
    {
      &quot;C&quot;: &quot;CN&quot;,
      &quot;ST&quot;: &quot;Shengzhen&quot;,
      &quot;L&quot;: &quot;Shengzhen&quot;,
      &quot;O&quot;: &quot;k8s&quot;,
      &quot;OU&quot;: &quot;System&quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;kube-apiserver-csrjson&quot;&gt;kube-apiserver-csr.json&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
    &quot;CN&quot;: &quot;kubernetes&quot;,
    &quot;hosts&quot;: [
        &quot;127.0.0.1&quot;,
        &quot;10.254.0.1&quot;,
        &quot;192.168.2.219&quot;,
        &quot;192.168.2.220&quot;,
        &quot;192.168.2.221&quot;,
        &quot;*.kubernetes.master&quot;,
        &quot;localhost&quot;,
        &quot;kubernetes&quot;,
        &quot;kubernetes.default&quot;,
        &quot;kubernetes.default.svc&quot;,
        &quot;kubernetes.default.svc.cluster&quot;,
        &quot;kubernetes.default.svc.cluster.local&quot;
    ],
    &quot;key&quot;: {
        &quot;algo&quot;: &quot;rsa&quot;,
        &quot;size&quot;: 2048
    },
    &quot;names&quot;: [
        {
            &quot;C&quot;: &quot;CN&quot;,
            &quot;ST&quot;: &quot;Shengzhen&quot;,
            &quot;L&quot;: &quot;Shengzhen&quot;,
            &quot;O&quot;: &quot;k8s&quot;,
            &quot;OU&quot;: &quot;System&quot;
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;kube-proxy-csrjson&quot;&gt;kube-proxy-csr.json&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
  &quot;CN&quot;: &quot;system:kube-proxy&quot;,
  &quot;hosts&quot;: [],
  &quot;key&quot;: {
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  },
  &quot;names&quot;: [
    {
      &quot;C&quot;: &quot;CN&quot;,
      &quot;ST&quot;: &quot;Shengzhen&quot;,
      &quot;L&quot;: &quot;Shengzhen&quot;,
      &quot;O&quot;: &quot;k8s&quot;,
      &quot;OU&quot;: &quot;System&quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;411-生成证书和配置&quot;&gt;4.1.1 生成证书和配置&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 生成 CA
cfssl gencert --initca=true k8s-root-ca-csr.json | cfssljson --bare k8s-root-ca

# 依次生成其他组件证书
for targetName in kube-apiserver admin kube-proxy; do
    cfssl gencert --ca k8s-root-ca.pem --ca-key k8s-root-ca-key.pem --config k8s-gencert.json --profile kubernetes $targetName-csr.json | cfssljson --bare $targetName
done

# 地址默认为 127.0.0.1:6443
# 如果在 master 上启用 kubelet 请在生成后的 kubeconfig 中
# 修改该地址为 当前MASTER_IP:6443
KUBE_APISERVER=&quot;https://127.0.0.1:6443&quot;
BOOTSTRAP_TOKEN=$(head -c 16 /dev/urandom | od -An -t x | tr -d ' ')
echo &quot;Tokne: ${BOOTSTRAP_TOKEN}&quot;

# 不要质疑 system:bootstrappers 用户组是否写错了，有疑问请参考官方文档
# https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/
cat &amp;gt; token.csv &amp;lt;&amp;lt;EOF
${BOOTSTRAP_TOKEN},kubelet-bootstrap,10001,&quot;system:bootstrappers&quot;
EOF

echo &quot;Create kubelet bootstrapping kubeconfig...&quot;
# 设置集群参数
kubectl config set-cluster kubernetes \
  --certificate-authority=k8s-root-ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=bootstrap.kubeconfig
# 设置客户端认证参数
kubectl config set-credentials kubelet-bootstrap \
  --token=${BOOTSTRAP_TOKEN} \
  --kubeconfig=bootstrap.kubeconfig
# 设置上下文参数
kubectl config set-context default \
  --cluster=kubernetes \
  --user=kubelet-bootstrap \
  --kubeconfig=bootstrap.kubeconfig
# 设置默认上下文
kubectl config use-context default --kubeconfig=bootstrap.kubeconfig

echo &quot;Create kube-proxy kubeconfig...&quot;
# 设置集群参数
kubectl config set-cluster kubernetes \
  --certificate-authority=k8s-root-ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=kube-proxy.kubeconfig
# 设置客户端认证参数
kubectl config set-credentials kube-proxy \
  --client-certificate=kube-proxy.pem \
  --client-key=kube-proxy-key.pem \
  --embed-certs=true \
  --kubeconfig=kube-proxy.kubeconfig
# 设置上下文参数
kubectl config set-context default \
  --cluster=kubernetes \
  --user=kube-proxy \
  --kubeconfig=kube-proxy.kubeconfig
# 设置默认上下文
kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig

# 创建高级审计配置
cat &amp;gt;&amp;gt; audit-policy.yaml &amp;lt;&amp;lt;EOF
# Log all requests at the Metadata level.
apiVersion: audit.k8s.io/v1beta1
kind: Policy
rules:
- level: Metadata
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;生成后的文件&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssl
├── admin.csr
├── admin-csr.json
├── admin-key.pem
├── admin.pem
├── audit-policy.yaml
├── bootstrap.kubeconfig
├── genconfig.sh
├── k8s-gencert.json
├── k8s-root-ca.csr
├── k8s-root-ca-csr.json
├── k8s-root-ca-key.pem
├── k8s-root-ca.pem
├── kube-apiserver.csr
├── kube-apiserver-csr.json
├── kube-apiserver-key.pem
├── kube-apiserver.pem
├── kube-proxy.csr
├── kube-proxy-csr.json
├── kube-proxy-key.pem
├── kube-proxy.kubeconfig
├── kube-proxy.pem
└── token.csv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;42-systemd-配置&quot;&gt;4.2 systemd 配置&lt;/h3&gt;

&lt;h4 id=&quot;kube-apiserverservice&quot;&gt;kube-apiserver.service&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
Description=Kubernetes API Server
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=network.target
After=etcd.service
[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/apiserver
User=root
ExecStart=/usr/local/bin/hyperkube apiserver \
            $KUBE_LOGTOSTDERR \
            $KUBE_LOG_LEVEL \
            $KUBE_ETCD_SERVERS \
            $KUBE_API_ADDRESS \
            $KUBE_API_PORT \
            $KUBELET_PORT \
            $KUBE_ALLOW_PRIV \
            $KUBE_SERVICE_ADDRESSES \
            $KUBE_ADMISSION_CONTROL \
            $KUBE_API_ARGS
Restart=on-failure
Type=notify
LimitNOFILE=65536
[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;kube-controller-managerservice&quot;&gt;kube-controller-manager.service&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
Description=Kubernetes Controller Manager
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/controller-manager
User=root
ExecStart=/usr/local/bin/hyperkube controller-manager \
            $KUBE_LOGTOSTDERR \
            $KUBE_LOG_LEVEL \
            $KUBE_MASTER \
            $KUBE_CONTROLLER_MANAGER_ARGS
Restart=on-failure
LimitNOFILE=65536
[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;kubeletservice&quot;&gt;kubelet.service&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
Description=Kubernetes Kubelet Server
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=docker.service
Requires=docker.service
[Service]
WorkingDirectory=/var/lib/kubelet
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/kubelet
ExecStart=/usr/local/bin/hyperkube kubelet \
            $KUBE_LOGTOSTDERR \
            $KUBE_LOG_LEVEL \
            $KUBELET_API_SERVER \
            $KUBELET_ADDRESS \
            $KUBELET_PORT \
            $KUBELET_HOSTNAME \
            $KUBE_ALLOW_PRIV \
            $KUBELET_ARGS
Restart=on-failure
KillMode=process
[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;kube-proxyservice&quot;&gt;kube-proxy.service&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
Description=Kubernetes Kube-Proxy Server
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=network.target
[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/proxy
ExecStart=/usr/local/bin/hyperkube proxy \
            $KUBE_LOGTOSTDERR \
            $KUBE_LOG_LEVEL \
            $KUBE_MASTER \
            $KUBE_PROXY_ARGS
Restart=on-failure
LimitNOFILE=65536
[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;kube-schedulerservice&quot;&gt;kube-scheduler.service&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
Description=Kubernetes Scheduler Plugin
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/scheduler
User=root
ExecStart=/usr/local/bin/hyperkube scheduler \
            $KUBE_LOGTOSTDERR \
            $KUBE_LOG_LEVEL \
            $KUBE_MASTER \
            $KUBE_SCHEDULER_ARGS
Restart=on-failure
LimitNOFILE=65536
[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;43-配置文件&quot;&gt;4.3 配置文件&lt;/h3&gt;
&lt;h4 id=&quot;431-master-节点配置&quot;&gt;4.3.1 master 节点配置&lt;/h4&gt;
&lt;p&gt;Master 节点主要会运行 3 各组件: kube-apiserver、kube-controller-manager、kube-scheduler，其中用到的配置文件如下&lt;/p&gt;
&lt;h5 id=&quot;config&quot;&gt;config&lt;/h5&gt;
&lt;p&gt;config 是一个通用配置文件，值得注意的是由于安装时对于 Node、Master 节点都会包含该文件;
在 Node 节点上请注释掉 KUBE_MASTER 变量，因为 Node 节点需要做 HA，要连接本地的 6443 加密端口；而这个变量将会覆盖 kubeconfig 中指定的 127.0.0.1:6443 地址&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;###
# kubernetes system config
#
# The following values are used to configure various aspects of all
# kubernetes services, including
#
#   kube-apiserver.service
#   kube-controller-manager.service
#   kube-scheduler.service
#   kubelet.service
#   kube-proxy.service
# logging to stderr means we get it in the systemd journal
KUBE_LOGTOSTDERR=&quot;--logtostderr=true&quot;

# journal message level, 0 is debug
KUBE_LOG_LEVEL=&quot;--v=2&quot;

# Should this cluster be allowed to run privileged docker containers
KUBE_ALLOW_PRIV=&quot;--allow-privileged=true&quot;

# How the controller-manager, scheduler, and proxy find the apiserver
KUBE_MASTER=&quot;--master=http://127.0.0.1:8080&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;apiserver&quot;&gt;apiserver&lt;/h5&gt;
&lt;p&gt;apiserver 配置相对于 1.8 略有变动，其中准入控制器(admission control)选项名称变为了 –enable-admission-plugins，控制器列表也有相应变化，这里采用官方推荐配置，具体请参考 &lt;a href=&quot;https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#is-there-a-recommended-set-of-admission-controllers-to-use&quot;&gt;官方文档&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;###
# kubernetes system config
#
# The following values are used to configure the kube-apiserver
#
# The address on the local server to listen to.
KUBE_API_ADDRESS=&quot;--advertise-address=192.168.2.219 --bind-address=192.168.2.219&quot;
# The port on the local server to listen on.
KUBE_API_PORT=&quot;--secure-port=6443&quot;
# Port minions listen on
# KUBELET_PORT=&quot;--kubelet-port=10250&quot;
# Comma separated list of nodes in the etcd cluster
KUBE_ETCD_SERVERS=&quot;--etcd-servers=https://192.168.2.219:2379,https://192.168.2.220:2379,https://192.168.2.221:2379&quot;
# Address range to use for services
KUBE_SERVICE_ADDRESSES=&quot;--service-cluster-ip-range=10.254.0.0/16&quot;
# default admission control policies
KUBE_ADMISSION_CONTROL=&quot;--enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,NodeRestriction&quot;
# Add your own!
KUBE_API_ARGS=&quot; --anonymous-auth=false \
                --apiserver-count=3 \
                --audit-log-maxage=30 \
                --audit-log-maxbackup=3 \
                --audit-log-maxsize=100 \
                --audit-log-path=/var/log/kube-audit/audit.log \
                --audit-policy-file=/etc/kubernetes/audit-policy.yaml \
                --authorization-mode=Node,RBAC \
                --client-ca-file=/etc/kubernetes/ssl/k8s-root-ca.pem \
                --enable-bootstrap-token-auth \
                --enable-garbage-collector \
                --enable-logs-handler \
                --enable-swagger-ui \
                --etcd-cafile=/etc/etcd/ssl/etcd-root-ca.pem \
                --etcd-certfile=/etc/etcd/ssl/etcd.pem \
                --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem \
                --etcd-compaction-interval=5m0s \
                --etcd-count-metric-poll-period=1m0s \
                --event-ttl=48h0m0s \
                --kubelet-https=true \
                --kubelet-timeout=3s \
                --log-flush-frequency=5s \
                --token-auth-file=/etc/kubernetes/token.csv \
                --tls-cert-file=/etc/kubernetes/ssl/kube-apiserver.pem \
                --tls-private-key-file=/etc/kubernetes/ssl/kube-apiserver-key.pem \
                --service-node-port-range=30000-50000 \
                --service-account-key-file=/etc/kubernetes/ssl/k8s-root-ca.pem \
                --storage-backend=etcd3 \
                --enable-swagger-ui=true&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;controller-manager&quot;&gt;controller-manager&lt;/h5&gt;
&lt;p&gt;controller manager 配置默认开启了证书轮换能力用于自动签署 kueblet 证书，并且证书时间也设置了 10 年，可自行调整；增加了 –controllers 选项以指定开启全部控制器&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;###
# The following values are used to configure the kubernetes controller-manager
# defaults from config and apiserver should be adequate
# Add your own!
KUBE_CONTROLLER_MANAGER_ARGS=&quot;  --bind-address=0.0.0.0 \
                                --cluster-name=kubernetes \
                                --cluster-signing-cert-file=/etc/kubernetes/ssl/k8s-root-ca.pem \
                                --cluster-signing-key-file=/etc/kubernetes/ssl/k8s-root-ca-key.pem \
                                --controllers=*,bootstrapsigner,tokencleaner \
                                --deployment-controller-sync-period=10s \
                                --experimental-cluster-signing-duration=86700h0m0s \
                                --leader-elect=true \
                                --node-monitor-grace-period=40s \
                                --node-monitor-period=5s \
                                --pod-eviction-timeout=5m0s \
                                --terminated-pod-gc-threshold=50 \
                                --root-ca-file=/etc/kubernetes/ssl/k8s-root-ca.pem \
                                --service-account-private-key-file=/etc/kubernetes/ssl/k8s-root-ca-key.pem \
                                --feature-gates=RotateKubeletServerCertificate=true&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;scheduler&quot;&gt;scheduler&lt;/h5&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;###
# kubernetes scheduler config

# default config should be adequate

# Add your own!
KUBE_SCHEDULER_ARGS=&quot;   --address=0.0.0.0 \
                        --leader-elect=true \
                        --algorithm-provider=DefaultProvider&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;432-node-节点配置&quot;&gt;4.3.2 node 节点配置&lt;/h4&gt;
&lt;p&gt;Node 节点上主要有 kubelet、kube-proxy 组件，用到的配置如下&lt;/p&gt;

&lt;h5 id=&quot;kubelet&quot;&gt;kubelet&lt;/h5&gt;
&lt;p&gt;kubeket 默认也开启了证书轮换能力以保证自动续签相关证书，同时增加了 –node-labels 选项为 node 打一个标签，关于这个标签最后部分会有讨论，如果在 master 上启动 kubelet，请将 node-role.kubernetes.io/k8s-node=true 修改为 node-role.kubernetes.io/k8s-master=true&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;###
# kubernetes kubelet (minion) config
# The address for the info server to serve on (set to 0.0.0.0 or &quot;&quot; for all interfaces)
KUBELET_ADDRESS=&quot;--node-ip=192.168.2.219&quot;
# The port for the info server to serve on
# KUBELET_PORT=&quot;--port=10250&quot;
# You may leave this blank to use the actual hostname
KUBELET_HOSTNAME=&quot;--hostname-override=master219&quot;
# location of the api-server
# KUBELET_API_SERVER=&quot;&quot;
# Add your own!
KUBELET_ARGS=&quot;  --bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \
                --cert-dir=/etc/kubernetes/ssl \
                --cgroup-driver=cgroupfs \
                --cluster-dns=10.254.0.2 \
                --cluster-domain=cluster.local. \
                --fail-swap-on=false \
                --feature-gates=RotateKubeletClientCertificate=true,RotateKubeletServerCertificate=true \
                --node-labels=node-role.kubernetes.io/master=true \
                --image-gc-high-threshold=70 \
                --image-gc-low-threshold=50 \
                --kube-reserved=cpu=500m,memory=512Mi,ephemeral-storage=1Gi \
                --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \
                --system-reserved=cpu=1000m,memory=1024Mi,ephemeral-storage=1Gi \
                --serialize-image-pulls=false \
                --sync-frequency=30s \
                --pod-infra-container-image=k8s.gcr.io/pause-amd64:3.0 \
                --resolv-conf=/etc/resolv.conf \
                --rotate-certificates&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;proxy&quot;&gt;proxy&lt;/h5&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;###
# kubernetes proxy config
# default config should be adequate
# Add your own!
KUBE_PROXY_ARGS=&quot;--bind-address=0.0.0.0 \
                 --hostname-override=node219 \
                 --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig \
                 --cluster-cidr=10.254.0.0/16&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;44-启动-master-节点&quot;&gt;4.4 启动 Master 节点&lt;/h3&gt;
&lt;p&gt;创建相关目录否则报错&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mkdir /var/log/kube-audit
mkdir /var/lib/kubelet
mkdir /usr/libexec
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cp -a conf /etc/kubernetes  
cp systemd/*.service /lib/systemd/system
systemctl daemon-reload
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;对于 &lt;code class=&quot;highlighter-rouge&quot;&gt;master&lt;/code&gt; 节点启动无需做过多处理，多个 &lt;code class=&quot;highlighter-rouge&quot;&gt;master&lt;/code&gt; 只要保证 &lt;code class=&quot;highlighter-rouge&quot;&gt;apiserver&lt;/code&gt; 等配置中的 &lt;code class=&quot;highlighter-rouge&quot;&gt;ip&lt;/code&gt; 地址监听没问题后直接启动即可&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;systemctl daemon-reload
systemctl start kube-apiserver
systemctl start kube-controller-manager
systemctl start kube-scheduler
systemctl enable kube-apiserver
systemctl enable kube-controller-manager
systemctl enable kube-scheduler

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;启动后:
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/kubernetes/kubernetes-get-cs.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;45-启动-node-节点&quot;&gt;4.5 启动 Node 节点&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;由于 HA 等功能需要，对于 Node 需要做一些处理才能启动，主要有以下两个地方需要处理&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;451-nginx-proxy-node节点部署&quot;&gt;4.5.1 nginx-proxy (node节点部署)&lt;/h4&gt;
&lt;p&gt;在启动 kubelet、kube-proxy 服务之前，需要在本地启动 nginx 来 tcp 负载均衡 apiserver 6443 端口，nginx-proxy 使用 docker + systemd 启动，配置如下&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;nginx-proxy.service&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
Description=kubernetes apiserver docker wrapper
Wants=docker.socket
After=docker.service

[Service]
User=root
PermissionsStartOnly=true
ExecStart=/usr/bin/docker run -p 127.0.0.1:6443:6443 \
                              -v /etc/nginx:/etc/nginx \
                              --name nginx-proxy \
                              --net=host \
                              --restart=on-failure:5 \
                              --memory=512M \
                              nginx:1.13.12-alpine
ExecStartPre=-/usr/bin/docker rm -f nginx-proxy
ExecStop=/usr/bin/docker stop nginx-proxy
Restart=always
RestartSec=15s
TimeoutStartSec=30s

[Install]
WantedBy=multi-user.target

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;nginx.conf&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;error_log stderr notice;

worker_processes auto;
events {
        multi_accept on;
        use epoll;
        worker_connections 1024;
}

stream {
    upstream kube_apiserver {
        least_conn;
        server 192.168.2.219:6443; ## 多个master 依次配置即可
        # server x.x.x.x:6443;
    }

    server {
        listen        0.0.0.0:6443;
        proxy_pass    kube_apiserver;
        proxy_timeout 10m;
        proxy_connect_timeout 1s;
    }
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;启动 apiserver 的本地负载均衡&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mkdir /etc/nginx
cp nginx.conf /etc/nginx
cp nginx-proxy.service /lib/systemd/system

systemctl daemon-reload
systemctl start nginx-proxy
systemctl enable nginx-proxy

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;452-tls-bootstrapping&quot;&gt;4.5.2 TLS bootstrapping&lt;/h4&gt;
&lt;p&gt;创建好 nginx-proxy 后不要忘记为 TLS Bootstrap 创建相应的 RBAC 规则，这些规则能实现证自动签署 TLS Bootstrap 发出的 CSR 请求，从而实现证书轮换(创建一次即可);&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;tls-bootstrapping-clusterrole.yaml&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# A ClusterRole which instructs the CSR approver to approve a node requesting a
# serving cert matching its client cert.
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeserver
rules:
- apiGroups: [&quot;certificates.k8s.io&quot;]
  resources: [&quot;certificatesigningrequests/selfnodeserver&quot;]
  verbs: [&quot;create&quot;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在 master 执行创建&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 给与 kubelet-bootstrap 用户进行 node-bootstrapper 的权限
kubectl create clusterrolebinding kubelet-bootstrap \
    --clusterrole=system:node-bootstrapper \
    --user=kubelet-bootstrap

kubectl create -f tls-bootstrapping-clusterrole.yaml

# 自动批准 system:bootstrappers 组用户 TLS bootstrapping 首次申请证书的 CSR 请求
kubectl create clusterrolebinding node-client-auto-approve-csr \
        --clusterrole=system:certificates.k8s.io:certificatesigningrequests:nodeclient \
        --group=system:bootstrappers

# 自动批准 system:nodes 组用户更新 kubelet 自身与 apiserver 通讯证书的 CSR 请求
kubectl create clusterrolebinding node-client-auto-renew-crt \
        --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeclient \
        --group=system:nodes

# 自动批准 system:nodes 组用户更新 kubelet 10250 api 端口证书的 CSR 请求
kubectl create clusterrolebinding node-server-auto-renew-crt \
        --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeserver \
        --group=system:nodes

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;453-启动&quot;&gt;4.5.3 启动&lt;/h4&gt;
&lt;p&gt;多节点部署时先启动好 nginx-proxy，然后修改好相应配置的 ip 地址等配置，最终直接启动即可(master 上启动 kubelet 不要忘了修改 kubeconfig 中的 apiserver 地址，还有对应的 kubelet 的 node label)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;systemctl daemon-reload
systemctl start kubelet
systemctl start kube-proxy
systemctl enable kubelet
systemctl enable kube-proxy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;454-master-节点启动-kubelet&quot;&gt;4.5.4 master 节点启动 kubelet&lt;/h4&gt;
&lt;blockquote&gt;
  &lt;p&gt;注意: 对于在 master 节点启动 kubelet 来说，只需要修改 kubelet.kubeconfig、kube-proxy.kubeconfig 中的 apiserver 地址为当前 master ip 6443 端口即可&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# grep server kube-proxy.kubeconfig
server: https://192.168.2.219:6443
# grep server bootstrap.kubeconfig
server: https://192.168.2.219:6443

systemctl daemon-reload
systemctl start kubelet
systemctl start kube-proxy
systemctl enable kubelet
systemctl enable kube-proxy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;最终成功启动后:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/kubernetes/kubernetes-get-node.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;五-calico&quot;&gt;五. Calico&lt;/h2&gt;
&lt;h3 id=&quot;51-修改calico-配置&quot;&gt;5.1 修改calico 配置&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#wget https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/hosted/calico.yaml -O calico.example.yaml

ETCD_CERT=`cat /etc/etcd/ssl/etcd.pem | base64 | tr -d '\n'`
ETCD_KEY=`cat /etc/etcd/ssl/etcd-key.pem | base64 | tr -d '\n'`
ETCD_CA=`cat /etc/etcd/ssl/etcd-root-ca.pem | base64 | tr -d '\n'`
ETCD_ENDPOINTS=&quot;https://192.168.2.219:2379,https://192.168.2.220:2379,https://192.168.2.221:2379&quot;

cp calico.example.yaml calico.yaml

sed -i &quot;s@.*etcd_endpoints:.*@\ \ etcd_endpoints:\ \&quot;${ETCD_ENDPOINTS}\&quot;@gi&quot; calico.yaml

sed -i &quot;s@.*etcd-cert:.*@\ \ etcd-cert:\ ${ETCD_CERT}@gi&quot; calico.yaml
sed -i &quot;s@.*etcd-key:.*@\ \ etcd-key:\ ${ETCD_KEY}@gi&quot; calico.yaml
sed -i &quot;s@.*etcd-ca:.*@\ \ etcd-ca:\ ${ETCD_CA}@gi&quot; calico.yaml

sed -i 's@.*etcd_ca:.*@\ \ etcd_ca:\ &quot;/calico-secrets/etcd-ca&quot;@gi' calico.yaml
sed -i 's@.*etcd_cert:.*@\ \ etcd_cert:\ &quot;/calico-secrets/etcd-cert&quot;@gi' calico.yaml
sed -i 's@.*etcd_key:.*@\ \ etcd_key:\ &quot;/calico-secrets/etcd-key&quot;@gi' calico.yaml

# 注释掉 calico-node 部分(由 Systemd 接管)
sed -i '123,219s@.*@#&amp;amp;@gi' calico.yaml

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;52-创建systemd-文件&quot;&gt;5.2 创建systemd 文件&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;需要在每个节点(master和node)执行&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;K8S_MASTER_IP=&quot;192.168.2.219&quot;
HOSTNAME=`cat /etc/hostname`
ETCD_ENDPOINTS=&quot;https://192.168.2.219:2379,https://192.168.2.220:2379,https://192.168.2.221:2379&quot;

cat &amp;gt; /lib/systemd/system/calico-node.service &amp;lt;&amp;lt;EOF
[Unit]
Description=calico node
After=docker.service
Requires=docker.service

[Service]
User=root
Environment=ETCD_ENDPOINTS=${ETCD_ENDPOINTS}
PermissionsStartOnly=true
ExecStart=/usr/bin/docker run   --net=host --privileged --name=calico-node \\
                                -e ETCD_ENDPOINTS=${ETCD_ENDPOINTS} \\
                                -e ETCD_CA_CERT_FILE=/etc/etcd/ssl/etcd-root-ca.pem \\
                                -e ETCD_CERT_FILE=/etc/etcd/ssl/etcd.pem \\
                                -e ETCD_KEY_FILE=/etc/etcd/ssl/etcd-key.pem \\
                                -e NODENAME=${HOSTNAME} \\
                                -e IP= \\
                                -e IP_AUTODETECTION_METHOD=can-reach=${K8S_MASTER_IP} \\
                                -e AS=64512 \\
                                -e CLUSTER_TYPE=k8s,bgp \\
                                -e CALICO_IPV4POOL_CIDR=10.20.0.0/16 \\
                                -e CALICO_IPV4POOL_IPIP=always \\
                                -e CALICO_LIBNETWORK_ENABLED=true \\
                                -e CALICO_NETWORKING_BACKEND=bird \\
                                -e CALICO_DISABLE_FILE_LOGGING=true \\
                                -e FELIX_IPV6SUPPORT=false \\
                                -e FELIX_DEFAULTENDPOINTTOHOSTACTION=ACCEPT \\
                                -e FELIX_LOGSEVERITYSCREEN=info \\
                                -e FELIX_IPINIPMTU=1440 \\
                                -e FELIX_HEALTHENABLED=true \\
                                -e CALICO_K8S_NODE_REF=${HOSTNAME} \\
                                -v /etc/calico/ssl:/etc/etcd/ssl \\
                                -v /lib/modules:/lib/modules \\
                                -v /var/lib/calico:/var/lib/calico \\
                                -v /var/run/calico:/var/run/calico \\
                                calico/node:v3.1.0
ExecStop=/usr/bin/docker rm -f calico-node
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;对于以上脚本中的 K8S_MASTER_IP 变量，只需要填写一个 master ip 即可，这个变量用于 calico 自动选择 IP 使用；在宿主机有多张网卡的情况下，calcio node 会自动获取一个 IP，获取原则就是尝试是否能够联通这个 master ip&lt;/p&gt;

&lt;p&gt;由于 calico 需要使用 etcd 存储数据，所以需要复制 etcd 证书到相关目录，/etc/calico 需要在每个节点都有&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cp -r /etc/etcd/ssl /etc/calico/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;53-修改-kubelet-配置&quot;&gt;5.3 修改 kubelet 配置&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;使用 Calico 后需要修改 kubelet 配置增加 CNI 设置(–network-plugin=cni)，修改后配置如下&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;###
# kubernetes kubelet (minion) config
# The address for the info server to serve on (set to 0.0.0.0 or &quot;&quot; for all interfaces)
KUBELET_ADDRESS=&quot;--node-ip=192.168.2.219&quot;
# The port for the info server to serve on
# KUBELET_PORT=&quot;--port=10250&quot;
# You may leave this blank to use the actual hostname
KUBELET_HOSTNAME=&quot;--hostname-override=master219&quot;
# location of the api-server
# KUBELET_API_SERVER=&quot;&quot;
# Add your own!
KUBELET_ARGS=&quot;  --bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \
                --cert-dir=/etc/kubernetes/ssl \
                --cgroup-driver=cgroupfs \
                --cluster-dns=10.254.0.2 \
                --network-plugin=cni \
                --cluster-domain=cluster.local. \
                --fail-swap-on=false \
                --feature-gates=RotateKubeletClientCertificate=true,RotateKubeletServerCertificate=true \
                --node-labels=node-role.kubernetes.io/master=true \
                --image-gc-high-threshold=70 \
                --image-gc-low-threshold=50 \
                --kube-reserved=cpu=500m,memory=512Mi,ephemeral-storage=1Gi \
                --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \
                --system-reserved=cpu=1000m,memory=1024Mi,ephemeral-storage=1Gi \
                --serialize-image-pulls=false \
                --sync-frequency=30s \
                --pod-infra-container-image=k8s.gcr.io/pause-amd64:3.0 \
                --resolv-conf=/etc/resolv.conf \
                --rotate-certificates&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;54-创建-calico-daemonset&quot;&gt;5.4 创建 Calico Daemonset&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 先创建 RBAC
kubectl apply -f \
https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/rbac.yaml

# 再创建 Calico Daemonset
kubectl create -f calico.yaml

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;55-启动-calico-node&quot;&gt;5.5 启动 Calico Node&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;systemctl daemon-reload
systemctl restart calico-node
systemctl enable calico-node

# 等待 20s 拉取镜像, 可以提前将镜像拉取
sleep 20
systemctl restart kubelet
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;56-测试网络&quot;&gt;5.6 测试网络&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 创建 deployment
cat &amp;lt;&amp;lt; EOF &amp;gt;&amp;gt; demo.deploy.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: demo-deployment
spec:
  replicas: 5
  selector:
    matchLabels:
      app: demo
  template:
    metadata:
      labels:
        app: demo
    spec:
      containers:
      - name: demo
        image: jevic/demo
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
EOF
kubectl create -f demo.deploy.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;测试结果&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@master219 ~]# kubectl get pod -o wide
NAME                             READY     STATUS    RESTARTS   AGE       IP             NODE
demo-deployment-566fd7b7-fjg7p   1/1       Running   0          3d        10.20.211.67   node220
demo-deployment-566fd7b7-qz5q2   1/1       Running   0          3d        10.20.237.5    master219
demo-deployment-566fd7b7-zzqf9   1/1       Running   0          3d        10.20.206.3    node221
[root@master219 ~]# kubectl exec -it demo-deployment-566fd7b7-fjg7p ping 10.20.206.3
PING 10.20.206.3 (10.20.206.3): 56 data bytes
64 bytes from 10.20.206.3: seq=0 ttl=62 time=0.431 ms
64 bytes from 10.20.206.3: seq=1 ttl=62 time=0.257 ms
64 bytes from 10.20.206.3: seq=2 ttl=62 time=0.246 ms
64 bytes from 10.20.206.3: seq=3 ttl=62 time=0.337 ms
^C
--- 10.20.206.3 ping statistics ---
4 packets transmitted, 4 packets received, 0% packet loss
round-trip min/avg/max = 0.246/0.317/0.431 ms
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;六-部署dns&quot;&gt;六. 部署DNS&lt;/h2&gt;
&lt;h3 id=&quot;61-修改配置文件&quot;&gt;6.1 修改配置文件&lt;/h3&gt;
&lt;p&gt;将下载的 kubernetes-server-linux-amd64.tar.gz 解压后，再解压其中的 kubernetes-src.tar.gz 文件。
coredns 对应的目录是：&lt;code class=&quot;highlighter-rouge&quot;&gt;cluster/addons/dns&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# diff coredns.yaml coredns.yaml.base
61c61
&amp;lt;         kubernetes cluster.local. in-addr.arpa ip6.arpa {
---
&amp;gt;         kubernetes __PILLAR__DNS__DOMAIN__ in-addr.arpa ip6.arpa {
103c103
&amp;lt;         image: k8s.jevic.cn/k8s.gcr.io/coredns:1.0.6
---
&amp;gt;         image: k8s.gcr.io/coredns:1.0.6
153c153
&amp;lt;   clusterIP: 10.254.0.2
---
&amp;gt;   clusterIP: __PILLAR__DNS__SERVER__
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;62-检查coredns&quot;&gt;6.2 检查coredns&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# kubectl get pod -n kube-system  |grep dns
coredns-787558c684-6tlwj                   1/1       Running   0          3d
coredns-787558c684-t4h6j                   1/1       Running   0          3d

# kubectl exec -it demo-deployment-566fd7b7-qz5q2 bash
bash-4.4# nslookup kubernetes
nslookup: can't resolve '(null)': Name does not resolve

Name:      kubernetes
Address 1: 10.254.0.1 kubernetes.default.svc.cluster.local

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;63-dns-自动扩容&quot;&gt;6.3 DNS 自动扩容&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.10.md#downloads-for-v11010&quot;&gt;下载源码文件&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;文件路径: kubernetes/kubernetes-src1.10.1/cluster/addons/dns-horizontal-autoscaler&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create -f dns-horizontal-autoscaler.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;七-dashboard&quot;&gt;七. Dashboard&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;wget https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml -O kubernetes-dashboard.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;71-配置端口&quot;&gt;7.1 配置端口&lt;/h3&gt;

&lt;p&gt;便于访问配置为: NodePort, 最后的修改部分如下&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# ------------------- Dashboard Service ------------------- #

kind: Service
apiVersion: v1
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
  namespace: kube-system
spec:
  type: NodePort
  ports:
    - name: dashboard-tls
      port: 443
      targetPort: 8443
      nodePort: 30000
      protocol: TCP
  selector:
    k8s-app: kubernetes-dashboard
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;执行 kubectl create -f kubernetes-dashboard.yaml 创建即可&lt;/p&gt;

&lt;h3 id=&quot;72-创建admin-账户&quot;&gt;7.2 创建Admin 账户&lt;/h3&gt;

&lt;p&gt;默认情况下部署成功后可以直接访问 https://NODE_IP:30000 访问，但是想要登录进去查看的话需要使用 kubeconfig 或者 access token 的方式；实际上这个就是 RBAC 授权控制，以下提供一个创建 admin access token 的脚本，更细节的权限控制比如只读用户可以参考&lt;a href=&quot;https://kubernetes.io/docs/reference/access-authn-authz/rbac/#rolebinding-and-clusterrolebinding&quot;&gt;官方文档&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if &lt;/span&gt;kubectl get sa dashboard-admin &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; kube-system &amp;amp;&amp;gt; /dev/null&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;then
    &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[33mWARNING: ServiceAccount dashboard-admin exist!&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;else
    &lt;/span&gt;kubectl create sa dashboard-admin &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; kube-system
    kubectl create clusterrolebinding dashboard-admin &lt;span class=&quot;nt&quot;&gt;--clusterrole&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;cluster-admin &lt;span class=&quot;nt&quot;&gt;--serviceaccount&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;kube-system:dashboard-admin
&lt;span class=&quot;k&quot;&gt;fi

&lt;/span&gt;kubectl describe secret &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; kube-system &lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;kubectl get secrets &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; kube-system | &lt;span class=&quot;nb&quot;&gt;grep &lt;/span&gt;dashboard-admin | cut &lt;span class=&quot;nt&quot;&gt;-f1&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;' '&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-E&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'^token'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;成功后访问如下(如果访问不了的话请检查下 iptable FORWARD 默认规则是否为 DROP，如果是将其改为 ACCEPT 即可)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/kubernetes/kubernetes-dashboard-sa.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/kubernetes/kubernetes-dashboard.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;八-部署-heapster&quot;&gt;八. 部署 heapster&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/kubernetes/heapster/blob/master/docs/influxdb.md&quot;&gt;官方说明&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;git clone https://github.com/kubernetes/heapster.git&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;81-grafana-nodeport&quot;&gt;8.1 grafana NodePort&lt;/h3&gt;
&lt;p&gt;在&lt;a href=&quot;https://github.com/kubernetes/heapster/blob/master/docs/influxdb.md&quot;&gt;官方部署说明&lt;/a&gt;中已经有提示,需要将grafana改为NodePort 进而方可使用各节点IP:Port访问，下面列出修改后的配置&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;.... 省略上面部分 .....
apiVersion: v1
kind: Service
metadata:
  labels:
    # For use as a Cluster add-on (https://github.com/kubernetes/kubernetes/tree/master/cluster/addons)
    # If you are NOT using this as an addon, you should comment out this line.
    kubernetes.io/cluster-service: 'true'
    kubernetes.io/name: monitoring-grafana
  name: monitoring-grafana
  namespace: kube-system
spec:
  # In a production setup, we recommend accessing Grafana through an external Loadbalancer
  # or through a public IP.
  # type: LoadBalancer
  # You could also use NodePort to expose the service at a randomly-generated port
  type: NodePort
  ports:
  - name: grafana-web  ## 自定义
    port: 80
    targetPort: 3000
    nodePort: 30001 ## 30000-50000 自定义
    protocol: TCP
  selector:
    k8s-app: grafana
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;82-执行部署&quot;&gt;8.2 执行部署&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create -f deploy/kube-config/influxdb/
kubectl create -f deploy/kube-config/rbac/heapster-rbac.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;83-查看grafana&quot;&gt;8.3 查看grafana&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;面板需要自己手动添加&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/kubernetes/kubernetes-grafana.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;84-访问dashboard&quot;&gt;8.4 访问Dashboard&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;可以看到界面上面已经显示内存 CPU资源图表&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/kubernetes/kubernetes-dashboard-view01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;九-其他说明&quot;&gt;九. 其他说明:&lt;/h2&gt;
&lt;h3 id=&quot;91-命令行自动补全&quot;&gt;9.1 命令行自动补全&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;source &amp;lt;(kubectl completion bash)
echo &quot;source &amp;lt;(kubectl completion bash)&quot; &amp;gt;&amp;gt; ~/.bashrc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;92-coredns&quot;&gt;9.2 coredns&lt;/h3&gt;

&lt;p&gt;如果配置失败或者报错请检查 /etc/resolv.conf 域名解析配置
另外请确保已经执行了前面初始化关于内核优化的执行部分!!!&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cat /etc/resolv.conf
# Generated by NetworkManager
#search lan
#nameserver 192.168.1.1
nameserver 223.5.5.5
nameserver 8.8.8.8
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;93-gcr-镜像被墙&quot;&gt;9.3 GCR 镜像被墙&lt;/h3&gt;
&lt;p&gt;默认kubernetes 镜像被托管在Google仓库无法被正常获取,使用开源社区镜像仓库Pull 即可
建议再即将部署前将所有用到的镜像提前pull 下来.
参考&lt;a href=&quot;https://www.jevic.cn/2018/05/25/mirror/&quot;&gt;GCR Google Container Registry 镜像&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;94-dashboard&quot;&gt;9.4 dashboard&lt;/h3&gt;
&lt;p&gt;直接使用kubernetes-src 里面的yaml文件创建即可,记得修改NodePort&lt;/p&gt;

&lt;h3 id=&quot;95-heapster&quot;&gt;9.5 heapster&lt;/h3&gt;
&lt;p&gt;同样直接使用github 官方提供的说明配置即可.无需再百度或者Google其他配置范例.&lt;/p&gt;

&lt;h3 id=&quot;96-善用帮助命令&quot;&gt;9.6 善用帮助命令&lt;/h3&gt;

&lt;p&gt;kubernetes 有着简单易用非常清晰明了的帮助提示命令,这点是绝对备受一致好评的;&lt;/p&gt;

&lt;p&gt;–help 不会哪里就help 哪里&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl expose --help
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;不会写yaml ? 没有关系使用下面这个命令即可获取资源定义帮助
使用’.’ 分割逐级查看各对象的使用方法&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## 例如这里获取pod 关于spec 的资源定义帮助信息
kubectl explain pod.spec
## 获取pod资源中containers的定义
kubectl explain pod.spec.containers
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;提示: 在帮助信息的最下方也会显示出此命令或资源定义的官网详细文档链接地址,查看官方文档可更快的帮助你理解和学习!!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;十-参考链接&quot;&gt;十. 参考链接&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://mritd.me/2018/04/19/set-up-kubernetes-1.10.1-cluster-by-hyperkube/&quot;&gt;set-up-kubernetes-1.10.1-cluster-by-hyperkube&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://k8s-install.opsnull.com/&quot;&gt;https://k8s-install.opsnull.com&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://kubernetes.feisky.xyz/&quot;&gt;https://kubernetes.feisky.xyz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Jevic</name></author><summary type="html">通读一遍先熟悉了过程在实际操作!!!</summary></entry><entry><title type="html">elasticsearch templates 模板配置</title><link href="http://0.0.0.0/2018/08/25/elasticsearch-templates/" rel="alternate" type="text/html" title="elasticsearch templates 模板配置" /><published>2018-08-25T16:42:16+08:00</published><updated>2018-08-25T16:42:16+08:00</updated><id>http://0.0.0.0/2018/08/25/elasticsearch-templates</id><content type="html" xml:base="http://0.0.0.0/2018/08/25/elasticsearch-templates/">&lt;h2 id=&quot;动态模板加载&quot;&gt;动态模板加载&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
  &quot;order&quot;: 0,
  &quot;template&quot;: &quot;api-*&quot;,
  &quot;settings&quot;: {
    &quot;index&quot;: {
      &quot;number_of_shards&quot;: &quot;2&quot;,
      &quot;number_of_replicas&quot;: &quot;1&quot;,
      &quot;refresh_interval&quot;: &quot;60s&quot;
    }
  },
  &quot;mappings&quot;: {
    &quot;_default_&quot;: {
      &quot;dynamic_templates&quot;: [
        {
          &quot;message_field&quot;: {
            &quot;mapping&quot;: {
              &quot;fielddata&quot;: {
                &quot;format&quot;: &quot;disabled&quot;
              },
              &quot;index&quot;: &quot;not_analyzed&quot;,
              &quot;omit_norms&quot;: true,
              &quot;type&quot;: &quot;string&quot;
            },
            &quot;match_mapping_type&quot;: &quot;string&quot;,
            &quot;match&quot;: &quot;message&quot;
          }
        },
        {
          &quot;string_fields&quot;: {
            &quot;mapping&quot;: {
              &quot;fielddata&quot;: {
                &quot;format&quot;: &quot;disabled&quot;
              },
              &quot;index&quot;: &quot;not_analyzed&quot;,
              &quot;omit_norms&quot;: true,
              &quot;type&quot;: &quot;string&quot;,
              &quot;fields&quot;: {
                &quot;raw&quot;: {
                  &quot;ignore_above&quot;: 256,
                  &quot;index&quot;: &quot;not_analyzed&quot;,
                  &quot;type&quot;: &quot;string&quot;
                }
              }
            },
            &quot;match_mapping_type&quot;: &quot;string&quot;,
            &quot;match&quot;: &quot;*&quot;
          }
        }
      ],
      &quot;_all&quot;: {
        &quot;omit_norms&quot;: true,
        &quot;enabled&quot;: false
      },
      &quot;properties&quot;: {
        &quot;args&quot;: {
          &quot;index&quot;: &quot;not_analyzed&quot;,
          &quot;type&quot;: &quot;string&quot;
        },
        &quot;@timestamp&quot;: {
          &quot;type&quot;: &quot;date&quot;
        },
        &quot;request_time&quot;: {
          &quot;index&quot;: &quot;not_analyzed&quot;,
          &quot;type&quot;: &quot;float&quot;
        },
        &quot;status&quot;: {
          &quot;index&quot;: &quot;not_analyzed&quot;,
          &quot;type&quot;: &quot;long&quot;
        }
      }
    }
  },
  &quot;aliases&quot;: {}
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;mapping&quot;&gt;mapping&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;适用于&amp;lt;6.x 版本&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
  &quot;order&quot;: 0,
  &quot;template&quot;: &quot;test-*&quot;,
  &quot;settings&quot;: {
    &quot;index&quot;: {
      &quot;number_of_shards&quot;: &quot;3&quot;,
      &quot;number_of_replicas&quot;: &quot;1&quot;,
      &quot;refresh_interval&quot;: &quot;60s&quot;
    }
  },
  &quot;mappings&quot;: {
    &quot;test1&quot;: {
      &quot;properties&quot;: {
        &quot;ext&quot;: {
          &quot;index&quot;: &quot;not_analyzed&quot;,
          &quot;type&quot;: &quot;string&quot;
        },
        &quot;id&quot;: {
          &quot;index&quot;: &quot;not_analyzed&quot;,
          &quot;type&quot;: &quot;string&quot;
        }
      }
    },
    &quot;test2&quot;: {
      &quot;properties&quot;: {
        &quot;ext&quot;: {
          &quot;index&quot;: &quot;not_analyzed&quot;,
          &quot;type&quot;: &quot;string&quot;
        },
        &quot;status&quot;: {
          &quot;index&quot;: &quot;not_analyzed&quot;,
          &quot;type&quot;: &quot;long&quot;
        }
      }
    }
  },
  &quot;aliases&quot;: {}
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;转载请注明出处，本文采用 &lt;a href=&quot;http://creativecommons.org/licenses/by-nc-nd/4.0/&quot;&gt;CC4.0&lt;/a&gt; 协议授权&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">动态模板加载</summary></entry></feed>