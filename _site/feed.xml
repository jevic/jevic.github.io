<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="http://0.0.0.0/feed.xml" rel="self" type="application/atom+xml" /><link href="http://0.0.0.0/" rel="alternate" type="text/html" /><updated>2018-11-23T16:36:57+08:00</updated><id>http://0.0.0.0/</id><title type="html">Jevic</title><subtitle>前路漫漫,忆往昔......</subtitle><author><name>Jevic</name></author><entry><title type="html">elastic-stack 6.5</title><link href="http://0.0.0.0/2018/11/22/elastic-stack-6.5/" rel="alternate" type="text/html" title="elastic-stack 6.5" /><published>2018-11-22T19:56:06+08:00</published><updated>2018-11-22T19:56:06+08:00</updated><id>http://0.0.0.0/2018/11/22/elastic-stack-6.5</id><content type="html" xml:base="http://0.0.0.0/2018/11/22/elastic-stack-6.5/">&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;在以往的旧版本(2.x,5.x) 每个索引可以存储不同类型的文档,
      &lt;ul&gt;
        &lt;li&gt;类比MySQL
          &lt;ul&gt;
            &lt;li&gt;index == database&lt;/li&gt;
            &lt;li&gt;_type == table&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;6.x 版本开始 移除了_type  也就是每个索引只有一种类型！！！&lt;/li&gt;
    &lt;li&gt;x-pack 从6.3版本开始已经内置在elasticsearch,kibana 当中无需另行安装!&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;elasticsearch&quot;&gt;elasticsearch&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.elastic.co/downloads&quot;&gt;官网下载&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;下载解压&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;配置基础环境&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# cat /etc/security/limit.conf
* soft nofile 65536
* hard nofile 65536
* soft nproc unlimited
* hard nproc unlimited
es soft memlock unlimited
es hard memlock unlimited
  
# cat /etc/sysctl.conf
vm.swappiness = 1
vm.max_map_count=262144
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;添加 es 用户并授权&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;启动&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;授权 license （30天试用版）&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;证书申请: https://register.elastic.co/marvel_register&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -H &quot;Content-Type:application/json&quot; -XPOST  http://192.168.2.221:9200/_xpack/license/start_trial?acknowledge=true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;x-pack-开启认证&quot;&gt;x-pack 开启认证&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;配置用户名密码:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;$ES_PATH:/bin/elasticsearch-setup-passwords interactive&lt;/li&gt;
      &lt;li&gt;根据提示一步步设置密码即可&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改 elasticsearch 配置文件&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# tail elasticsearch.yml -n 1
xpack.security.enabled: true  ## 开启认证
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;重启ES，再次访问则需要输入用户名密码&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改密码&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -H &quot;Content-Type:application/json&quot; -XPOST -u elastic 'http://192.168.2.221:9200/_xpack/security/user/elastic/_password' -d '{ &quot;password&quot; : &quot;123456&quot; }'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;kibana&quot;&gt;kibana&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;配置对应的用户名密码以及 ES 链接地址&lt;/li&gt;
  &lt;li&gt;配置文件添加此配置:
    &lt;ul&gt;
      &lt;li&gt;xpack.security.enabled: true&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;启动即可&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;cerebro&quot;&gt;cerebro&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/lmenezes/cerebro&quot;&gt;github&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;具体步骤查看文档即可&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sql-插件&quot;&gt;sql 插件&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/NLPchina/elasticsearch-sql&quot;&gt;github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;转载请注明出处，本文采用 &lt;a href=&quot;http://creativecommons.org/licenses/by-nc-nd/4.0/&quot;&gt;CC4.0&lt;/a&gt; 协议授权&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">在以往的旧版本(2.x,5.x) 每个索引可以存储不同类型的文档, 类比MySQL index == database _type == table 6.x 版本开始 移除了_type 也就是每个索引只有一种类型！！！ x-pack 从6.3版本开始已经内置在elasticsearch,kibana 当中无需另行安装!</summary></entry><entry><title type="html">elasticsearch templates 模板配置</title><link href="http://0.0.0.0/2018/08/25/elasticsearch-templates/" rel="alternate" type="text/html" title="elasticsearch templates 模板配置" /><published>2018-08-25T16:42:16+08:00</published><updated>2018-08-25T16:42:16+08:00</updated><id>http://0.0.0.0/2018/08/25/elasticsearch-templates</id><content type="html" xml:base="http://0.0.0.0/2018/08/25/elasticsearch-templates/">&lt;h2 id=&quot;动态模板加载&quot;&gt;动态模板加载&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
  &quot;order&quot;: 0,
  &quot;template&quot;: &quot;api-*&quot;,
  &quot;settings&quot;: {
    &quot;index&quot;: {
      &quot;number_of_shards&quot;: &quot;2&quot;,
      &quot;number_of_replicas&quot;: &quot;1&quot;,
      &quot;refresh_interval&quot;: &quot;60s&quot;
    }
  },
  &quot;mappings&quot;: {
    &quot;_default_&quot;: {
      &quot;dynamic_templates&quot;: [
        {
          &quot;message_field&quot;: {
            &quot;mapping&quot;: {
              &quot;fielddata&quot;: {
                &quot;format&quot;: &quot;disabled&quot;
              },
              &quot;index&quot;: &quot;not_analyzed&quot;,
              &quot;omit_norms&quot;: true,
              &quot;type&quot;: &quot;string&quot;
            },
            &quot;match_mapping_type&quot;: &quot;string&quot;,
            &quot;match&quot;: &quot;message&quot;
          }
        },
        {
          &quot;string_fields&quot;: {
            &quot;mapping&quot;: {
              &quot;fielddata&quot;: {
                &quot;format&quot;: &quot;disabled&quot;
              },
              &quot;index&quot;: &quot;not_analyzed&quot;,
              &quot;omit_norms&quot;: true,
              &quot;type&quot;: &quot;string&quot;,
              &quot;fields&quot;: {
                &quot;raw&quot;: {
                  &quot;ignore_above&quot;: 256,
                  &quot;index&quot;: &quot;not_analyzed&quot;,
                  &quot;type&quot;: &quot;string&quot;
                }
              }
            },
            &quot;match_mapping_type&quot;: &quot;string&quot;,
            &quot;match&quot;: &quot;*&quot;
          }
        }
      ],
      &quot;_all&quot;: {
        &quot;omit_norms&quot;: true,
        &quot;enabled&quot;: false
      },
      &quot;properties&quot;: {
        &quot;args&quot;: {
          &quot;index&quot;: &quot;not_analyzed&quot;,
          &quot;type&quot;: &quot;string&quot;
        },
        &quot;@timestamp&quot;: {
          &quot;type&quot;: &quot;date&quot;
        },
        &quot;request_time&quot;: {
          &quot;index&quot;: &quot;not_analyzed&quot;,
          &quot;type&quot;: &quot;float&quot;
        },
        &quot;status&quot;: {
          &quot;index&quot;: &quot;not_analyzed&quot;,
          &quot;type&quot;: &quot;long&quot;
        }
      }
    }
  },
  &quot;aliases&quot;: {}
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;mapping&quot;&gt;mapping&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;适用于&amp;lt;6.x 版本&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
  &quot;order&quot;: 0,
  &quot;template&quot;: &quot;test-*&quot;,
  &quot;settings&quot;: {
    &quot;index&quot;: {
      &quot;number_of_shards&quot;: &quot;3&quot;,
      &quot;number_of_replicas&quot;: &quot;1&quot;,
      &quot;refresh_interval&quot;: &quot;60s&quot;
    }
  },
  &quot;mappings&quot;: {
    &quot;test1&quot;: {
      &quot;properties&quot;: {
        &quot;ext&quot;: {
          &quot;index&quot;: &quot;not_analyzed&quot;,
          &quot;type&quot;: &quot;string&quot;
        },
        &quot;id&quot;: {
          &quot;index&quot;: &quot;not_analyzed&quot;,
          &quot;type&quot;: &quot;string&quot;
        }
      }
    },
    &quot;test2&quot;: {
      &quot;properties&quot;: {
        &quot;ext&quot;: {
          &quot;index&quot;: &quot;not_analyzed&quot;,
          &quot;type&quot;: &quot;string&quot;
        },
        &quot;status&quot;: {
          &quot;index&quot;: &quot;not_analyzed&quot;,
          &quot;type&quot;: &quot;long&quot;
        }
      }
    }
  },
  &quot;aliases&quot;: {}
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;转载请注明出处，本文采用 &lt;a href=&quot;http://creativecommons.org/licenses/by-nc-nd/4.0/&quot;&gt;CC4.0&lt;/a&gt; 协议授权&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">动态模板加载</summary></entry><entry><title type="html">Kubeadm 快速部署kubernetes 1.10.1</title><link href="http://0.0.0.0/2018/07/17/kubeadm-kubernetes1.10.1/" rel="alternate" type="text/html" title="Kubeadm 快速部署kubernetes 1.10.1" /><published>2018-07-17T20:35:46+08:00</published><updated>2018-07-17T20:35:46+08:00</updated><id>http://0.0.0.0/2018/07/17/kubeadm-kubernetes1.10.1</id><content type="html" xml:base="http://0.0.0.0/2018/07/17/kubeadm-kubernetes1.10.1/">&lt;h2 id=&quot;系统环境&quot;&gt;系统环境&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;IP地址&lt;/th&gt;
      &lt;th&gt;主机名&lt;/th&gt;
      &lt;th&gt;Docker 版本&lt;/th&gt;
      &lt;th&gt;kubernetes 版本&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;192.168.2.65&lt;/td&gt;
      &lt;td&gt;k1.master&lt;/td&gt;
      &lt;td&gt;17.03.1-ce&lt;/td&gt;
      &lt;td&gt;v1.10.1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;192.168.2.66&lt;/td&gt;
      &lt;td&gt;k2.master&lt;/td&gt;
      &lt;td&gt;17.03.1-ce&lt;/td&gt;
      &lt;td&gt;v1.10.1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;192.168.2.67&lt;/td&gt;
      &lt;td&gt;k3.master&lt;/td&gt;
      &lt;td&gt;17.03.1-ce&lt;/td&gt;
      &lt;td&gt;v1.10.1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;初始化&quot;&gt;初始化&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;所有节点执行&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@k1 ~]# setenforce 0
[root@k1 ~]# sed -i 's/SELINUX=enforcing/SELINUX=disalbe/g' /etc/sysconfig/selinux

[root@k1 ~]# cat &amp;gt;&amp;gt; /etc/security/limits.conf &amp;lt;&amp;lt;EOF
* soft nofile 65536
* hard nofile 65536
* soft nproc unlimited
* hard nproc unlimited
EOF

[root@k1 ~]# swapoff -a

[root@k1 ~]# cat &amp;gt;&amp;gt; /etc/sysctl.conf &amp;lt;&amp;lt;EOF
net.bridge.bridge-nf-call-iptables=1
net.bridge.bridge-nf-call-ip6tables=1
net.ipv4.ip_forward=1
net.ipv4.tcp_tw_recycle=0
vm.swappiness=0
vm.overcommit_memory=1
vm.panic_on_oom=0
fs.inotify.max_user_watches=89100
fs.file-max=52706963
fs.nr_open=52706963
net.ipv6.conf.all.disable_ipv6=1
net.netfilter.nf_conntrack_max=2310720
EOF

[root@k1 ~]# systemctl stop firewalld &amp;amp;&amp;amp; systemctl disable firewalld

[root@k1 ~]# wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo

[root@k1 ~]# yum makecache fast
[root@k1 ~]# yum install -y epel-release
[root@k1 ~]# yum install -y conntrack ipvsadm ipset jq sysstat curl iptables libseccomp ntpdate
[root@k1 ~]# ntpdate cn.pool.ntp.org
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;install-docker&quot;&gt;Install Docker&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;参考 &lt;a href=&quot;https://docs.docker.com/install/linux/docker-ce/centos/#install-using-the-repository&quot;&gt;官方文档&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@k1 ~]# yum install -y yum-utils device-mapper-persistent-data lvm2
[root@k1 ~]# yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
[root@k1 ~]# yum list docker-ce --showduplicates | sort -r
[root@k1 ~]# yum -y install docker-ce-17.03.1.ce
[root@k1 ~]# systemctl start docker &amp;amp;&amp;amp; systemctl stop docker
[root@k1 ~]# cat &amp;gt; /etc/docker/daemon.json &amp;lt;&amp;lt;EOF
{
  &quot;registry-mirrors&quot;: [&quot;https://dlvqhrac.mirror.aliyuncs.com&quot;]
}
EOF
[root@k1 ~]# systemctl daemon-reload
[root@k1 ~]# systemctl start docker

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;kubeadm-组件&quot;&gt;Kubeadm 组件&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;配置阿里云 yum 源&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@k1 ~]# cat &amp;gt; /etc/yum.repos.d/kubernetes.repo &amp;lt;&amp;lt;EOF
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
gpgcheck=0
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
enabled=1
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;安装组件&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@k1 ~]# yum install kubelet kubeadm kubectl

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;初始化-master&quot;&gt;初始化 Master&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;镜像
    &lt;ul&gt;
      &lt;li&gt;出于不可描述的原因获取镜像会遇到困难&lt;/li&gt;
      &lt;li&gt;从Docker hub FROM 官方镜像再从自己镜像仓库拉取即可&lt;/li&gt;
      &lt;li&gt;具体操作细节在此忽略&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;修改配置&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@k1 ~]# cat /etc/sysconfig/kubelet
KUBELET_EXTRA_ARGS=&quot;--fail-swap-on=false&quot;
KUBE_PROXY_MODE=ipvs,ip_vs,ip_vs_rr,ip_vs_wrr,ip_vs_sh,nf_conntrack_ipv4

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;初始化&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@k1 ~]# kubeadm init --kubernetes-version=v1.10.1 --pod-network-cidr=10.20.0.0/16 --apiserver-advertise-address=192.168.2.65

记录最后的节点初始化信息，添加节点即可 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;添加flannel网络插件
    &lt;ul&gt;
      &lt;li&gt;https://github.com/coreos/flannel&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;查看集群状态&quot;&gt;查看集群状态&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@k1 ~]# kubectl get node
NAME        STATUS   ROLES    AGE     VERSION
k1.master   Ready    master   2d14h   v1.10.1
k2.master   Ready    &amp;lt;none&amp;gt;   2d14h   v1.10.1
k3.master   Ready    &amp;lt;none&amp;gt;   2d14h   v1.10.1

[root@k1 ~]# kubectl get pod -n kube-system
NAME                                READY   STATUS             RESTARTS   AGE
etcd-k1.master                      1/1     Running            2          2d14h
kube-apiserver-k1.master            1/1     Running            5          2d14h
kube-controller-manager-k1.master   1/1     Running            4          2d14h
kube-flannel-ds-amd64-9xzfl         1/1     Running            2          2d14h
kube-flannel-ds-amd64-krc4l         1/1     Running            1          2d14h
kube-flannel-ds-amd64-phhc7         1/1     Running            2          2d14h
kube-proxy-4vndk                    1/1     Running            3          2d14h
kube-proxy-f4dqb                    1/1     Running            2          2d14h
kube-proxy-s6p9z                    1/1     Running            2          2d14h
kube-scheduler-k1.master            1/1     Running            4          2d14h

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;转载请注明出处，本文采用 &lt;a href=&quot;http://creativecommons.org/licenses/by-nc-nd/4.0/&quot;&gt;CC4.0&lt;/a&gt; 协议授权&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">系统环境</summary></entry><entry><title type="html">CDN 厂商选择三要素</title><link href="http://0.0.0.0/2018/06/10/cdn-choice/" rel="alternate" type="text/html" title="CDN 厂商选择三要素" /><published>2018-06-10T20:25:16+08:00</published><updated>2018-06-10T20:25:16+08:00</updated><id>http://0.0.0.0/2018/06/10/cdn-choice</id><content type="html" xml:base="http://0.0.0.0/2018/06/10/cdn-choice/">&lt;blockquote&gt;
  &lt;p&gt;作为技术决策者在选择使用 CDN 服务时最关心的三个问题是：&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;一，哪家的 CDN 更快（速度快，用户体验好）。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;二， 哪家 CDN 功能最全，即使现在用不到也不会给将来业务发展挖坑。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;三，怎么付费最划算。本文通过分析对国内 CDN 市场占有率靠前的十家服务商的网络环境和技术服务，希望给大家提供一些启发和建议。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.idcps.com/idc/china/cdn&quot;&gt;IDC 评述网&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;哪家的-cdn-更快&quot;&gt;哪家的 CDN 更快？&lt;/h2&gt;

&lt;p&gt;CDN 服务商经常引用独立第三方公司的拨测数据来证明自己的 CDN 服务更好。虽然这些数据在某个区域或时间段也许是准确的，实际却是盲人摸象，无法证明全时段和全网 CDN 服务的真实性能。也许从 CDN 服务商所处的网络环境和提供的技术功能入手，会是更科学和公平的对比方法。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;阿里云，腾讯云和网宿科技由于支持 HttpDNS 在技术上有领先优势，可以列为第一梯队。第二梯队的是百度云，蓝讯，Ucloud 和网易云。它们所在 AS 和两个以上运营商主干网 AS 相邻，也具有一定优势。剩下的金山云，七牛云和京东云排在第三梯队。金山云所在 AS 只和电信骨干网 AS 相连，使用其它运营商的用户访问其 CDN 节点理论上会相对电信的慢一些。七牛云和京东云其网络属于北京电信通的 AS，需要穿过两个 AS 才接入骨干网，理论上速度也会比其他 CDN 服务商稍慢。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;国内用户普遍使用互联网提供商 (ISP) 的宽带上网，具体访问流程如下图：
&lt;img src=&quot;http://ok6h8mla5.bkt.clouddn.com/cdn_wx01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;用户终端访问 CDN 的过程分两个步骤;
一是用户通过 DNS 找到最近的 CDN 边缘节点 IP; 
二是数据在网络中的送达用户终端。
整个过程中，有三个方面会影响用户访问 CDN 的体验。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h5 id=&quot;一拥有-dns-优化策略的-cdn-提供商会有更好的用户体验&quot;&gt;一，拥有 DNS 优化策略的 CDN 提供商，会有更好的用户体验。&lt;/h5&gt;

&lt;p&gt;从图 1 可见， 客户终端的 DNS Resolver 负责告诉浏览器到哪里去找 CDN 的资源。理论上 ISP 的 DNS 服务器会选择离用户最近 CDN 节点 IP 并返回给用户，但是实际情况并不是这么简单。国内的大城市的 ISP 业务，除了一些区域性的 ISP，基本被联通、电信和移动这样的大运营商所垄断。由于各运营商之间存在着网间费用结算，运营商会想尽一切办法将用户的访问在自己的网内解决掉。比如，广州联调宽带的用户想访问的内容在联通北京的 CDN 节点， 尽管在广东移动的 CDN 节点有用户想访问的资源，联通的 DNS 还是会返回联通北京 CDN 节点的 IP。&lt;/p&gt;

&lt;p&gt;另外，一些 ISP 为了节省网间流量，未经 CDN 服务商同意，自己针对一些 CDN 文件做了一层 CDN 缓存，通过“DNS 劫持”把用户访问 CDN 资源的请求都指到自己网内的非法 CDN 缓存服务器。很多时候这些缓存的内容不能及时和 CDN 节点同步更新，会造成使用该 ISP 的用户终端出现访问 CDN 资源缓慢，失败等现象。同时，国内严重的 DNS 污染问题也影响了用户的上网体验。&lt;/p&gt;

&lt;p&gt;因此，如果能使用一些技术优化用户 DNS 查询，会大幅度提高用户的体验。目前优化 DNS 的技术主要是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;HttpDNS ：客户端基于 Http 协议向 CDN 服务商指定的 DNS 服务器发送域名解析请求，从而避免 LocalDNS 造成的域名劫持和跨网访问;
&lt;img src=&quot;http://ok6h8mla5.bkt.clouddn.com/cdn_wx02.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Http 302 跳转: CDN 厂商维护 CDN 域名 IP 库，根据用户访问终端的 IP 和 CDN 边缘节点的状态，选择最合适的 CDN 节点，发出 HTTP 的 302 返回码，将用户的请求跳转到合适的 CDN 边缘节点。例如腾讯的下载直通车就使用类似技术。
&lt;img src=&quot;http://ok6h8mla5.bkt.clouddn.com/cdn_wx02.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;二拥有自治系统autonomous-system-as的-cdn-提供商数据包跨越最少的网络边界能获得更快的传输速度&quot;&gt;二，拥有自治系统（Autonomous system, AS）的 CDN 提供商，数据包跨越最少的网络边界，能获得更快的传输速度。&lt;/h5&gt;

&lt;p&gt;在 BGP 协议中，IP 包从一个 AS 向另一个 AS 传输时，需要经过边界路由器，如果由于网络问题造成 IP 包不可达，则需要边界路由器重新规划线路。如果 CDN 服务商自己拥有自治系统，AS 内部拥有同样的选路策略，数据就能在 CDN 服务商自己的 AS 中高效传输，理论上最终送达用户所花的时间也会最小。 就好比我们开车在省内玩，肯定要比跨多个省经过多个收费站耗时要少。&lt;/p&gt;

&lt;h5 id=&quot;三-cdn-服务商所在自治系统-as-的相邻-as-越多离运营商骨干网越近数据传输也会更有优势&quot;&gt;三， CDN 服务商所在自治系统 AS 的相邻 AS 越多，离运营商骨干网越近，数据传输也会更有优势。&lt;/h5&gt;

&lt;p&gt;CDN 服务商所在的 AS 离运营商骨干网 AS 越近，理论上数据包传输所花时间也越少。另外， CDN 厂商如果同时租用了多个运营商品牌的带宽线路，其服务器的 IP 就会同时属于这几家运营商的 AS，跨运营商的数据传输时间也会比只有一个运营商的相对快些。就如同有多个高速公路的通行证，数据在传输过程中从一家的路面后就可直达用户，而不用来回在多个道路上切换，避免了不必要的时间损耗。&lt;/p&gt;

&lt;h2 id=&quot;哪家-cdn-功能最全&quot;&gt;哪家 CDN 功能最全&lt;/h2&gt;

&lt;p&gt;CDN 服务的功能点非常多，为了比较方便选择了 11 个常用的功能，主要覆盖加速优化，监控和安全三个方面：&lt;/p&gt;

&lt;h4 id=&quot;加速优化&quot;&gt;加速优化&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;HTTP2.0 加速&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;HTTP2.0 和现在的 HTTP1.1 相比，做了很大的改动和优化，例如头部压缩、服务端推送等。因为它要求服务器端和浏览器端都得支持 HTTP2.0 协议，所以在国内获得普遍支持还有一段时间。不过作为互联网下一代 HTTP 协议，即使我们现在用不上，也应考虑为将来的系统升级留下余地。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;文件压缩&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;目前 CDN 节点使用的 WEB 服务器端普遍支持 GZIP 协议的压缩， 当用户浏览器访问静态资源，并且支持 Gzip 压缩时， 服务器端可以把资源压缩打包发送给浏览器，由浏览器进行解压， 减少文件在互联网传输的数据量和时间。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;源站推送&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为了避免传统的 CDN 节点同时去源站拉数据，造成访问洪峰压垮源站的带宽和服务器。 CDN 厂商使用源站推送功能将源站内容提前推送给边缘 CDN 节点，提前进行刷新预热。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;点播加速&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CDN 对音视频等流媒体文件进行加速，其背后是一套复杂的技术方案，包括上传，转码，分发，以及 CDN 边缘节点根据用户终端支持协议的情况下发合适的流媒体格式。不同 CDN 服务商对点播加速的技术实现方案不同，不好做量化比较，只用是否支持播加速功能来比较。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;直播加速&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;直播加速如何解决播放延时、连麦时多路音视频的合并、以及突发热点对带宽的冲击等这些技术挑战，对 CDN 服务商的技术、硬件和网络条件都有很高的要求。也用是否支持直播加速来比较。&lt;/p&gt;

&lt;h4 id=&quot;监控统计&quot;&gt;监控统计&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;实时监控&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CDN 服务商提供图形化工具，对 CDN 的使用情况，例如点击量，命中率，公网下行流量等进行统计和监控。方便客户对于 CDN 使用效率和结果进行评估，及时发现问题和调整网络带宽预算。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;原始日志&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;提供所有客户终端访问 CDN 服务的原始日志 (access log)，这些日志看似没用，其实很有价值。例如，可以通过分析原始日志的数据包总量估算出 CDN 实际的下行流量，作为支付 CDN 服务费的参考。也可以通过分析这些日志的响应时间，结合客户端 IP，评估各地区终端用户实际访问 CDN 的情况&lt;/p&gt;

&lt;h4 id=&quot;安全&quot;&gt;安全&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;防盗链&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CDN 服务商防盗链的手段很多，例如常用的 http Referer 防盗链，其原理是利用 http header 中的 referer 属性，判断用户提交信息的网站 IP 地址，然后和真正的源站端的地址相比较，如果一致则表明是站内提交，或者为自己信任的站点提交，否则视为盗链。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;IP 黑白名单&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;黑白名单是我们可以根据业务需要对用户请求的源 IP 访问进行管理，为我们提供了主动防御的能力。使用 IP 黑名单的功能，可以有效的帮助我们阻止盗链，和恶意攻击。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;SNI （ 服务器名称指示 Server Name Indication ）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;网站使用 SSL/TSL 协议校验是目前防止盗链，和解决 “DNS 劫持”最好的方式。目前国内外大型网站都已经换成了基于该协议的 HTTPS 通信方式。早期的 SSL 协议默认每个 IP 地址上只能用一个证书。TLSv1z 增加了服务器名称指示（SNI）功能，通过发送虚拟主机名作为 TLS 协商的一部分这使得服务器可以在握手阶段选择正确虚拟域，并发送对应证书。这样每个 IP 上可以部署多张证书，对于运行很多虚机和域名的用户会非常节省资源。如果 CDN 服务商支持该项功能，说明 CDN 服务支持 HTTPS 和 TSL v1 以上版本。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;OCSP 装订（OCSP STAPLING）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;使用 SSL 认证时，客户端会在 TLS 握手阶段，去发证机构对实时查询 OCSP （Online Certificate Status Protocol，在线证书状态协议）接口，来判断服务器端的证书是否作废。在获得获得 OCSP 结果前会阻塞后续流程，通常发证机构都在国外，客户端的访问会延迟整个 TLS 握手的时间。而 OCSP Stapling 功能，是指服务端在证书链中封装了发证书机构对证书的 OCSP 查询结果，从而让客户端浏览器跳过自己去验证的过程。如果 CDN 服务商支持该功能，说明其 CDN 服务支持 HTTPS 加速比较好。&lt;/p&gt;

&lt;h4 id=&quot;对比结果&quot;&gt;对比结果&lt;/h4&gt;

&lt;p&gt;对十家 CDN 服务商进行打分，结果如下表：
&lt;img src=&quot;http://ok6h8mla5.bkt.clouddn.com/cdn_wx05.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;腾讯云和网宿科技得分最高，其它厂商各有优劣。 9 分以上的厂商占了前 50%，分别是腾讯云，网宿科技，阿里云，百度云蓝汛。后 50% 的厂商分数在 8-7 分之间。&lt;/p&gt;

&lt;p&gt;转载请注明出处，本文采用 &lt;a href=&quot;http://creativecommons.org/licenses/by-nc-nd/4.0/&quot;&gt;CC4.0&lt;/a&gt; 协议授权&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">作为技术决策者在选择使用 CDN 服务时最关心的三个问题是：</summary></entry><entry><title type="html">分布式系统发展史</title><link href="http://0.0.0.0/2018/06/10/distributed-system/" rel="alternate" type="text/html" title="分布式系统发展史" /><published>2018-06-10T19:55:15+08:00</published><updated>2018-06-10T19:55:15+08:00</updated><id>http://0.0.0.0/2018/06/10/distributed-system</id><content type="html" xml:base="http://0.0.0.0/2018/06/10/distributed-system/">&lt;blockquote&gt;
  &lt;p&gt;分布式系统从最早的数据共享需求，发展到现在的 serverless 架构。它伴随着技术的发展与公司实际需求变化而演进。现在的云服务提供商简化了分布式系统开发的复杂性，让应用开发者只需关注开发，而把基础设施管理交给大型的云服务提供商。回顾分布式系统发展的历史，了解容器技术革新的原动力。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;p&gt;分布式系统（确切地说应该是分布式计算机系统）从它诞生到现在已经过去了很长的时间。在很久以前，一台电脑一次只能完成一项特定的任务。如果我们需要同时完成多项任务，则需要多台计算机并行运行。但是，并行运行并不足以构建真正的分布式系统，因为它需要一种机制来在不同计算机或者那些运行在计算机上的程序之间进行通信。这种在多台计算机之间交换 / 共享数据的需求催生了面向消息通信的想法，即两台计算机使用包含了数据的消息来共享数据。文件共享、数据库共享等其他机制当时还没有出现。
&lt;img src=&quot;http://ok6h8mla5.bkt.clouddn.com/DS_wxp01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;接着，我们进入了多任务操作系统和个人电脑的时代。利用 Windows、Unix、Linux 等操作系统，我们可以在同一台计算机上运行多个任务。这使得分布式系统开发人员能够在一台或者几台通过消息传递连接的计算机内构建和运行整个分布式系统。这催生了面向服务的架构（SOA），其中每个分布式系统可以通过一组集成在一台计算机或多台计算机上运行的服务来构建。我们通过 WSDL（用于 SOAP 协议）或 WADL（用于 REST 协议）等语言适当地定义服务接口。接着，服务的使用者将利用这些接口来进行客户端的实现。
&lt;img src=&quot;http://ok6h8mla5.bkt.clouddn.com/DS_wxp02.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;随着计算能力和存储价格的降低，世界各地的组织都开始使用分布式系统和基于 SOA 的企业 IT 系统。但是，一旦服务或系统的数量增加，这些服务之间的点到点连接就不再是可扩展和可维护的了。这催生了集中式“服务总线”概念的产生。服务总线通过类似集线器的架构将所有系统连接在一起。这个组件被称为 ESB（企业服务总线）。它作为一个“语言”翻译者，就像一个中间人在帮助一群使用不同“语言”但希望相互通信的人进行沟通。在企业应用中，“语言”代表着在通信时不同系统的消息传递协议和消息格式。
&lt;img src=&quot;http://ok6h8mla5.bkt.clouddn.com/DS_wxp03.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这种模式工作得很好，即使在今天也能正常工作。随着万维网的普及和模型的简化，基于 REST 的通信比基于 SOAP 的通信模型变得更加流行。这促进了基于应用程序编程接口（API）的 REST 模型通信的发展。由于 REST 模型的简洁特性，我们需要在标准 REST API 实现之上实现安全（身份验证和授权）、缓存、流控和监控等各种类型的功能。但我们并不想独立地在每个 API 上实现这些功能，而是需要一个公共组件将这些功能应用于这些 API 之上。这样的需求催生了 API 管理平台的发展。现在，它已经成为了任何分布式系统的核心功能之一。
&lt;img src=&quot;http://ok6h8mla5.bkt.clouddn.com/DS_wxp04.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;随后，我们见证了分布式系统大爆炸的时代。Facebook、Google、Amazon、Netflix、LinkedIn、Twitter 等互联网公司变得异常庞大。他们开始想要构建跨越多个地理区域和多个数据中心的分布式系统。这样的需求使他们的技术焦点转向了一切开始的地方。工程师们开始思考单台计算机和单个程序的概念。他们不再把一台计算机当作一台计算机来看，而在同一台计算机内创建多台虚拟计算机。这催生了关于虚拟机的想法，即同一台计算机可以充当多台计算机并且全部并行运行。尽管这是一个还不错的主意，但在宿主计算机的资源利用方面，这并不是最好的选择。运行多个操作系统需要更多的资源，但在同一个操作系统里运行多个程序并不需要这些资源。&lt;/p&gt;

&lt;p&gt;这些问题最终催生了关于容器技术的想法。容器只使用一个宿主操作系统（Linux）的内核，就可以运行多个程序并分别依赖于相互独立的运行时。这个概念在 Linux 操作系统上已经有一段时间了。随着基于容器技术的应用程序部署的普及，它变得更加流行并且有了很多改进和提升。容器可以像虚拟机一样工作，却不需要多一个操作系统的开销。您可以将应用程序和所有相关的依赖项放入容器镜像中。它便可以被放在任何可以运行容器的宿主操作系统中运行。Docker 和 Rocket 是两个热门的容器构建平台。
&lt;img src=&quot;http://ok6h8mla5.bkt.clouddn.com/DS_wxp05.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;容器技术为 Netflix、LinkedIn 和 Twitter 等组织提供了底层框架，用于构建他们要求苛刻的永远在线的多区域、多数据中心应用平台。但这并不意味着利用容器技术没有任何难点。基于容器的部署带来的轻量特性让跨多个容器的平台维护和编排变得非常复杂。随着微服务架构（MSA）的出现，单体式应用程序被分成更小块的微服务。这些微服务能够完成整个服务里的某一个特定功能并部署在容器中（在大多数情况下都可以）。这给分布式系统生态系统带来了一系列新的需求。要让系统最终保持一致，并且彼此之间没有太多复杂的通信。
&lt;img src=&quot;http://ok6h8mla5.bkt.clouddn.com/DS_wxp06.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这些新的需求最终帮助工程师们构建了一个容器编排系统。该系统可用于维护更大规模的容器部署的一致性。毋庸置疑的是，这个领域的顶尖技术来自 Google。因为它们的规模非常大。他们构建了名为“Kubernetes”（又名 k8s）的容器编排平台，并成为大规模容器编排需求的事实标准。k8s 让工程师可以：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在大型集群中运行容器&lt;/li&gt;
  &lt;li&gt;将数据中心视为一台计算机&lt;/li&gt;
  &lt;li&gt;控制服务之间的通信（在容器上运行）&lt;/li&gt;
  &lt;li&gt;动态伸缩与为多个服务进行负载均衡&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Kubernetes 和 Docker 让应用程序员的生活更加轻松。他们不用再考虑他们的应用在不同的环境（操作系统、开发环境、测试环境、生产环境等）下的不同表现。他构建的容器镜像在所有环境中运行表现几乎完全相同，因为所有依赖项都被打包到镜像中了。
&lt;img src=&quot;http://ok6h8mla5.bkt.clouddn.com/DS_wxp07.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但是，尽管我们有了容器和编排框架，我们仍然需要一个管理这些服务器的团队。这意味着数据中心需要使用像 Docker 和 Kubernetes 这样的技术进行管理，以确保它对于应用程序来说就像一个单台计算机一样。如果不是你自己来做这些事情，而是别人来为你管理这部分工作，这正是 serverless 架构所带来的便利。您的服务器将由第三方云提供商（如 Amazon（Lambda），Microsoft（Azure Functions）或 Google（Cloud Functions））进行管理。现在，分布式系统将由应用程序员进行编程，而基础设施管理将由云提供商完成。这是分布式系统发展的最新状态，并且会不断地发展下去。&lt;/p&gt;

&lt;p&gt;转载请注明出处，本文采用 &lt;a href=&quot;http://creativecommons.org/licenses/by-nc-nd/4.0/&quot;&gt;CC4.0&lt;/a&gt; 协议授权&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">分布式系统从最早的数据共享需求，发展到现在的 serverless 架构。它伴随着技术的发展与公司实际需求变化而演进。现在的云服务提供商简化了分布式系统开发的复杂性，让应用开发者只需关注开发，而把基础设施管理交给大型的云服务提供商。回顾分布式系统发展的历史，了解容器技术革新的原动力。</summary></entry><entry><title type="html">kafka 数据保存时间动态调整</title><link href="http://0.0.0.0/2018/06/07/kafka-data-clear/" rel="alternate" type="text/html" title="kafka 数据保存时间动态调整" /><published>2018-06-07T22:07:44+08:00</published><updated>2018-06-07T22:07:44+08:00</updated><id>http://0.0.0.0/2018/06/07/kafka-data-clear</id><content type="html" xml:base="http://0.0.0.0/2018/06/07/kafka-data-clear/">&lt;blockquote&gt;
  &lt;p&gt;动态调整kafka 数据保存时间,清理过期数据!!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;## kafka 版本: kafka_2.10-0.8.2.2&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;topics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;test1 test2&quot;&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;zk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;zk1:2181,zk2:2181,zk3:2181/kafka&quot;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;### 修改保留时间&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;### 保留几个小时&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;hours&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;2
&lt;span class=&quot;c&quot;&gt;### 转换为毫秒&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;Times&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$hours&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; * 3600000&quot;&lt;/span&gt;|bc&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;## 修改配置&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;### 控制未压缩数据 retention.ms&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;retention.ms&quot;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;### 控制压缩后的数据 delete.retention.ms&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#conf=&quot;delete.retention.ms&quot;&lt;/span&gt;

ClearLog&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;## 清理数据&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;i &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$topics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;do
&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/opt/kafka/bin/kafka-topics.sh --zookeeper &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$zk&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; --alter --topic &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$i&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; --config &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;Times&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#/opt/kafka/bin/kafka-topics.sh --zookeeper $zk --alter --topic $i --config ${conf}=${Times}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

DelConf&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;## 删除配置&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/opt/kafka/bin/kafka-topics.sh --zookeeper &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$zk&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; --alter --topic &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$i&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; --delete-config &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$conf&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#/opt/kafka/bin/kafka-topics.sh --zookeeper $zk --alter --topic $i --delete-config $conf&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in
     &lt;/span&gt;clear&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     ClearLog &lt;span class=&quot;p&quot;&gt;;;&lt;/span&gt;
     delconf&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     DelConf &lt;span class=&quot;p&quot;&gt;;;&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;clear --- 清理日志&quot;&lt;/span&gt;
     &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;delconf --- 删除配置&quot;&lt;/span&gt;
     &lt;span class=&quot;p&quot;&gt;;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;esac&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;转载请注明出处，本文采用 &lt;a href=&quot;http://creativecommons.org/licenses/by-nc-nd/4.0/&quot;&gt;CC4.0&lt;/a&gt; 协议授权&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">动态调整kafka 数据保存时间,清理过期数据!!</summary></entry><entry><title type="html">docker 问题定位记述</title><link href="http://0.0.0.0/2018/05/06/docker-problem-location/" rel="alternate" type="text/html" title="docker 问题定位记述" /><published>2018-05-06T17:56:26+08:00</published><updated>2018-05-06T17:56:26+08:00</updated><id>http://0.0.0.0/2018/05/06/docker-problem-location</id><content type="html" xml:base="http://0.0.0.0/2018/05/06/docker-problem-location/">&lt;blockquote&gt;
  &lt;p&gt;性能测试发现业务进程运行在容器中比业务进程运行在宿主机上吞吐量下降了 100 倍，这让周一显得更加阴暗。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;周一&quot;&gt;周一&lt;/h4&gt;
&lt;blockquote&gt;
  &lt;p&gt;先找下游了解了下业务模型，他们说已经把业务模型最简化了，当前的模式是：业务进程运行在容器中，通过与主机共享 IPC namespace 的方式来使用共享内存与宿主机上的 Daemon 进程进行通信，整个过程不涉及磁盘读写、网络交互等。
撸起袖子开始干，定位第一步，当然是找瓶颈了，分析下到底问题出在哪。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h5 id=&quot;top&quot;&gt;top&lt;/h5&gt;

&lt;p&gt;用到的第一个命令自然是 top，top 是 linux 里一个非常强大的命令，通过它基本上能看到系统中的所有指标。
&lt;img src=&quot;http://ok6h8mla5.bkt.clouddn.com/docker-error-wx01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面是 top 命令运行时的一个示意图，比较重要的指标都已经标了出来：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;1 处表示系统负载，它表示当前正在等待被 cpu 调度的进程数量，这个值小于系统 vcpu 数（超线程数）的时候是比较正常的，一旦大于 vcpu 数，则说明并发运行的进程太多了，有进程迟迟得不到 cpu 时间。这种情况给用户的直观感受就是敲任何命令都卡。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;2 处表示当前系统的总进程数，通常该值过大的时候就会导致 load average 过大。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;3 处表示 cpu 的空闲时间，可以反应 cpu 的繁忙程度，该值较高时表示系统 cpu 处于比较清闲的状态，如果该值较低，则说明系统的 cpu 比较繁忙。需要注意的是，有些时候该值比较高，表示 cpu 比较清闲，但是 load average 依然比较高，这种情况很可能就是因为进程数太多，进程切换占用了大量的 cpu 时间，从而挤占了业务运行需要使用的 cpu 时间。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;4 处表示进程 IO 等待的时间，该值较高时表示系统的瓶颈可能出现在磁盘和网络。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;5 处表示系统的剩余内存，反应了系统的内存使用情况。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;6 处表示单个进程的 cpu 和内存使用情况。关于 top 命令中各个指标含义的进一步描述可以参见：&lt;/li&gt;
  &lt;li&gt;http://www.jb51.net/LINUXjishu/34604.html&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;使用 top 命令查看了下系统情况，发现一切正常。load average 也不高，task 也不多，cpu 和内存都还很空闲，就连 IO 等待时间都很低，也没有哪个进程的 cpu 和内存使用率偏高，一切都很和谐，没有瓶颈！&lt;/p&gt;

&lt;p&gt;当然，没有瓶颈是不可能的。由于我们的容器都是绑核的，所以很有可能是分配给容器的那些核是处于繁忙状态，而由于总核数较多，将 cpu 的使用率给拉了下来。于是又按下了“1”键，切换到详细模式下：
&lt;img src=&quot;http://ok6h8mla5.bkt.clouddn.com/docker-error-wx02.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在这种模式下，可以看到每个 vcpu 的使用情况。一切依然很和谐，诡异的和谐。
看来从 cpu 这块是看不出来什么了，那就继续看看是不是磁盘搞的鬼吧。&lt;/p&gt;

&lt;h5 id=&quot;iostate&quot;&gt;iostate&lt;/h5&gt;
&lt;blockquote&gt;
  &lt;p&gt;iostate 命令是用来查看磁盘使用情况的一个命令，经验告诉我们，磁盘和网络已经成为影响性能的最大嫌疑犯。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;使用 iostate 工具时，通常只用关注最后一行（%util）即可，它反映了磁盘的繁忙程度。虽然下游部门已经说了他们跑的用例是一个纯内存的场景，不涉及磁盘读写。但是客户的话信得住，母猪也能上树，我还是要跑一下 iostate，看下磁盘情况怎么样。结果，依旧很和谐，磁盘使用率基本为零。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;后面还尝试了观察网络指标，发现确实也没有网络吞吐，完了，看来问题没那么简单。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;周二&quot;&gt;周二&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;虽然周一看似白忙活了一天，但是也得到了一个重要结论：这个问题不简单！不过简单的在资源层面时分析不出来啥了，得寄出性能分析的大杀器——perf 了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h5 id=&quot;perf-火焰图&quot;&gt;perf+ 火焰图&lt;/h5&gt;
&lt;blockquote&gt;
  &lt;p&gt;perf 是 linux 下一个非常强大的性能分析工具，通过它可以分析出进程运行过程中的主要时间都花在了哪些地方。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;之前没太使用过 perf，因此刚开始进行分析，就自然而然地直接使用上了 perf+ 火焰图这种最常见的组合：&lt;/p&gt;

&lt;p&gt;安装 perf。&lt;/p&gt;

&lt;p&gt;yum install perf&lt;/p&gt;

&lt;p&gt;下载火焰图工具。&lt;/p&gt;

&lt;p&gt;git clone https://github.com/brendangregg/FlameGraph.git&lt;/p&gt;

&lt;p&gt;采样。&lt;/p&gt;

&lt;p&gt;perf record -e cpu-clock -g -p 1572（业务进程 id）&lt;/p&gt;

&lt;p&gt;一段时间（通常 20s 足够）之后 ctrl+c，结束采样。&lt;/p&gt;

&lt;p&gt;用 perf script 工具对 perf.data 进行解析。&lt;/p&gt;

&lt;p&gt;perf script -i perf.data &amp;amp;&amp;gt; perf.unfold。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;PS：如果在容器中运行的程序有较多的依赖，则该命令解析出来的符号中可能会有较多的“Unregistered symbol…”错误，此时需要通过–symfs参数指定容器的rootfs位置来解决该问题。获取容器rootfs的方法根据 docker 的 storagedriver 的不同而有所不同，如果是device mapper类型，则可以通过 dockerinspect 找到容器的rootfs所在位置，如果是overlay类型，则需要通过 dockerexport 命令将该容器的rootfs导出来，如果是富容器的话，一般都有外置的rootfs，直接使用即可。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;将 perf.unfold 中的符号进行折叠。&lt;/p&gt;

&lt;p&gt;./stackcollapse-perf.pl perf.unfold &amp;amp;&amp;gt; perf.folded&lt;/p&gt;

&lt;p&gt;最后生成 svg 图。&lt;/p&gt;

&lt;p&gt;/flamegraph.pl perf.folded &amp;gt; perf.svg&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://ok6h8mla5.bkt.clouddn.com/docker-error-wx03.png&quot; alt=&quot;&quot; /&gt;
最后就能得到像下面这种样子的漂亮图片。通常情况下，如果程序中有一些函数占用了大量的 CPU 时间，则会在图片中以长横条的样式出现，表示该函数占用了大量的 CPU 时间。&lt;/p&gt;

&lt;p&gt;然而，perf+ 火焰图在这次并没有起到太大的作用，反复统计了很多次，并没有出现梦寐以求的“长横条”，还是很和谐。&lt;/p&gt;

&lt;h5 id=&quot;perf-stat&quot;&gt;perf stat&lt;/h5&gt;
&lt;p&gt;perf+ 火焰图并没有起到很好的效果，就想换个工具继续试试，但是找来找去、请教大神，也没找到更好的工具，只好继续研究 perf 这个工具。&lt;/p&gt;

&lt;p&gt;perf 除了上面提到的 record（记录事件）、script（解析记录的事件）命令之外，还有其他一些命令，常用的有 report（与 script 类似，都是对 perf record 记录的事件进行解析，不同之处在于 report 直接解析程序中的运行热点，script 的扩展性更强一点，可以调用外部脚本对事件数据进行解析）、stat（记录进程一段时间之内触发的事件数）、top（实时分析程序运行时热点）、list（列出 perf 可以记录的事件数）等命令。&lt;/p&gt;

&lt;p&gt;这些命令挨个试了个遍，终于在 perf stat 命令这块有了突破：&lt;/p&gt;

&lt;p&gt;使用 perf stat 对业务进程运行在物理机和容器上分别进行统计，发现业务进程运行在容器中时，大部分事件（task-clock、context-switches、cycles、instructions 等）的触发次数是运行在物理机上时的百分之一。&lt;/p&gt;

&lt;p&gt;这是什么原因呢？一定是什么东西阻塞住了程序的运转，这个东西是什么呢？&lt;/p&gt;

&lt;p&gt;前面已经分析了，不是磁盘，不是网络，也不是内存，更不是 cpu，那还有什么呢？？&lt;/p&gt;

&lt;h4 id=&quot;周三&quot;&gt;周三&lt;/h4&gt;

&lt;p&gt;是什么原因阻塞住了程序的运转呢？百思不得其解，百问不得其解，百猜不得其解，得，还是得动手，上控制变量法。&lt;/p&gt;

&lt;p&gt;运行在容器中的程序和运行在物理机上有什么区别呢？我们知道，docker 容器 =cgroup+namespace+secomp+capability+selinux，那么就把这些技术一个个都去掉，看到底是哪个特性搞的鬼。&lt;/p&gt;

&lt;p&gt;在这 5 个技术中，后三个都是安全相关的，都有开关可以控制，经过测试，发现把后三个都关掉之后，性能还是很差，说明这 3 个技术是无辜的，开始排查 cgroup 和 namespace。&lt;/p&gt;

&lt;p&gt;首先怀疑的当然是 cgroup，毕竟它就是做资源限制的，很有可能一不小心限制错了，就把业务给限制了。&lt;/p&gt;

&lt;h5 id=&quot;cgexec&quot;&gt;cgexec&lt;/h5&gt;
&lt;blockquote&gt;
  &lt;p&gt;cgexec 是 cgroup 提供的一个工具，可以在启动时就将程序运行到某个 cgroup 中，因此我们可以将业务程序运行在物理机上，但是放到业务容器所在的 cgroup 中，看看性能会不会下降。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;具体用法如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cgexec -g *:/system.slice/docker-03c2dd57ba123879abab6f7b6da5192a127840534990c515be325450b7193c11.scope ./run.sh

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;通过该命令即可将 run.sh 运行在与容器 03c2dd57 相同的 cgroup 中。在多次测试之后，发现这种情况下，业务进程的运行速度没有受到影响，cgroup 被洗白，那么真相只有一个——凶手就是 namespace。&lt;/p&gt;

&lt;h4 id=&quot;周四&quot;&gt;周四&lt;/h4&gt;

&lt;p&gt;虽然说凶手已经确定是 namespace，但是 namespace 家族也有一大票人，有 ipc namespace、pid namespace 等等，还需要进一步确定真凶。&lt;/p&gt;

&lt;h5 id=&quot;nsenter&quot;&gt;nsenter&lt;/h5&gt;

&lt;blockquote&gt;
  &lt;p&gt;nsenter 是一个 namespace 相关的工具，通过它可以进入某个进程所在的 namespace。在 docker exec 命令出现之前，它唯一一个可以进入 docker 容器的工具，在 docker exec 出现之后，nsenter 也由于其可以选择进入哪些 namespace 而成为 docker 问题定位的一个极其重要的工具。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;通过如下命令，即可进入容器所在的 mount namespace。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;nsenter --target $(docker inspect --format '' 容器 id) --mount bash
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;同理，通过如下命令即可进入容器所在的 IPC namespace 和 pid namespace。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;nsenter --target $(docker inspect --format '' 容器 id) --ipc --pid bash

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在不断的将业务进程在各个 namespace 之间切换后，终于进一步锁定了真凶：mount namespace。测试发现，一旦将业务进程放置到容器所在的 mount namespace，性能就会急剧下降。&lt;/p&gt;

&lt;p&gt;这是为什么呢？这是为什么呢？mount namespace 到底做了什么，会有这么大的影响？&lt;/p&gt;

&lt;h4 id=&quot;周五&quot;&gt;周五&lt;/h4&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mount namespace&lt;/code&gt; 为什么有这么大的威力呢？它到底影响什么了呢？实在想不通，就去请教了下大神，大神想了想，回了我句，试试 ldd？&lt;/p&gt;

&lt;h5 id=&quot;ldd&quot;&gt;ldd&lt;/h5&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ldd 是什么？&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;当然这句话我没去问大神，转身自己查去了。&lt;/p&gt;

&lt;p&gt;ldd 是 list, dynamic, dependencies 的缩写，意思是列出动态库依赖关系。顿时豁然开朗，mount namespace 隔离出了自己的文件系统，所以容器内外可以使用不同的依赖库，而不同的依赖库就可能造成无数种影响。&lt;/p&gt;

&lt;p&gt;于是开始通过 ldd 对比容器中业务进程的依赖库与宿主机上业务进程的依赖库，最终发现容器中的 glibc 库与宿主机上的 glibc 库版本不一致，很可能是这个原因导致性能下降的。&lt;/p&gt;

&lt;p&gt;于是将容器中的 glibc 库版本替换为宿主机上的 glibc 库之后，容器内业务的性能终于恢复了，猜想得到证实。&lt;/p&gt;

&lt;h4 id=&quot;后记&quot;&gt;后记&lt;/h4&gt;

&lt;p&gt;为什么容器内外 glibc 版本不一致就导致性能下降了呢？&lt;/p&gt;

&lt;p&gt;这是和业务模型相关的，前面提到，下游的业务模型是通过与主机共享 IPC namespace 的方式来使用共享内存与宿主机上的 daemon 进程进行通信。而 glibc 在一次升级中，更新了信号量的数据结构（如下），就会导致在共享内存通信时，由于数据格式不一致，每次信号量通信都超时，从而影响了程序运行效率。&lt;/p&gt;

&lt;p&gt;转载请注明出处，本文采用 &lt;a href=&quot;http://creativecommons.org/licenses/by-nc-nd/4.0/&quot;&gt;CC4.0&lt;/a&gt; 协议授权&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">性能测试发现业务进程运行在容器中比业务进程运行在宿主机上吞吐量下降了 100 倍，这让周一显得更加阴暗。</summary></entry><entry><title type="html">12款Kubernetes发行版</title><link href="http://0.0.0.0/2018/04/27/k8s-release-12/" rel="alternate" type="text/html" title="12款Kubernetes发行版" /><published>2018-04-27T20:35:46+08:00</published><updated>2018-04-27T20:35:46+08:00</updated><id>http://0.0.0.0/2018/04/27/k8s-release-12</id><content type="html" xml:base="http://0.0.0.0/2018/04/27/k8s-release-12/">&lt;blockquote&gt;
  &lt;p&gt;12 款最突出的 Kubernetes 产品，也就是整合了 Kubernetes 和容器工具的发行版。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://d33wubrfki0l68.cloudfront.net/1567471e7c58dc9b7d9c65dcd54e60cbf5870daa/a2249/images/flower.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Kubernetes 已经成为大规模容器编排的首选。这款由 Google 开源的容器编排系统受到广泛好评和支持，发展势头迅猛。&lt;/p&gt;

&lt;p&gt;Kubernetes 十分庞大而复杂，难以搭建和配置。不仅如此，还有很多繁重的工作留给了最终用户去做。因此，最好的方法就是不要尝试单独使用 Kubernetes，而是寻找一种将 Kubernetes 作为组件的容器解决方案。&lt;/p&gt;

&lt;p&gt;在这里，我列出了 12 款最突出的 Kubernetes 产品，也就是整合了 Kubernetes 和容器工具的发行版，可媲美各种供应商提供的 Linux 内核版本。&lt;/p&gt;

&lt;p&gt;请注意，此列表不包含专有云服务，如 Amazon EKS 或 Google Kubernetes Engine，我们主要关注的是可在本地运行或作为云托管服务的产品。&lt;/p&gt;

&lt;h4 id=&quot;coreos-tectonic&quot;&gt;CoreOS Tectonic&lt;/h4&gt;
&lt;p&gt;CoreOS 主要提供基于容器的 Linux 发行版，与 Docker 兼容，但具有自己的自定义镜像格式和运行时，以及“企业级 Kubernetes”发行版。它们一起构成了 CoreOS Tectonic 技术栈的基础。&lt;/p&gt;

&lt;p&gt;CoreOS 的操作系统 Container Linux 主要作为一组容器化的组件进行发行。通过这种方式，操作系统的自动更新可以直接进入生产环境中，无需关闭运行中的应用程序。CoreOS 也支持“一键”更新 Kubernetes。CoreOS Tectonic 可运行在 Amazon Web Services、Microsoft Azure 和裸机上。&lt;/p&gt;

&lt;h4 id=&quot;kubernetes-的-canonical-发行版&quot;&gt;Kubernetes 的 Canonical 发行版&lt;/h4&gt;

&lt;p&gt;Canonical 是 Ubuntu Linux 的制造商，也提供了自己的 Kubernetes 发行版。Canonical 发行版的一大卖点是它以已经得到广泛推崇和部署的 Ubuntu Linux 发行版为基础。 Canonical 称它的技术栈可以在云端或本地运行，并且支持 CPU 和 GPU 两种工作负载。对于付费用户，有 Canonical 工程师来远程协助管理 Kubernetes 群集。&lt;/p&gt;

&lt;p&gt;Canonical 和 Rancher 实验室（见下文）共同推出了 Cloud Native Platform，将 Canonical 的 Kubernetes 发行版与 Rancher 的容器管理平台组合在一起。该平台使用 Kubernetes 来管理每个集群中运行的容器，并使用 Rancher 来管理多个 Kubernetes 集群。Cloud Native Platform 将随 Rancher 2.0 一起发布，目前提供了测试预览版。&lt;/p&gt;

&lt;h4 id=&quot;docker-社区版和-docker-企业版&quot;&gt;Docker 社区版和 Docker 企业版&lt;/h4&gt;

&lt;p&gt;对于大多数人来说，Docker 就是容器。自 2014 年起，Docker 拥有了自己的集群和编排系统 Docker Swarm，不久前 Docker Swarm 还是 Kubernetes 的竞争对手。2017 年 10 月，Docker 宣布将 Kubernetes 作为 Docker 社区版和 Docker Enterprise 2.0 的标准插入式组件。&lt;/p&gt;

&lt;p&gt;简而言之，Docker 公司承认 Kubernetes 比 Swarm 更适合管理大型复杂的容器环境。但是，Docker 仍然为小型作业保留了初始的集群系统（也就是“Swarm 模式”），比如部署在数量不会很大的防火墙后面的本地应用程序。&lt;/p&gt;

&lt;h4 id=&quot;heptio-kubernetes-subscription&quot;&gt;Heptio Kubernetes Subscription&lt;/h4&gt;
&lt;p&gt;Kubernetes 的两位作者 Craig McLuckie 和 Joe Beda 共同创立了 Heptio，旨在提供基于 Kubernetes 的服务和产品。他们的第一个主要产品是 Heptio Kubernetes Subscription（HKS），一项付费的 Kubernetes 部署服务，由 Heptio 提供 24/7 全天候支持。起价为每月 2000 美元。&lt;/p&gt;

&lt;p&gt;Heptio 的主要卖点是提供没有供应商锁定的企业级 Kubernetes。该产品可以运行在公有云或私有硬件上。Heptio 提供的所有用于管理和配置 Kubernetes 的工具都是开源的，补丁可以直接推送到受支持的集群。&lt;/p&gt;

&lt;h4 id=&quot;mesosphere-dcos&quot;&gt;Mesosphere DC/OS&lt;/h4&gt;

&lt;p&gt;Mesosphere DC/OS 使用 Apache Mesos 将一组机器变成单个资源，并可以动态分配给多个应用程序。 Kubernetes 作为 DC/OS 上众多应用程序包之一，用户可以跨 DC/OS 群集安装、运行和更新 Kubernetes。&lt;/p&gt;

&lt;p&gt;Kubernetes 并不完全是 DC/OS 的一部分，但可以通过 DC/OS 来部署，就像 Linux 应用程序可以通过 Linux 发行版的包管理系统来管理一样，这么说来，DC/OS 本身是不是一个 Kubernetes 发行版仍然值得商榷。尽管如此，Mesosphere 在如何使用 Kubernetes 方面与 Kubernetes 的工作原理息息相关，例如，它使用 Kubernetes 的主流社区发行版来确保与现有工具集的高度兼容性。&lt;/p&gt;

&lt;h4 id=&quot;mirantis-cloud-platform&quot;&gt;Mirantis Cloud Platform&lt;/h4&gt;

&lt;p&gt;如 Mirantis 所言，Mirantis Cloud Platform 将 OpenStack、Kubernetes 或两者的组合作为“敏捷基础设施平台”的基础。简而言之，Mirantis Cloud Platform 是一个用于编排虚拟机、容器和裸机服务器的单一集成解决方案。该平台以“DevOps 方式”管理部署在该平台上的应用程序，使用 Salt 作为配置管理工具，并集成 CI/CD 支持以确保应用程序被正确部署。&lt;/p&gt;

&lt;p&gt;Mirantis Cloud Platform 可以直接在裸机、OpenStack 集群或公有云上运行 Kubernetes。&lt;/p&gt;

&lt;p&gt;Mirantis 声称，Mirantis Cloud Platform 可以更容易地与 Kubernetes 集成，因为配置 Kubernetes 基础设施的相关任务不会落在最终用户身上。&lt;/p&gt;

&lt;h4 id=&quot;platform9-managed-kubernetes&quot;&gt;Platform9 Managed Kubernetes&lt;/h4&gt;

&lt;p&gt;大多数 Kubernetes 发行版专注于让 Kubernetes 从内到外和从上到下都易于管理。 Platform9 Managed Kubernetes 可以在任意环境中运行——本地裸机或远程的公共有云上，并可由 Platform9 的工程师作为服务进行远程管理。&lt;/p&gt;

&lt;p&gt;在客户的监督下，Platform9 大约每六周推出一次 Managed Kubernetes 更新。 Platform9 还提供了一些功能，比如多租户用户配额，而该功能在 Kubernetes 集群中通常需要通过手动来添加。Platform9 还提供了与 Platform9 Fission 项目的集成，Fission 是一个无服务器计算服务（“函数即服务”系统），可与大多数具有容器化运行时的编程语言一起使用。&lt;/p&gt;

&lt;h4 id=&quot;rancher-20&quot;&gt;Rancher 2.0&lt;/h4&gt;

&lt;p&gt;Rancher 实验室已经将 Kubernetes 集成到它的容器管理平台 Rancher 2.0 版本中，Rancher 2.0 目前处于测试阶段。相比其他 Kubernetes 发行版，Rancher 2.0 位于更上层，它位于 Linux 主机、Docker 容器和 Kubernetes 节点之上，可以独立管理所有这些节点。它甚至可以管理 Amazon EKS、Google Kubernetes Engine、Azure Container Service 和其他云端的 Kubernetes。&lt;/p&gt;

&lt;p&gt;Rancher 也有自己的 Kubernetes 发行版。Rancher 旨在消除搭建 Kubernetes 集群和为特定环境定制 Kubernetes 所需要的苦差事，并防止这些自定义功能妨碍 Kubernetes 升级。&lt;/p&gt;

&lt;h4 id=&quot;red-hat-openshift&quot;&gt;Red Hat OpenShift&lt;/h4&gt;

&lt;p&gt;Red Hat 的 PaaS 产品 OpenShift 最初使用 Heroku 风格的“cartridges”来打包应用程序，然后把它们部署到名为“gear”的容器中。后来，Docker 出现了，OpenShift 进行了重写，以便利用新的容器镜像和运行时标准。Red Hat 也不可避免地将 Kubernetes 作为 OpenShift 的编配技术。&lt;/p&gt;

&lt;p&gt;OpenShift 旨在为 PaaS 中的所有组件提供抽象和自动化。这种抽象和自动化也扩展到了 Kubernetes，因此带来了相当大的管理负担，而 OpenShift 可以用来在部署 PaaS 的过程中缓解这一点。&lt;/p&gt;

&lt;h4 id=&quot;stackube&quot;&gt;Stackube&lt;/h4&gt;

&lt;p&gt;Hyper.sh 云服务用于运行容器，它的开发商 HyperHQ 推出了 Stackube，一个“以 Kubernetes 为中心的 OpenStack 发行版”。通常，OpenStack 使用一个名为 Nova 的组件来配置和管理计算节点，而 Stackube 使用的是 Kubernetes。除此之外，它使用的是“普通”的 OpenStack 和 Kubernetes，所有其他额外细节由 OpenStack 插件来处理。&lt;/p&gt;

&lt;p&gt;HyperHQ 声称，Stackube 的主要优势是它可以根据使用哪个容器运行时提供不同程度的多租户。对于“软”多租户，可以使用 Docker，要想更可靠地进行资源分离，可以使用 HyperContainer，HyperContainer 提供了 Hypervisor 级别的隔离。&lt;/p&gt;

&lt;h4 id=&quot;suse-caas-平台&quot;&gt;SUSE CaaS 平台&lt;/h4&gt;

&lt;p&gt;SUSE 以在欧洲广泛流行的 Linux 发行版而闻名，它还提供了 SUSE CaaS 平台。从概念上讲，它让人联想到 CoreOS Tectonic——捆绑运行容器的裸机“微”操作系统，将 Kubernetes 作为容器编排系统，内置镜像注册表和集群配置工具。&lt;/p&gt;

&lt;p&gt;SUSE CaaS Platform 可以在公有云以及本地裸机上运行，但要注意，“SUSE 目前不支持任何与底层云基础设施的集成”。这意味着 SUSE CaaS Platform 的设计不是为了弥补 Amazon EKS 或 Google Kubernetes Engine 的不足，而是为了让用户可以跨多个云和数据中心运行容器。&lt;/p&gt;

&lt;h4 id=&quot;telekube&quot;&gt;Telekube&lt;/h4&gt;

&lt;p&gt;Teleport SSH 服务器开发商 Gravitational 推出了 Telekube，这是一款在本地或远程集群上运行的“生产强化型”Kubernetes 发行版。Telekube 定位为私有 SaaS 平台解决方案，将 Kubernetes 作为跨多个区域运行的托管服务。&lt;/p&gt;

&lt;p&gt;Telekube 上的应用程序必须能够在 Kubernetes 容器中运行。他们还必须打包成“Bundle”，然后发布到 Kubernetes 集群中。在部署基于容器的应用程序之前，需要为捆绑做一些额外的工作，不过 Telekube 唯一留给用户的任务是维护 Bundle Manifest。&lt;/p&gt;

&lt;p&gt;转载请注明出处，本文采用 &lt;a href=&quot;http://creativecommons.org/licenses/by-nc-nd/4.0/&quot;&gt;CC4.0&lt;/a&gt; 协议授权&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">12 款最突出的 Kubernetes 产品，也就是整合了 Kubernetes 和容器工具的发行版。</summary></entry><entry><title type="html">Docker device or resource busy 问题</title><link href="http://0.0.0.0/2018/04/10/docker-device-or-resource-busy/" rel="alternate" type="text/html" title="Docker device or resource busy 问题" /><published>2018-04-10T20:09:12+08:00</published><updated>2018-04-10T20:09:12+08:00</updated><id>http://0.0.0.0/2018/04/10/docker-device-or-resource-busy</id><content type="html" xml:base="http://0.0.0.0/2018/04/10/docker-device-or-resource-busy/">&lt;h2 id=&quot;现象描述&quot;&gt;现象描述&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;查看容器发现 Dead 状态容器&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node ~]# docker ps -a |grep Dead
e0fdd4b75b7c        store.jevic.com/fileinject-agents/tcs:a35104a    &quot;/fileinject-agent...&quot;   28 hours ago        Dead                                             r-fileinject-agents-tcs-16-81cfe394
7d7841c49c7b        store.jevic.com/fileinject-agents/ups:ebb7241    &quot;/fileinject-agent...&quot;   28 hours ago        Dead                                                                                       

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;查看系统挂载
    &lt;ul&gt;
      &lt;li&gt;此时有很多Dead 容器依然被挂载中&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node ~]# df -h|grep docker
overlay         415G   18G  398G   5% /var/lib/docker/overlay/93b1805f06dda8ae47b762465ca51ec27463fd715d08f91b25ca21ac074d8010/merged
shm              64M     0   64M   0% /var/lib/docker/containers/420d6805eede457b88f0781f50d8744647d1cdcc535f40207259abdd68f6e31e/shm
overlay         415G   18G  398G   5% /var/lib/docker/overlay/
....... 此次省略......

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;删除容器&quot;&gt;删除容器&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node ~]# docker rm -f 7d7841c49c7b
Error response from daemon: driver &quot;overlay&quot; failed to remove root filesystem for 7d7841c49c7b4109756274020d93776ce615f0f512c4f21e05b3ac94371b0604: remove /var/lib/docker/overlay/80299696071d4181254a31052dfecea062201905f0b3187ae241575fbc7a059e/merged: device or resource busy

提示: 设备正忙

卸载重新删除
[root@node ~]# umount var/lib/docker/overlay/80299696071d4181254a31052dfecea062201905f0b3187ae241575fbc7a059e/merged
[root@node ~]# docker rm -f 7d7841c49c7b
....
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;最后 重新docker ps 发现 容器已经被删除&lt;/p&gt;
  &lt;blockquote&gt;
    &lt;p&gt;对于有些应用容器 可能上述步骤依然无法删除掉容器;
直接重启宿主机也可以恢复正常,当然根据实际情况来判断是否需要此操作毕竟会导致服务中断；
这种Dead 状态的并不影响docker正常使用，所以可视情况执行操作；&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;问题原因&quot;&gt;问题原因&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;挂载点泄露实际上是 RHEL/CentOS 内核的一个 bug，目前预计会在 RHEL7.4 kernel 中修复。
因此该问题理论上在 Fedora,ubuntu  等发行版本中是不存在的。
目前在RHEL/CentOS下需要在 docker.service中增加MountFlags=slave来保证 mount namespace 是私有的，不会造成挂载点泄露。
另外，挂载点泄露在各种 storage driver 中都存在，比如最常见的 devicemeppaer 和 overlay。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;但是，目前 RHEL/CentOS 版本下 MountFlags=slave 和 –live-restore 两个给力的参数不能同时存在。
因为 MountFlags=slave 会导致 docker daemon 每次重启时私有挂载命名空间都会发生变化，而 –live-restore 又相当于使得容器持有了变化之前的旧的挂载点信息，因此，当重启 docker daemon 之后，执行 docker exec 试图进入容器时会报错值得一提的是，虽然无法进入容器，但是容器依旧工作正常并且 docker logs 也没问题。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;对于生产环境，遇到 Device is busy 问题时，使用 docker rm -f [container] 后重新启动新的容器即可；
对于新的机器，当前版本下为 docker.service 加上 MountFlags=slave 即可。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;转载请注明出处，本文采用 &lt;a href=&quot;http://creativecommons.org/licenses/by-nc-nd/4.0/&quot;&gt;CC4.0&lt;/a&gt; 协议授权&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">现象描述 查看容器发现 Dead 状态容器</summary></entry><entry><title type="html">Shadowsocks 翻墙</title><link href="http://0.0.0.0/2018/03/19/shadowsocks/" rel="alternate" type="text/html" title="Shadowsocks 翻墙" /><published>2018-03-19T10:35:46+08:00</published><updated>2018-03-19T10:35:46+08:00</updated><id>http://0.0.0.0/2018/03/19/shadowsocks</id><content type="html" xml:base="http://0.0.0.0/2018/03/19/shadowsocks/">&lt;blockquote&gt;
  &lt;p&gt;国外一台机器配置了shadowsocks,以此进行科学上网&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;server-端配置&quot;&gt;Server 端配置&lt;/h2&gt;
&lt;h3 id=&quot;一键安装脚本&quot;&gt;一键安装脚本&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;wget --no-check-certificate -O shadowsocks-go.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-go.sh
chmod +x shadowsocks-go.sh
./shadowsocks-go.sh 2&amp;gt;&amp;amp;1 | tee shadowsocks-go.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;配置文件
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vim /etc/shadowsocks/config.json
{
  &quot;server&quot;:&quot;0.0.0.0&quot;,
  &quot;server_port&quot;:xxxx,
  &quot;local_port&quot;:1080,
  &quot;password&quot;:&quot;xxxxx&quot;,
  &quot;method&quot;:&quot;aes-256-cfb&quot;,
  &quot;timeout&quot;:600
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;启动&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/etc/init.d/shadowsocks start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;卸载&quot;&gt;卸载&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./shadowsocks-go.sh uninstall

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;客户端&quot;&gt;客户端&lt;/h2&gt;
&lt;h3 id=&quot;windows-客户端&quot;&gt;Windows 客户端&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;https://github.com/shadowsocks/shadowsocks-windows/releases&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;linux-客户端配置&quot;&gt;Linux 客户端配置&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;安装 扩展源,pip
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yum install epel-relase
yum install python-pip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;安装shadowsocks&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install shadowsocks
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;添加连接配置&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;默认没有配置文件需要手动添加&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vim /etc/shadowsocks/shadowsocks.json
{
    &quot;server&quot;:&quot;x.x.x.x&quot;, ## 服务端IP
    &quot;server_port&quot;:xxxx, ## 服务端口
    &quot;local_address&quot;: &quot;127.0.0.1&quot;, ## 0.0.0.0
    &quot;local_port&quot;:1080,
    &quot;password&quot;:&quot;xxxx&quot;,
    &quot;method&quot;:&quot;aes-256-cfb&quot;,
    &quot;timeout&quot;:600
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;启动文件
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cat &amp;gt; /lib/systemd/system/shadowsocks.service&amp;lt;&amp;lt;EOF
[Unit]
Description=Shadowsocks
[Service]
TimeoutStartSec=0
ExecStart=/usr/bin/sslocal -c /etc/shadowsocks/shadowsocks.json
[Install]
WantedBy=multi-user.target
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;启动管理
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;systemctl daemon-reload
systemctl start shadowsocks
systemctl enable shadowsocks
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;测试连接&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@master218 ~]# curl --socks5 127.0.0.1:1080 http://httpbin.org/ip
{
  &quot;origin&quot;: &quot;x.x.x.x&quot;  ## 返回你的服务器地址,状态OK
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;privoxy&quot;&gt;Privoxy&lt;/h3&gt;
&lt;h4 id=&quot;安装&quot;&gt;安装&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yum install -y privoxy
systemctl enable privoxy
systemctl start privoxy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;修改配置文件&quot;&gt;修改配置文件&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@master218 ~]# tail -n 1 /etc/privoxy/config
forward-socks5t / 127.0.0.1:1080 .
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;配置环境变量&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@master218 ~]# vim /etc/profile
PROXY_HOST=127.0.0.1
export all_proxy=http://$PROXY_HOST:8118 ## privoxy 默认端口8118
export ftp_proxy=http://$PROXY_HOST:8118
export http_proxy=http://$PROXY_HOST:8118
export https_proxy=http://$PROXY_HOST:8118
export no_proxy=localhost,172.16.0.0/16,192.168.0.0/16.,127.0.0.1,10.10.0.0/16

[root@master218 ~]# source /etc/profile
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;测试连接&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@master218 ~]# curl -I www.google.com
HTTP/1.1 200 OK
......
Accept-Ranges: none
Vary: Accept-Encoding
Proxy-Connection: keep-alive

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;取消代理&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;while read var; do unset $var; done &amp;lt; &amp;lt;(env | grep -i proxy | awk -F= '{print $1}')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;参考链接:&lt;/p&gt;
  &lt;blockquote&gt;
    &lt;p&gt;https://teddysun.com/392.html&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;</content><author><name>Jevic</name></author><summary type="html">国外一台机器配置了shadowsocks,以此进行科学上网</summary></entry></feed>