<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="http://0.0.0.0/feed.xml" rel="self" type="application/atom+xml" /><link href="http://0.0.0.0/" rel="alternate" type="text/html" /><updated>2020-05-22T11:15:22+08:00</updated><id>http://0.0.0.0/</id><title type="html">Jevic</title><subtitle>......</subtitle><author><name>Jevic</name></author><entry><title type="html">Can’t kill YARN apps using ResourceManager UI</title><link href="http://0.0.0.0/2020/04/17/yar-app-kill/" rel="alternate" type="text/html" title="Can't kill YARN apps using ResourceManager UI" /><published>2020-04-17T21:30:06+08:00</published><updated>2020-04-17T21:30:06+08:00</updated><id>http://0.0.0.0/2020/04/17/yar-app-kill</id><content type="html" xml:base="http://0.0.0.0/2020/04/17/yar-app-kill/">&lt;ul&gt;
  &lt;li&gt;调整添加以下参数:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;调整core-site.xml:
hadoop.http.filter.initializers=org.apache.hadoop.security.HttpCrossOriginFilterInitializer,org.apache.hadoop.http.lib.StaticUserWebFilter

新增yare-site.xml:
yarn.resourcemanager.webapp.ui-actions.enabled=true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://community.cloudera.com/t5/Support-Questions/Can-t-kill-YARN-apps-using-ResourceManager-UI-after-HDP-3-1/td-p/243835&quot;&gt;参考文档&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Jevic</name></author><summary type="html">调整添加以下参数:</summary></entry><entry><title type="html">Apache Tez-ui</title><link href="http://0.0.0.0/2020/04/17/tez-ui/" rel="alternate" type="text/html" title="Apache Tez-ui" /><published>2020-04-17T18:56:06+08:00</published><updated>2020-04-17T18:56:06+08:00</updated><id>http://0.0.0.0/2020/04/17/tez-ui</id><content type="html" xml:base="http://0.0.0.0/2020/04/17/tez-ui/">&lt;ul&gt;
  &lt;li&gt;版本信息:
    &lt;ul&gt;
      &lt;li&gt;Ambari 2.7.5&lt;/li&gt;
      &lt;li&gt;HDP-3.1.4.0&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;tez-ui-war包&quot;&gt;tez-ui war包&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://tez.apache.org/releases/&quot;&gt;Releases Downloads&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tar -zxf /opt/apache-tez-0.9.2-bin.tar.gz
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;tomcat&quot;&gt;tomcat&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://tomcat.apache.org/whichversion.html&quot;&gt;下载&lt;/a&gt;官方 tar.gz 安装包解压即可&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;tez-ui-配置&quot;&gt;tez-ui 配置&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# mkdir -p /opt/apache-tomcat-9.0.19/webapps/tez-ui
# cp /opt/apache-tez-0.9.2-bin/tez-ui-0.9.2.war /opt/apache-tomcat-9.0.19/webapps/tez-ui
# cd /opt/apache-tomcat-9.0.19/webapps/tez-ui
# unzip tez-ui-0.9.2.war
# cat config/configs.env
...... 省略 ......
ENV = {
  hosts: {
    /*
     * Timeline Server Address:
     * By default TEZ UI looks for timeline server at http://localhost:8188, uncomment and change
     * the following value for pointing to a different address.
     */
    timeline: &quot;http://192.168.1.12:8188&quot;,

    /*
     * Resource Manager Address:
     * By default RM REST APIs are expected to be at http://localhost:8088, uncomment and change
     * the following value to point to a different address.
     */
    rm: &quot;http://192.168.1.12:8088&quot;,

    /*
     * Resource Manager Web Proxy Address:
     * Optional - By default, value configured as RM host will be taken as proxy address
     * Use this configuration when RM web proxy is configured at a different address than RM.
     */
    //rmProxy: &quot;http://localhost:8088&quot;,
  },
  ...... 省略....

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;修改 tomcat server.conf 端口号&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;Connector port=&quot;9999&quot; protocol=&quot;HTTP/1.1&quot;
               connectionTimeout=&quot;20000&quot;
               redirectPort=&quot;8443&quot; /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;启动tomcat:
    &lt;ul&gt;
      &lt;li&gt;./bin/startup.sh&lt;/li&gt;
      &lt;li&gt;http://192.168.1.12:9999/tez-ui/ 访问页面&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;tez-sitexml&quot;&gt;tez-site.xml&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;tez.history.logging.service.class&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;org.apache.tez.dag.history.logging.ats.ATSHistoryLoggingService&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;tez.tez-ui.history-url.base&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;http://192.168.1.12:9999/tez-ui/&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://community.cloudera.com/t5/Community-Articles/How-to-install-Tez-UI-Standalone-and-use-it-to-debug-Hive/ta-p/247345&quot;&gt;参考文档&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Jevic</name></author><summary type="html">版本信息: Ambari 2.7.5 HDP-3.1.4.0</summary></entry><entry><title type="html">Oozie-YARN异常YarnException:Failed while publishing entity的解决方案</title><link href="http://0.0.0.0/2020/03/30/oozie-yarn-error/" rel="alternate" type="text/html" title="Oozie-YARN异常YarnException:Failed while publishing entity的解决方案" /><published>2020-03-30T18:56:06+08:00</published><updated>2020-03-30T18:56:06+08:00</updated><id>http://0.0.0.0/2020/03/30/oozie-yarn-error</id><content type="html" xml:base="http://0.0.0.0/2020/03/30/oozie-yarn-error/">&lt;p&gt;版本: HDP 3.1.4
Mapreduce提交任务计算时，job已经结束，但是容器仍不能关闭持续等待五分钟;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2020-03-30 21:09:30,393 INFO [Thread-75] org.apache.hadoop.yarn.event.AsyncDispatcher: Waiting for AsyncDispatcher to drain. Thread state is :WAITING
2020-03-30 21:09:30,494 INFO [Thread-75] org.apache.hadoop.yarn.event.AsyncDispatcher: Waiting for AsyncDispatcher to drain. Thread state is :WAITING
2020-03-30 21:09:30,594 INFO [Thread-75] org.apache.hadoop.yarn.event.AsyncDispatcher: Waiting for AsyncDispatcher to drain. Thread state is :WAITING
2020-03-30 21:09:30,694 INFO [Thread-75] org.apache.hadoop.yarn.event.AsyncDispatcher: Waiting for AsyncDispatcher to drain. Thread state is :WAITING
2020-03-30 21:09:30,794 INFO [Thread-75] org.apache.hadoop.yarn.event.AsyncDispatcher: Waiting for AsyncDispatcher to drain. Thread state is :WAITING
2020-03-30 21:09:30,819 ERROR [Job ATS Event Dispatcher] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Failed to process Event JOB_FINISHED for the job : job_1585569116633_0009
org.apache.hadoop.yarn.exceptions.YarnException: Failed while publishing entity
	at org.apache.hadoop.yarn.client.api.impl.TimelineV2ClientImpl$TimelineEntityDispatcher.dispatchEntities(TimelineV2ClientImpl.java:548)
	at org.apache.hadoop.yarn.client.api.impl.TimelineV2ClientImpl.putEntities(TimelineV2ClientImpl.java:149)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.processEventForNewTimelineService(JobHistoryEventHandler.java:1405)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleTimelineEvent(JobHistoryEventHandler.java:742)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.access$1200(JobHistoryEventHandler.java:93)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler$ForwardingEventHandler.handle(JobHistoryEventHandler.java:1795)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler$ForwardingEventHandler.handle(JobHistoryEventHandler.java:1791)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:197)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:126)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.sun.jersey.api.client.ClientHandlerException: java.net.SocketTimeoutException: Read timed out
	at com.sun.jersey.client.urlconnection.URLConnectionClientHandler.handle(URLConnectionClientHandler.java:155)
	at com.sun.jersey.api.client.Client.handle(Client.java:652)
	at com.sun.jersey.api.client.WebResource.handle(WebResource.java:682)
	at com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74)
	at com.sun.jersey.api.client.WebResource$Builder.put(WebResource.java:539)
	at org.apache.hadoop.yarn.client.api.impl.TimelineV2ClientImpl.doPutObjects(TimelineV2ClientImpl.java:291)
	at org.apache.hadoop.yarn.client.api.impl.TimelineV2ClientImpl.access$000(TimelineV2ClientImpl.java:66)
	at org.apache.hadoop.yarn.client.api.impl.TimelineV2ClientImpl$1.run(TimelineV2ClientImpl.java:302)
	at org.apache.hadoop.yarn.client.api.impl.TimelineV2ClientImpl$1.run(TimelineV2ClientImpl.java:299)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hue-oozie01.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hue-oozie02.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hue-oozie3.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hue-oozie03.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;发生这种情况是因为来自ATSv2的嵌入式HBASE崩溃。
需要重置ATsv2内嵌HBASE数据库&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;停止yarn服务&quot;&gt;停止Yarn服务&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Ambari - &amp;gt; Yarn-Actions- &amp;gt; Stop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;删除zookeeper-上的atsv2-znode&quot;&gt;删除zookeeper 上的ATSv2 Znode&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@ ~]# cd /usr/hdp/3.1.4.0-315/zookeeper/bin
[root@ bin]# ./zkCli.sh
......
[zk: localhost:2181(CONNECTED) 1] rmr /atsv2-hbase-unsecure
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;删除hdfs时间线服务目录内的hbase数据&quot;&gt;删除HDFS时间线服务目录内的hbase数据&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[hdfs@s05 ~]$ hdfs dfs -rm -r /atsv2/hbase
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;启动yarn服务&quot;&gt;启动Yarn服务&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Ambari - &amp;gt; Yarn-Actions- &amp;gt; Start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;再次提交服务&quot;&gt;再次提交服务&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hue-oozie04.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">版本: HDP 3.1.4 Mapreduce提交任务计算时，job已经结束，但是容器仍不能关闭持续等待五分钟;</summary></entry><entry><title type="html">Ambari安装oozie UI无法显示</title><link href="http://0.0.0.0/2020/03/17/oozie-ui/" rel="alternate" type="text/html" title="Ambari安装oozie UI无法显示" /><published>2020-03-17T18:56:06+08:00</published><updated>2020-03-17T18:56:06+08:00</updated><id>http://0.0.0.0/2020/03/17/oozie-ui</id><content type="html" xml:base="http://0.0.0.0/2020/03/17/oozie-ui/">&lt;blockquote&gt;
  &lt;p&gt;如下图所示,无法正常显示UI界面&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/oozie-web.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;1-停止oozie-服务&quot;&gt;1. 停止oozie 服务&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/oozie02.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-下载扩展包&quot;&gt;2. 下载扩展包&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@dt-hdp01 libext]# pwd
/usr/hdp/3.1.4.0-315/oozie/libext
[root@dt-hdp01 libext]# rm -rf ext-2.2  #如果已经存在的删除即可
[root@dt-hdp01 libext]# wget http://archive.cloudera.com/gplextras/misc/ext-2.2.zip
[root@dt-hdp01 libext]# unzip -q ext-2.2.zip 
[root@dt-hdp01 libext]# chown oozie.hadoop ext-2.2 -R
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;3-删除旧页面文件&quot;&gt;3. 删除旧页面文件&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@dt-hdp01 webapps]# pwd
/usr/hdp/current/oozie-server/oozie-server/webapps
[root@dt-hdp01 webapps]# rm -rf oozie oozie.war 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;4-重新编译生成war包&quot;&gt;4. 重新编译生成war包&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@dt-hdp01 bin]# pwd
/usr/hdp/current/oozie-server/bin
[root@dt-hdp01 bin]# ./oozie-setup.sh prepare-war
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/oozie01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;5-启动oozie访问web页面即可&quot;&gt;5. 启动oozie,访问web页面即可&lt;/h3&gt;

&lt;h3 id=&quot;其他说明&quot;&gt;其他说明:&lt;/h3&gt;
&lt;p&gt;关于ext-2.2 目录的位置;
根据步骤3 当中所示的软连接地址把下载的包放置到对应位置即可;
其他集群管理工具安装的oozie大致一样;&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">如下图所示,无法正常显示UI界面</summary></entry><entry><title type="html">Hue</title><link href="http://0.0.0.0/2020/03/16/hue/" rel="alternate" type="text/html" title="Hue" /><published>2020-03-16T18:56:06+08:00</published><updated>2020-03-16T18:56:06+08:00</updated><id>http://0.0.0.0/2020/03/16/hue</id><content type="html" xml:base="http://0.0.0.0/2020/03/16/hue/">&lt;p&gt;HUE是一个开源的Apache Hadoop UI系统，早期由Cloudera开发，后来贡献给开源社区。它是基于Python Web框架Django实现的。通过使用Hue我们可以通过浏览器方式操纵Hadoop集群。例如put、get、执行MapReduce Job等等&lt;/p&gt;

&lt;h2 id=&quot;安装&quot;&gt;安装&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;官网提供的只是源码只能编译安装(太耗时)&lt;/li&gt;
  &lt;li&gt;直接使用CDH 的发行版本&lt;a href=&quot;https://docs.cloudera.com/documentation/enterprise/6/release-notes/topics/rg_cm_6_version_download.html#cm_6_version_download&quot;&gt;cm_6_version_download&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Docker 或者 kubernetes 部署 (优选)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;docker-方式部署&quot;&gt;Docker 方式部署&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;关于镜像
    &lt;ul&gt;
      &lt;li&gt;由于官方镜像实在是太大网络不好的根本很难正常下载;&lt;/li&gt;
      &lt;li&gt;这里使用阿里云镜像仓库进行FROM 构建&lt;/li&gt;
      &lt;li&gt;在从阿里云镜像拉取会快很多&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# cat Dockerfile
FROM gethue/hue:latest
ENV US jevic

....
docker pull registry.cn-shenzhen.aliyuncs.com/jevic/hue:v1
docker tag registry.cn-shenzhen.aliyuncs.com/jevic/hue:v1 hue
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;为了修改配置文件方便,可将配置文件进行挂载；&lt;/li&gt;
  &lt;li&gt;挂载之前先将镜像的配置文件目录拷贝出来&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# docker run -it hue /bin/bash
另外打开一个终端: 
# docker cp hue:/usr/share/hue/desktop/conf /opt/hue/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;启动hue
    &lt;ul&gt;
      &lt;li&gt;如果使用默认桥接网络你需要显示的指明hostname:&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--add-host=db1.jevic.cn:192.168.1.1&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;否则容器内部无法进行域名解析&lt;/li&gt;
      &lt;li&gt;这里使用host 模式所以无需指定&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# cat run.hue.sh
docker run -it -d \
--name hue \
--network host \
-v /opt/hue/conf:/usr/share/hue/desktop/conf \
hue
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;修改hue的元数据库为mysql&quot;&gt;修改hue的元数据库为mysql&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;默认使用sqlite&lt;/li&gt;
  &lt;li&gt;如果不修改为Mysql hue 访问是会出现 &lt;code class=&quot;highlighter-rouge&quot;&gt;Database is locked&lt;/code&gt; 错误&lt;/li&gt;
  &lt;li&gt;需要注意: 一定要提前创建好 hue 数据库;之前在安装Ambari 时已经创建了所以此处不再列出;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;修改hueini-配置&quot;&gt;修改hue.ini 配置&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;需要修改两处配置项,参考图例&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hdp-hue-mysql.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    name=mysqldb
    engine=mysql
    host=db1.jevic.cn
    port=3306
    user=hue
    password=Hue@123456
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hdp-hue-mysql02.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    engine=mysql
    host=db1.jevic.cn
    port=3306
    user=hue
    password=Hue@123456
    name=hue
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;初始化数据库&quot;&gt;初始化数据库&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root@mdb2:/usr/share/hue/build/env# ./bin/hue syncdb
root@mdb2:/usr/share/hue/build/env# ./bin/hue migrate
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hue-init-mysql.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;重启服务:
 docker restart hue&lt;/p&gt;

&lt;p&gt;其他的配置项根据需要逐一调整即可,具体参数示例可参考&lt;a href=&quot;https://docs.gethue.com/administrator/configuration/connectors/&quot;&gt;官方文档&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;参考文档
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.jianshu.com/p/087404300cda&quot;&gt;Hue&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/zlslch/p/6819622.html?utm_source=itdadao&amp;amp;utm_medium=referral&quot;&gt;Hue 问题汇总&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Jevic</name></author><summary type="html">HUE是一个开源的Apache Hadoop UI系统，早期由Cloudera开发，后来贡献给开源社区。它是基于Python Web框架Django实现的。通过使用Hue我们可以通过浏览器方式操纵Hadoop集群。例如put、get、执行MapReduce Job等等</summary></entry><entry><title type="html">Ambari-Cluster配置(三)</title><link href="http://0.0.0.0/2020/03/07/ambari-cluster/" rel="alternate" type="text/html" title="Ambari-Cluster配置(三)" /><published>2020-03-07T20:35:06+08:00</published><updated>2020-03-07T20:35:06+08:00</updated><id>http://0.0.0.0/2020/03/07/ambari-cluster</id><content type="html" xml:base="http://0.0.0.0/2020/03/07/ambari-cluster/">&lt;h1 id=&quot;ambari-集群配置&quot;&gt;Ambari 集群配置&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hdp-install-01.png&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hdp-install-02.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;选择你需要安装的服务然后进入到配置界面&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;调整配置项&quot;&gt;调整配置项&lt;/h2&gt;
&lt;h3 id=&quot;hadoop-hue-依赖配置&quot;&gt;hadoop hue 依赖配置&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;检查确认是否有下列配置项,后面hue 要使用;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.gethue.com/administrator/configuration/connectors/#hdfs&quot;&gt;hue for HDFS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## core-site.xml
hadoop.proxyuser.falcon.groups=*
hadoop.proxyuser.falcon.hosts=*
hadoop.proxyuser.hbase.groups=*
hadoop.proxyuser.hbase.hosts=*
hadoop.proxyuser.hcat.groups=*
hadoop.proxyuser.hcat.hosts=*
hadoop.proxyuser.httpfs.groups=*
hadoop.proxyuser.httpfs.hosts=*
hadoop.proxyuser.hue.groups=*
hadoop.proxyuser.hue.hosts=*
hadoop.proxyuser.root.hosts=*
hadoop.proxyuser.root.groups=*
hadoop.proxyuser.yarn.hosts=*
hadoop.proxyuser.yarn.groups=*
hadoop.proxyuser.mapred.hosts=*
hadoop.proxyuser.mapred.groups=*

## hdfs-site.xml
# 关闭权限
dfs.permissions.enabled=false
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hdp-install-hadoop.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;hive&quot;&gt;Hive&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;连接数据库时使用,ambari 页面会有提示根据提示进行操作即可&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@dt1 ~]# ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java-5.1.48-bin.jar
Using python  /usr/bin/python
Setup ambari-server
Copying /usr/share/java/mysql-connector-java-5.1.48-bin.jar to /var/lib/ambari-server/resources
If you are updating existing jdbc driver jar for mysql with mysql-connector-java-5.1.48-bin.jar. Please remove the old driver jar, from all hosts. Restarting services that need the driver, will automatically copy the new jar to the hosts.
JDBC driver was successfully initialized.
Ambari Server 'setup' completed successfully.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hdp-install-hive.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;oozie&quot;&gt;Oozie&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.gethue.com/administrator/configuration/connectors/#apache-oozie&quot;&gt;hue oozie&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ambari 初始化安装时添加下列参数&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## oozie-site.xml
oozie.service.ProxyUserService.proxyuser.hive.groups=*
oozie.service.ProxyUserService.proxyuser.hive.hosts=*
oozie.service.ProxyUserService.proxyuser.hue.groups=*
oozie.service.ProxyUserService.proxyuser.hue.hosts=*
oozie.processing.timezone=GMT+0800
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hdp-install-oozie.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;最终安装结果如下图&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hdp-install-end.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;hadoop-ha&quot;&gt;Hadoop HA&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;ambari 默认安装hadoop时,没有启用HA 高可用,所以当安装完成后需要再次点击启用HA&lt;/li&gt;
  &lt;li&gt;参考&lt;a href=&quot;http://www.louisvv.com/archives/1490.html&quot;&gt;Ambari Hadoop安装启用HA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hdp-hadoop-ha-01.png&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hdp-hadoop-ha-02.png&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hdp-hadoop-ha-03.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;剩下的步骤根据提示一步步操作即可!&lt;/p&gt;

&lt;h2 id=&quot;yarn-ha&quot;&gt;yarn HA&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;与hadoop ha 一样点击开启HA,根据步骤操作即可&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;hadoop-httpfs&quot;&gt;hadoop-httpfs&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yum install -y hadoop-httpfs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;安装完成后,无法正常启动;原因是由于缺失相关目录:
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hadoop-httpfs-01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;打补丁:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;下载 &lt;a href=&quot;https://github.com/jevic/bigdata/blob/master/ambari/hadoop-httpfs_3.x_patch.tar.gz&quot;&gt;hadoop-httpfs_3.x_patch.tar.gz&lt;/a&gt;;解压后执行patch.sh&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;启动hadoop-httpfs&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## root用户操作
# mkdir -p /var/run/hadoop/httpfs
# chmod 777 /var/run/hadoop/httpfs
# /usr/hdp/current/hadoop-httpfs/etc/rc.d/init.d/hadoop-httpfs start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Jevic</name></author><summary type="html">Ambari 集群配置</summary></entry><entry><title type="html">Ambari-Server&amp;amp;agent安装配置(二)</title><link href="http://0.0.0.0/2020/03/07/ambari-server-install/" rel="alternate" type="text/html" title="Ambari-Server&amp;agent安装配置(二)" /><published>2020-03-07T18:56:06+08:00</published><updated>2020-03-07T18:56:06+08:00</updated><id>http://0.0.0.0/2020/03/07/ambari-server-install</id><content type="html" xml:base="http://0.0.0.0/2020/03/07/ambari-server-install/">&lt;h2 id=&quot;数据库配置&quot;&gt;数据库配置&lt;/h2&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;说明：数据库表名设置为大小写不敏感，修改mysql数据库配置文件my.cnf 即可

# mysql -u root -p123456 -e &quot;show variables like 'lower_case_table_names';&quot;
mysql: [Warning] Using a password on the command line interface can be insecure.
+------------------------+-------+
| Variable_name          | Value |
+------------------------+-------+
| lower_case_table_names | 1     |
+------------------------+-------+
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;创建数据库&quot;&gt;创建数据库&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;根据你需要安装的服务创建对应的数据库及配置访问信息;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;create database ambari character set utf8;
GRANT ALL PRIVILEGES ON ambari.* TO 'ambari'@'%' IDENTIFIED BY 'Ambari_123';
FLUSH PRIVILEGES;
create database hive character set latin1;
GRANT ALL PRIVILEGES ON hive.* TO 'hive'@'%' IDENTIFIED BY 'Hive@123';
FLUSH PRIVILEGES;
create database oozie character set utf8;
GRANT ALL PRIVILEGES ON oozie.* TO 'oozie'@'%' IDENTIFIED BY 'Oozie@123';
FLUSH PRIVILEGES;
create database ranger character set utf8;
GRANT ALL PRIVILEGES ON rangeradmin.* TO 'rangeradmin'@'%' IDENTIFIED BY 'Ranger@123';
FLUSH PRIVILEGES;
create database superset character set utf8;
GRANT ALL PRIVILEGES ON superset.* TO 'superset'@'%' IDENTIFIED BY 'Superset@123';
FLUSH PRIVILEGES;
create database hbase character set latin1;
GRANT ALL PRIVILEGES ON hbase.* TO 'hbase'@'%' IDENTIFIED BY 'Hbase@123';
FLUSH PRIVILEGES;

## hue 
create database hue character set utf8;
GRANT ALL PRIVILEGES ON hue.* TO 'hue'@'%' IDENTIFIED BY 'Hue@123456';
FLUSH PRIVILEGES;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;主机初始化&quot;&gt;主机初始化&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;JDK 安装&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;主机名配置
        &lt;ul&gt;
          &lt;li&gt;1.1.1.1 node.xxx.xx&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;双机互相&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    ssh-keygen -t rsa
    ssh-copy-id NODE_NAME
    ## 也可以使用sshpass 去除密码输入提示
    yum install -y sshpass
    sshpass PASSWORD -e ssh-copy-id NODE_NAME 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;初始化脚本:
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/jevic/bigdata/blob/master/ambari/initos.sh&quot;&gt;initos.sh&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ambari-server&quot;&gt;ambari-server&lt;/h2&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Current Version: 2.6.5.0-292 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;公共仓库]
http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.5.0
http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.22/repos/centos7


&lt;span class=&quot;c&quot;&gt;## &lt;/span&gt;
yum install ambari-server &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;## jdbc 驱动下载地址 &lt;/span&gt;
https://cdn.mysql.com//Downloads/Connector-J/mysql-connector-java-5.1.48.tar.gz
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;root@jevic-t01 ~]# &lt;span class=&quot;nb&quot;&gt;grep &lt;/span&gt;server.jdbc.driver.path /etc/ambari-server/conf/ambari.properties 
server.jdbc.driver.path&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/usr/share/java/mysql-connector-java-5.1.48-bin.jar


&lt;span class=&quot;c&quot;&gt;## 初始化安装&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;root@dt1 ~]# ambari-server setup
Using python  /usr/bin/python
Setup ambari-server
Checking SELinux...
SELinux status is &lt;span class=&quot;s1&quot;&gt;'disabled'&lt;/span&gt;
Customize user account &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;ambari-server daemon &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;y/n] &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;? y
Enter user account &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;ambari-server daemon &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;root&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:ambari
Adjusting ambari-server permissions and ownership...
Checking firewall status...
Checking JDK...
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;1] Oracle JDK 1.8 + Java Cryptography Extension &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;JCE&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; Policy Files 8
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;2] Oracle JDK 1.7 + Java Cryptography Extension &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;JCE&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; Policy Files 7
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;3] Custom JDK
&lt;span class=&quot;o&quot;&gt;==============================================================================&lt;/span&gt;
Enter choice &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;: 3
WARNING: JDK must be installed on all hosts and JAVA_HOME must be valid on all hosts.
WARNING: JCE Policy files are required &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;configuring Kerberos security. If you plan to use Kerberos,please make sure JCE Unlimited Strength Jurisdiction Policy Files are valid on all hosts.
Path to JAVA_HOME: /usr/local/java
Validating JDK on Ambari Server...done.
Checking GPL software agreement...
GPL License &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;LZO: https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html
Enable Ambari Server to download and install GPL Licensed LZO packages &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;y/n] &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;? n
Completing setup...
Configuring database...
Enter advanced database configuration &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;y/n] &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;? y
Configuring database...
&lt;span class=&quot;o&quot;&gt;==============================================================================&lt;/span&gt;
Choose one of the following options:
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;1] - PostgreSQL &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Embedded&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;2] - Oracle
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;3] - MySQL / MariaDB
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;4] - PostgreSQL
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;5] - Microsoft SQL Server &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Tech Preview&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;6] - SQL Anywhere
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;7] - BDB
&lt;span class=&quot;o&quot;&gt;==============================================================================&lt;/span&gt;
Enter choice &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;: 3
Hostname &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;localhost&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;: db1.jevic.cn
Port &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;3306&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:
Database name &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;ambari&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;: ambari
Username &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;ambari&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:
Enter Database Password &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;bigdata&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:
Re-enter password:
Configuring ambari database...
Configuring remote database connection properties...
WARNING: Before starting Ambari Server, you must run the following DDL against the database to create the schema: /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql
Proceed with configuring remote database connection properties &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;y/n] &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;y&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;?
Extracting system views...
ambari-admin-2.6.2.2.1.jar
...........
Adjusting ambari-server permissions and ownership...
Ambari Server &lt;span class=&quot;s1&quot;&gt;'setup'&lt;/span&gt; completed successfully.



&lt;span class=&quot;c&quot;&gt;## 将Ambari数据库脚本导入到数据库&lt;/span&gt;
mysql &lt;span class=&quot;nt&quot;&gt;-uambari&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-pxxx&lt;/span&gt;
use ambari&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql


&lt;span class=&quot;c&quot;&gt;## 启动ambari server&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# ambari-server start&lt;/span&gt;

在浏览器中访问ip:8080，默认登录名：admin 密码:admin
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;ambari-agent&quot;&gt;ambari-agent&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;配置yum 源
yum -y install ambari-agent

#ambari-agent 打ssl认证有问题，需要关闭
grep -q &quot;^force_https_protocol=PROTOCOL_TLSv1_2&quot; /etc/ambari-agent/conf/ambari-agent.ini ||sed -i 's@\[security\]@&amp;amp;\nforce_https_protocol=PROTOCOL_TLSv1_2@g' /etc/ambari-agent/conf/ambari-agent.ini

grep -q &quot;^verify=diable&quot; /etc/python/cert-verification.cfg || sed -i 's@\[https\]@&amp;amp;\nverify=diable@g' /etc/python/cert-verification.cfg 

/usr/sbin/ambari-agent reset ServiceNAME
/usr/sbin/ambari-agent start 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;后记&quot;&gt;后记&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;以下是在安装ambari 2.7.4时遇到的问题(安装方式一样)&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;初始化集群加入主机,状态一直为: preparing&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;解决方案: sudo chown -R ambari /var/run/ambari-server&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;HDFS 开启HA时报错 500&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;500 status code received on GET method for API: /api/v1/stacks/HDP/versions/2.4/recommendations 
Error message: Error occured during stack advisor command invocation: Cannot create /var/run/ambari-server/stack-recommendations&lt;/p&gt;

&lt;p&gt;解决方案：sudo chown -R ambari /var/run/ambari-server&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;ntpd 服务无法开机自启动
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/ambari-init-ntpd.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;解决方案: systemctl disable chronyd&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">数据库配置 ``` 说明：数据库表名设置为大小写不敏感，修改mysql数据库配置文件my.cnf 即可</summary></entry><entry><title type="html">Ambari-本地Yum源配置(一)</title><link href="http://0.0.0.0/2020/03/06/ambari-yum/" rel="alternate" type="text/html" title="Ambari-本地Yum源配置(一)" /><published>2020-03-06T18:56:06+08:00</published><updated>2020-03-06T18:56:06+08:00</updated><id>http://0.0.0.0/2020/03/06/ambari-yum</id><content type="html" xml:base="http://0.0.0.0/2020/03/06/ambari-yum/">&lt;h2 id=&quot;ambari概述&quot;&gt;Ambari概述&lt;/h2&gt;
&lt;p&gt;Apache Ambari是一种基于Web的工具，支持Apache Hadoop集群的创建、管理和监控。Ambari已支持大多数Hadoop组件，包括HDFS、MapReduce、Hive、Pig、 Hbase、Zookeeper、Sqoop和Hcatalog等；除此之外，Ambari还支持Spark、Storm等计算框架及资源调度平台YARN。&lt;/p&gt;

&lt;p&gt;Apache Ambari 从集群节点和服务收集大量信息，并把它们表现为容易使用的，集中化的接口：Ambari Web.&lt;/p&gt;

&lt;p&gt;Ambari Web显示诸如服务特定的摘要、图表以及警报信息。可通过Ambari Web对Hadoop集群进行创建、管理、监视、添加主机、更新服务配置等；也可以利用Ambari Web执行集群管理任务，例如启用 Kerberos 安全以及执行Stack升级。任何用户都可以查看Ambari Web特性。拥有administrator-level 角色的用户可以访问比 operator-level 或 view-only 的用户能访问的更多选项。例如，Ambari administrator 可以管理集群安全，一个 operator 用户可以监控集群，而 view-only 用户只能访问系统管理员授予他的必要的权限。&lt;/p&gt;

&lt;h2 id=&quot;ambari体系结构&quot;&gt;Ambari体系结构&lt;/h2&gt;
&lt;p&gt;Ambari 自身也是一个分布式架构的软件，主要由两部分组成：Ambari Server 和 Ambari Agent。简单来说，用户通过Ambari Server通知 Ambari Agent 安装对应的软件；Agent 会定时地发送各个机器每个软件模块的状态给 Ambari Server，最终这些状态信息会呈现在 Ambari 的 GUI，方便用户了解到集群的各种状态，并进行相应的维护。&lt;/p&gt;

&lt;p&gt;Ambari Server 从整个集群上收集信息。每个主机上都有 Ambari Agent, Ambari Server 通过 Ambari Agent 控制每部主机。&lt;/p&gt;

&lt;h2 id=&quot;配置本地yum源&quot;&gt;配置本地YUM源&lt;/h2&gt;
&lt;h2 id=&quot;参考文档&quot;&gt;参考文档&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;https://docs.cloudera.com/HDPDocuments&lt;/li&gt;
  &lt;li&gt;https://docs.cloudera.com/HDPDocuments/Ambari-2.7.5.0/bk_ambari-installation/content/ambari_repositories.html&lt;/li&gt;
  &lt;li&gt;https://docs.cloudera.com/HDPDocuments/Ambari-2.7.5.0/bk_ambari-installation/content/hdp_315_repositories.html&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;目录结构&quot;&gt;目录结构&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@192-168-5-12 ~]# mkdir -p /tmp/temp
 
 
wget -N http://192.168.12.62/ambari/ambari2.6.2.2/HDP-2.6.5.0-centos7-rpm.tar.gz -P /tmp/temp/
wget -N  http://192.168.12.62/ambari/ambari2.6.2.2/HDP-GPL-2.6.5.0-centos7-gpl.tar.gz -P /tmp/temp/
wget -N  http://192.168.12.62/ambari/ambari2.6.2.2/HDP-UTILS-1.1.0.22-centos7.tar.gz -P /tmp/temp/
wget -N  http://192.168.12.62/ambari/ambari2.6.2.2/ambari-2.6.2.2-centos7.tar.gz -P /tmp/temp/
 
 
[root@192-168-5-12 ~]# for file in `ls -1 /tmp/temp/*.tar.gz` ; do tar -xzvf $file -C /tmp/temp/ ; done ;
 
 
 
[root@192-168-5-12 ~]#  mkdir -p /data/wwwroot/yum/{ambari,hdp,hdp-utils,hdp-gpl}
 
 
mv /tmp/temp/ambari/centos7/2.6.2.2-1/* /data/wwwroot/yum/ambari/
mv /tmp/temp/HDP/centos7/2.6.5.0-292/* /data/wwwroot/yum/hdp/
mv /tmp/temp/HDP-GPL/centos7/2.6.5.0-292/* /data/wwwroot/yum/hdp-gpl/
mv /tmp/temp/HDP-UTILS/centos7/1.1.0.22/* /data/wwwroot/yum//hdp-utils/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@yum ambari2.7.4]# pwd
/data/wwwroot/yum/ambari2.7.4
[root@yum ambari2.7.4]# tree -d -L 2
.
├── ambari
│   ├── ambari
│   ├── repodata
│   ├── RPM-GPG-KEY
│   ├── smartsense
│   └── tars
├── hdp
│   ├── accumulo
│   ├── atlas
│   ├── bigtop-jsvc
│   ├── bigtop-tomcat
│   ├── datafu
│   ├── druid
│   ├── hadoop
│   ├── hbase
│   ├── hdp-select
│   ├── hive
│   ├── hive_warehouse_connector
│   ├── kafka
│   ├── knox
│   ├── livy
│   ├── oozie
│   ├── phoenix
│   ├── pig
│   ├── ranger
│   ├── repodata
│   ├── RPM-GPG-KEY
│   ├── shc
│   ├── spark2
│   ├── spark_atlas_connector
│   ├── spark_schema_registry
│   ├── sqoop
│   ├── storm
│   ├── superset
│   ├── tez
│   ├── vrpms
│   ├── zeppelin
│   └── zookeeper
├── hdp-gpl
│   ├── hadooplzo
│   ├── repodata
│   ├── RPM-GPG-KEY
│   └── vrpms
└── hdp-utils
    ├── openblas
    ├── repodata
    ├── RPM-GPG-KEY
    └── snappy

48 directories
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;nginx-server配置&quot;&gt;nginx server配置&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
server {
        listen       80;
        server_name  localhost;
        location / {
            #root   /data/wwwroot/yum;
	    root /data/wwwroot/yum ;
            charset utf-8;
	    autoindex on;
            # set to on means use localtime
            autoindex_localtime on;
            # show size with unit 'MB' instead of 'Byte'
            autoindex_exact_size off;
            index  index.html index.htm;
        }
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
    }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;repo文件&quot;&gt;repo文件&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@s03 yum.repos.d]# cat ambari.repo
#VERSION_NUMBER=2.7.4.0-118
[ambari-2.7.4.0]
#json.url = http://public-repo-1.hortonworks.com/HDP/hdp_urlinfo.json
name=ambari Version - ambari-2.7.4.0
#baseurl=http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.7.4.0
baseurl=http://192.168.12.70/ambari2.7.4/ambari/
gpgcheck=1
#gpgkey=http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.7.4.0/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins
gpgkey=http://192.168.12.70/ambari2.7.4/ambari/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins
enabled=1
priority=1


[root@s03 yum.repos.d]# cat hdp*repo

#VERSION_NUMBER=3.1.4.0-315
[HDP-GPL-3.1.4.0]
name=HDP-GPL Version - HDP-GPL-3.1.4.0
#baseurl=http://public-repo-1.hortonworks.com/HDP-GPL/centos7/3.x/updates/3.1.4.0
baseurl=http://192.168.12.70/ambari2.7.4/hdp-gpl
gpgcheck=1
#gpgkey=http://public-repo-1.hortonworks.com/HDP-GPL/centos7/3.x/updates/3.1.4.0/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins
gpgkey=http://192.168.12.70/ambari2.7.4/hdp-gpl/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins
enabled=1
priority=1

#VERSION_NUMBER=3.1.4.0-315
[HDP-3.1.4.0]
name=HDP Version - HDP-3.1.4.0
#baseurl=http://public-repo-1.hortonworks.com/HDP/centos7/3.x/updates/3.1.4.0
baseurl=http://192.168.12.70/ambari2.7.4/hdp/
gpgcheck=1
#gpgkey=http://public-repo-1.hortonworks.com/HDP/centos7/3.x/updates/3.1.4.0/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins
gpgkey=http://192.168.12.70/ambari2.7.4/hdp/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins
enabled=1
priority=1


[HDP-UTILS-1.1.0.22]
name=HDP-UTILS Version - HDP-UTILS-1.1.0.22
#baseurl=http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.22/repos/centos7
baseurl=http://192.168.12.70/ambari2.7.4/hdp-utils
gpgcheck=1
#gpgkey=http://public-repo-1.hortonworks.com/HDP/centos7/3.x/updates/3.1.4.0/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins
gpgkey=http://192.168.12.70/ambari2.7.4/hdp-utils/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins
enabled=1
priority=1

[HDP-UTILS-1.1.0.22]
name=Hortonworks Data Platform Utils Version - HDP-UTILS-1.1.0.22
#baseurl=http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.22/repos/centos7
baseurl=http://192.168.12.70/ambari2.7.4/hdp-utils
gpgcheck=1
enabled=0
priority=1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Jevic</name></author><summary type="html">Ambari概述 Apache Ambari是一种基于Web的工具，支持Apache Hadoop集群的创建、管理和监控。Ambari已支持大多数Hadoop组件，包括HDFS、MapReduce、Hive、Pig、 Hbase、Zookeeper、Sqoop和Hcatalog等；除此之外，Ambari还支持Spark、Storm等计算框架及资源调度平台YARN。</summary></entry><entry><title type="html">Elastic Stack 7.x 初识</title><link href="http://0.0.0.0/2019/11/06/elk-7-release/" rel="alternate" type="text/html" title="Elastic Stack 7.x 初识" /><published>2019-11-06T18:56:06+08:00</published><updated>2019-11-06T18:56:06+08:00</updated><id>http://0.0.0.0/2019/11/06/elk-7-release</id><content type="html" xml:base="http://0.0.0.0/2019/11/06/elk-7-release/">&lt;h3 id=&quot;概述&quot;&gt;概述&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;2019年04月25日 &lt;a href=&quot;https://www.elastic.co/cn/blog/elastic-stack-7-0-0-released&quot;&gt;Elastic Stack 7.0.0 重磅发布&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;2019年10月02日 &lt;a href=&quot;https://www.elastic.co/cn/blog/elastic-stack-7-4-0-released&quot;&gt;Elastic Stack 7.4.0 重磅发布&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;关系型数据库与 Elasticsearch 的抽象与类比
    &lt;ul&gt;
      &lt;li&gt;在7.0 版本之前,一个index 可以设置多个 &lt;code class=&quot;highlighter-rouge&quot;&gt;Types&lt;/code&gt;;&lt;/li&gt;
      &lt;li&gt;7.0 以后一个索引只能创建一个 &lt;code class=&quot;highlighter-rouge&quot;&gt;Type =&amp;gt; &quot;_doc&quot;&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;RDBMS&lt;/th&gt;
      &lt;th&gt;Elasticsearch&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Table&lt;/td&gt;
      &lt;td&gt;Index(Type)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Row&lt;/td&gt;
      &lt;td&gt;Document&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Column&lt;/td&gt;
      &lt;td&gt;Filed&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Schema&lt;/td&gt;
      &lt;td&gt;Mapping&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;SQL&lt;/td&gt;
      &lt;td&gt;DSL&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;关键特性&quot;&gt;关键特性&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;全新设计和导航……还有夜间模式&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/cn/blog/a-new-era-for-cluster-coordination-in-elasticsearch&quot;&gt;Elasticsearch 集群协调迎来新时代&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/cn/blog/improving-node-resiliency-with-the-real-memory-circuit-breaker&quot;&gt;使用真实内存断路器提高节点弹性&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/cn/subscriptions&quot;&gt;Elastic Stack 订阅&lt;/a&gt;
 核心安全功能 免费、免费、免费!!&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;安装配置&quot;&gt;安装配置&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;详细的 安装配置说明可参考 &lt;a href=&quot;https://www.jevic.cn/2017/01/23/elk-elasticsearch-install-5x/&quot;&gt;Elasticsearch 5.x 集群配置&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Download 7.4.2
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.4.2-linux-x86_64.tar.gz&quot;&gt;elasticsearch&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://artifacts.elastic.co/downloads/kibana/kibana-7.4.2-linux-x86_64.tar.gz&quot;&gt;kibana&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://artifacts.elastic.co/downloads/logstash/logstash-7.4.2.tar.gz&quot;&gt;logstash&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Beat&lt;/code&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.4.2-linux-x86_64.tar.gz&quot;&gt;filebeat&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-7.4.2-linux-x86_64.tar.gz&quot;&gt;metricbeat&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://artifacts.elastic.co/downloads/beats/auditbeat/auditbeat-7.4.2-linux-x86_64.tar.gz&quot;&gt;auditbeat&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://artifacts.elastic.co/downloads/beats/heartbeat/heartbeat-7.4.2-linux-x86_64.tar.gz&quot;&gt;heartbeat&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;elasticsearch&quot;&gt;Elasticsearch&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;此处使用的版本为: &lt;code class=&quot;highlighter-rouge&quot;&gt;7.4.2&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;提示: OpenJDK 已经内置 &lt;code class=&quot;highlighter-rouge&quot;&gt;$ES_PATH/jdk&lt;/code&gt; &lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/current/setup.html#jvm-version&quot;&gt;JAVA (JVM)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;系统配置&quot;&gt;系统配置&lt;/h5&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@jevic ~]# cat /etc/security/limits.conf
* soft nofile 65536
* hard nofile 65536
* soft nproc unlimited
* hard nproc unlimited
es soft memlock unlimited
es hard memlock unlimited

[root@jevic ~]# cat /etc/security/limits.d/20-nproc.conf
# Default limit for number of user's processes to prevent
# accidental fork bombs.
# See rhbz #432903 for reasoning.

*          soft    nproc     102400
root       soft    nproc     unlimited
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;elasticsearchyml&quot;&gt;elasticsearch.yml&lt;/h5&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cluster.name: JevicTestDB
node.name: node194
node.master: true
node.data: true
path.data: /es-data1/data
bootstrap.memory_lock: true
network.host: 192.168.0.194
http.port: 9200
discovery.zen.minimum_master_nodes: 2
discovery.seed_hosts: [&quot;node194&quot;, &quot;node198&quot;, &quot;node204&quot;]
#discovery.seed_providers: unicast_hosts.txt
## 重试间隔
discovery.find_peers_interval: 1s
cluster.initial_master_nodes: [&quot;node194&quot;, &quot;node198&quot;, &quot;node204&quot;]
### sql插件支持
http.cors.enabled: true
http.cors.allow-origin: &quot;*&quot;
#### 必须停用xpack sql才可以使用elasticsearch-sql
xpack.sql.enabled: false
### 开启认证:
### 初始化认证: $ES_PATH/bin/elasticsearch-setup-passwords interactive
#xpack.security.enabled: true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;kibana&quot;&gt;Kibana&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;server.name: kibana
server.host: &quot;0&quot;
elasticsearch.hosts: [ &quot;http://elasticsearch:9200&quot; ]
### 开启认证
#xpack.security.enabled: true
#elasticsearch.username: &quot;kibana&quot;
#elasticsearch.password: &quot;123456&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;logstash&quot;&gt;Logstash&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;收集 NGINX 日志&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;日志格式&quot;&gt;日志格式&lt;/h5&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;log_format  json '{&quot;cip&quot;:&quot;$remote_addr&quot;,'
                            '&quot;timestamp&quot;:&quot;$time_iso8601&quot;,'
                            '&quot;rtime&quot;:$request_time,'
                            '&quot;upres_time&quot;:$upstream_response_time,'
                            '&quot;sbyte&quot;:$body_bytes_sent,'
                            '&quot;host&quot;:&quot;$http_host&quot;,'
                            '&quot;request&quot;:&quot;$request&quot;,'
                            '&quot;scheme&quot;:&quot;$scheme&quot;,'
                            '&quot;length&quot;:&quot;$content_length&quot;,'
                            '&quot;server&quot;:&quot;$upstream_addr&quot;,'
                            '&quot;method&quot;:&quot;$request_method&quot;,'
                            '&quot;status&quot;:$status}';
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;pipe-配置&quot;&gt;pipe 配置&lt;/h5&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;input{
    file {
        path =&amp;gt; [ &quot;/var/log/nginx/es_access.log&quot; ]
        start_position =&amp;gt; &quot;beginning&quot;
        codec =&amp;gt; &quot;json&quot;
    }
}

filter {
  date {
    match =&amp;gt; [ &quot;timestamp&quot;, &quot;ISO8601&quot; ]
    target =&amp;gt; &quot;@timestamp&quot;
  }
  mutate {
    split =&amp;gt; { &quot;request&quot; =&amp;gt; &quot; &quot; }
    add_field =&amp;gt; { &quot;url&quot; =&amp;gt; &quot;%{[request][1]}&quot;}
  }
  mutate {
    remove_field =&amp;gt; [ &quot;path&quot;, &quot;tags&quot;, &quot;request&quot;]
  }
}

output {
    #elasticsearch {
    #    hosts =&amp;gt; [ &quot;192.168.0.194:9200&quot; ]
    #    index =&amp;gt; &quot;nginx-%{+YYYY.MM.dd}&quot;
    #}
     stdout {
	       codec =&amp;gt; rubydebug
     }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;ps: &lt;a href=&quot;https://www.elastic.co/guide/en/logstash/current/plugins-filters-mutate.html&quot;&gt;filters-mutate&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;扩展阅读&quot;&gt;扩展阅读&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/cn/blog/how-to-monitor-nginx-web-servers-with-the-elastic-stack&quot;&gt;如何使用 Elastic Stack 监测 Nginx Web 服务器&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/cn/blog/monitoring-kafka-with-elasticsearch-kibana-and-beats&quot;&gt;通过 Elasticsearch、Kibana 和 Beats 监测 Kafka&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;关于 &lt;a href=&quot;https://github.com/NLPchina/elasticsearch-sql/wiki&quot;&gt;elasticsearch-sql&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/lmenezes/cerebro&quot;&gt;cerebro&lt;/a&gt; 插件的安装部署请移步Github&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Jevic</name></author><summary type="html">概述 2019年04月25日 Elastic Stack 7.0.0 重磅发布 2019年10月02日 Elastic Stack 7.4.0 重磅发布</summary></entry><entry><title type="html">Kubernetes Pod 异常排查处理</title><link href="http://0.0.0.0/2019/08/30/kubernetes-pod-error/" rel="alternate" type="text/html" title="Kubernetes Pod 异常排查处理" /><published>2019-08-30T18:56:06+08:00</published><updated>2019-08-30T18:56:06+08:00</updated><id>http://0.0.0.0/2019/08/30/kubernetes-pod-error</id><content type="html" xml:base="http://0.0.0.0/2019/08/30/kubernetes-pod-error/">&lt;blockquote&gt;
  &lt;p&gt;一般来说，无论 Pod 处于什么异常状态，都可以执行以下命令来查看 Pod 的状态&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get pod &amp;lt;pod-name&amp;gt; -o yaml 查看 Pod 的配置是否正确
kubectl describe pod &amp;lt;pod-name&amp;gt; 查看 Pod 的事件
kubectl logs &amp;lt;pod-name&amp;gt; [-c &amp;lt;container-name&amp;gt;] 查看容器日志
这些事件和日志通常都会有助于排查 Pod 发生的问题。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;pod-一直处于-pending-状态&quot;&gt;Pod 一直处于 Pending 状态&lt;/h3&gt;
&lt;p&gt;Pending 说明 Pod 还没有调度到某个 Node 上面。可以通过 &lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl describe pod &amp;lt;pod-name&amp;gt;&lt;/code&gt;命令查看到当前 Pod 的事件，进而判断为什么没有调度。可能的原因包括&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;资源不足，集群内所有的 Node 都不满足该 Pod 请求的 CPU、内存、GPU 等资源&lt;/li&gt;
  &lt;li&gt;HostPort 已被占用，通常推荐使用 Service 对外开放服务端口&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pod-一直处于-waiting-或-containercreating-状态&quot;&gt;Pod 一直处于 Waiting 或 ContainerCreating 状态&lt;/h3&gt;
&lt;p&gt;首先还是通过 &lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl describe pod &amp;lt;pod-name&amp;gt;&lt;/code&gt; 命令查看到当前 Pod 的事件。可能的原因包括&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;镜像拉取失败，比如
    &lt;ul&gt;
      &lt;li&gt;配置了错误的镜像&lt;/li&gt;
      &lt;li&gt;Kubelet 无法访问镜像（国内环境访问 gcr.io 需要特殊处理）&lt;/li&gt;
      &lt;li&gt;私有镜像的密钥配置错误&lt;/li&gt;
      &lt;li&gt;镜像太大，拉取超时（可以适当调整 kubelet 的 –image-pull-progress-deadline 和 –runtime-request-timeout 选项）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;CNI 网络错误，一般需要检查 CNI 网络插件的配置，比如
    &lt;ul&gt;
      &lt;li&gt;无法配置 Pod 网络&lt;/li&gt;
      &lt;li&gt;无法分配 IP 地址&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;容器无法启动，需要检查是否打包了正确的镜像或者是否配置了正确的容器参数&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pod-处于-imagepullbackoff-状态&quot;&gt;Pod 处于 ImagePullBackOff 状态&lt;/h3&gt;
&lt;p&gt;这通常是镜像名称配置错误或者私有镜像的密钥配置错误导致。这种情况可以使用 docker pull &lt;image&gt; 来验证镜像是否可以正常拉取。&lt;/image&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果是私有镜像，需要首先创建一个 docker-registry 类型的 Secret&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create secret docker-registry my-secret --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAIL
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;然后在容器中引用这个 Secret&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spec:
  containers:
  - name: private-reg-container
    image: &amp;lt;your-private-image&amp;gt;
  imagePullSecrets:
  - name: my-secret
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;pod-一直处于-crashloopbackoff-状态&quot;&gt;Pod 一直处于 CrashLoopBackOff 状态&lt;/h3&gt;
&lt;p&gt;CrashLoopBackOff 状态说明容器曾经启动了，但又异常退出了。此时可以先查看一下容器的日志&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl logs &amp;lt;pod-name&amp;gt;
kubectl logs --previous &amp;lt;pod-name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;这里可以发现一些容器退出的原因，比如
    &lt;ul&gt;
      &lt;li&gt;容器进程退出&lt;/li&gt;
      &lt;li&gt;健康检查失败退出&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;此时如果还未发现线索，还可以到容器内执行命令来进一步查看退出原因&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl exec cassandra -- cat /var/log/cassandra/system.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;如果还是没有线索，那就需要 SSH 登录该 Pod 所在的 Node 上，查看 Kubelet 或者 Docker 的日志进一步排查了&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 查询 Node
kubectl get pod &amp;lt;pod-name&amp;gt; -o wide
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;pod-处于-error-状态&quot;&gt;Pod 处于 Error 状态&lt;/h3&gt;
&lt;p&gt;通常处于 Error 状态说明 Pod 启动过程中发生了错误。常见的原因包括&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;依赖的 ConfigMap、Secret 或者 PV 等不存在&lt;/li&gt;
  &lt;li&gt;请求的资源超过了管理员设置的限制，比如超过了 LimitRange 等&lt;/li&gt;
  &lt;li&gt;违反集群的安全策略，比如违反了 PodSecurityPolicy 等&lt;/li&gt;
  &lt;li&gt;容器无权操作集群内的资源，比如开启 RBAC 后，需要为 ServiceAccount 配置角色绑定&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pod-处于-terminating-或-unknown-状态&quot;&gt;Pod 处于 Terminating 或 Unknown 状态&lt;/h3&gt;
&lt;p&gt;从 v1.5 开始，Kubernetes 不会因为 Node 失联而删除其上正在运行的 Pod，而是将其标记为 Terminating 或 Unknown 状态。想要删除这些状态的 Pod 有三种方法：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;从集群中删除该 Node。使用公有云时，kube-controller-manager 会在 VM 删除后自动删除对应的 Node。而在物理机部署的集群中，需要管理员手动删除 Node（如 kubectl delete node &lt;node-name&gt;。&lt;/node-name&gt;&lt;/li&gt;
  &lt;li&gt;Node 恢复正常。Kubelet 会重新跟 kube-apiserver 通信确认这些 Pod 的期待状态，进而再决定删除或者继续运行这些 Pod。&lt;/li&gt;
  &lt;li&gt;用户强制删除。用户可以执行 &lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl delete pods &amp;lt;pod&amp;gt; --grace-period=0 --force&lt;/code&gt; 强制删除 Pod。除非明确知道 Pod 的确处于停止状态（比如 Node 所在 VM 或物理机已经关机），否则不建议使用该方法。特别是 StatefulSet 管理的 Pod，强制删除容易导致脑裂或者数据丢失等问题。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pod-行为异常&quot;&gt;Pod 行为异常&lt;/h3&gt;
&lt;p&gt;这里所说的行为异常是指 Pod 没有按预期的行为执行，比如没有运行 podSpec 里面设置的命令行参数。这一般是 podSpec yaml 文件内容有误，可以尝试使用 –validate 参数重建容器，比如&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl delete pod mypod
kubectl create --validate -f mypod.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;也可以查看创建后的 podSpec 是否是对的，比如&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get pod mypod -o yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;修改静态-pod-的-manifest-后未自动重建&quot;&gt;修改静态 Pod 的 Manifest 后未自动重建&lt;/h3&gt;
&lt;p&gt;Kubelet 使用 inotify 机制检测 /etc/kubernetes/manifests 目录（可通过 Kubelet 的 –pod-manifest-path 选项指定）中静态 Pod 的变化，并在文件发生变化后重新创建相应的 Pod。但有时也会发生修改静态 Pod 的 Manifest 后未自动创建新 Pod 的情景，此时一个简单的修复方法是重启 Kubelet。&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">一般来说，无论 Pod 处于什么异常状态，都可以执行以下命令来查看 Pod 的状态</summary></entry></feed>