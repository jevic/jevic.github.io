<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="http://0.0.0.0/feed.xml" rel="self" type="application/atom+xml" /><link href="http://0.0.0.0/" rel="alternate" type="text/html" /><updated>2020-04-17T13:56:29+08:00</updated><id>http://0.0.0.0/</id><title type="html">Jevic</title><subtitle>......</subtitle><author><name>Jevic</name></author><entry><title type="html">Oozie-YARN异常YarnException:Failed while publishing entity的解决方案</title><link href="http://0.0.0.0/2020/03/30/oozie-yarn-error/" rel="alternate" type="text/html" title="Oozie-YARN异常YarnException:Failed while publishing entity的解决方案" /><published>2020-03-30T18:56:06+08:00</published><updated>2020-03-30T18:56:06+08:00</updated><id>http://0.0.0.0/2020/03/30/oozie-yarn-error</id><content type="html" xml:base="http://0.0.0.0/2020/03/30/oozie-yarn-error/">&lt;p&gt;版本: HDP 3.1.4
Mapreduce提交任务计算时，job已经结束，但是容器仍不能关闭持续等待五分钟;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2020-03-30 21:09:30,393 INFO [Thread-75] org.apache.hadoop.yarn.event.AsyncDispatcher: Waiting for AsyncDispatcher to drain. Thread state is :WAITING
2020-03-30 21:09:30,494 INFO [Thread-75] org.apache.hadoop.yarn.event.AsyncDispatcher: Waiting for AsyncDispatcher to drain. Thread state is :WAITING
2020-03-30 21:09:30,594 INFO [Thread-75] org.apache.hadoop.yarn.event.AsyncDispatcher: Waiting for AsyncDispatcher to drain. Thread state is :WAITING
2020-03-30 21:09:30,694 INFO [Thread-75] org.apache.hadoop.yarn.event.AsyncDispatcher: Waiting for AsyncDispatcher to drain. Thread state is :WAITING
2020-03-30 21:09:30,794 INFO [Thread-75] org.apache.hadoop.yarn.event.AsyncDispatcher: Waiting for AsyncDispatcher to drain. Thread state is :WAITING
2020-03-30 21:09:30,819 ERROR [Job ATS Event Dispatcher] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Failed to process Event JOB_FINISHED for the job : job_1585569116633_0009
org.apache.hadoop.yarn.exceptions.YarnException: Failed while publishing entity
	at org.apache.hadoop.yarn.client.api.impl.TimelineV2ClientImpl$TimelineEntityDispatcher.dispatchEntities(TimelineV2ClientImpl.java:548)
	at org.apache.hadoop.yarn.client.api.impl.TimelineV2ClientImpl.putEntities(TimelineV2ClientImpl.java:149)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.processEventForNewTimelineService(JobHistoryEventHandler.java:1405)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleTimelineEvent(JobHistoryEventHandler.java:742)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.access$1200(JobHistoryEventHandler.java:93)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler$ForwardingEventHandler.handle(JobHistoryEventHandler.java:1795)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler$ForwardingEventHandler.handle(JobHistoryEventHandler.java:1791)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:197)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:126)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.sun.jersey.api.client.ClientHandlerException: java.net.SocketTimeoutException: Read timed out
	at com.sun.jersey.client.urlconnection.URLConnectionClientHandler.handle(URLConnectionClientHandler.java:155)
	at com.sun.jersey.api.client.Client.handle(Client.java:652)
	at com.sun.jersey.api.client.WebResource.handle(WebResource.java:682)
	at com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74)
	at com.sun.jersey.api.client.WebResource$Builder.put(WebResource.java:539)
	at org.apache.hadoop.yarn.client.api.impl.TimelineV2ClientImpl.doPutObjects(TimelineV2ClientImpl.java:291)
	at org.apache.hadoop.yarn.client.api.impl.TimelineV2ClientImpl.access$000(TimelineV2ClientImpl.java:66)
	at org.apache.hadoop.yarn.client.api.impl.TimelineV2ClientImpl$1.run(TimelineV2ClientImpl.java:302)
	at org.apache.hadoop.yarn.client.api.impl.TimelineV2ClientImpl$1.run(TimelineV2ClientImpl.java:299)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hue-oozie01.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hue-oozie02.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hue-oozie3.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hue-oozie03.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;发生这种情况是因为来自ATSv2的嵌入式HBASE崩溃。
需要重置ATsv2内嵌HBASE数据库&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;停止yarn服务&quot;&gt;停止Yarn服务&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Ambari - &amp;gt; Yarn-Actions- &amp;gt; Stop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;删除zookeeper-上的atsv2-znode&quot;&gt;删除zookeeper 上的ATSv2 Znode&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@ ~]# cd /usr/hdp/3.1.4.0-315/zookeeper/bin
[root@ bin]# ./zkCli.sh
......
[zk: localhost:2181(CONNECTED) 1] rmr /atsv2-hbase-unsecure
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;删除hdfs时间线服务目录内的hbase数据&quot;&gt;删除HDFS时间线服务目录内的hbase数据&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[hdfs@s05 ~]$ hdfs dfs -rm -r /atsv2/hbase
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;启动yarn服务&quot;&gt;启动Yarn服务&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Ambari - &amp;gt; Yarn-Actions- &amp;gt; Start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;再次提交服务&quot;&gt;再次提交服务&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hue-oozie04.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">版本: HDP 3.1.4 Mapreduce提交任务计算时，job已经结束，但是容器仍不能关闭持续等待五分钟;</summary></entry><entry><title type="html">Ambari安装oozie UI无法显示</title><link href="http://0.0.0.0/2020/03/17/oozie-ui/" rel="alternate" type="text/html" title="Ambari安装oozie UI无法显示" /><published>2020-03-17T18:56:06+08:00</published><updated>2020-03-17T18:56:06+08:00</updated><id>http://0.0.0.0/2020/03/17/oozie-ui</id><content type="html" xml:base="http://0.0.0.0/2020/03/17/oozie-ui/">&lt;blockquote&gt;
  &lt;p&gt;如下图所示,无法正常显示UI界面&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/oozie-web.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;1-停止oozie-服务&quot;&gt;1. 停止oozie 服务&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/oozie02.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-下载扩展包&quot;&gt;2. 下载扩展包&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@dt-hdp01 libext]# pwd
/usr/hdp/3.1.4.0-315/oozie/libext
[root@dt-hdp01 libext]# rm -rf ext-2.2  #如果已经存在的删除即可
[root@dt-hdp01 libext]# wget http://archive.cloudera.com/gplextras/misc/ext-2.2.zip
[root@dt-hdp01 libext]# unzip -q ext-2.2.zip 
[root@dt-hdp01 libext]# chown oozie.hadoop ext-2.2 -R
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;3-删除旧页面文件&quot;&gt;3. 删除旧页面文件&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@dt-hdp01 webapps]# pwd
/usr/hdp/current/oozie-server/oozie-server/webapps
[root@dt-hdp01 webapps]# rm -rf oozie oozie.war 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;4-重新编译生成war包&quot;&gt;4. 重新编译生成war包&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@dt-hdp01 bin]# pwd
/usr/hdp/current/oozie-server/bin
[root@dt-hdp01 bin]# ./oozie-setup.sh prepare-war
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/oozie01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;5-启动oozie访问web页面即可&quot;&gt;5. 启动oozie,访问web页面即可&lt;/h3&gt;

&lt;h3 id=&quot;其他说明&quot;&gt;其他说明:&lt;/h3&gt;
&lt;p&gt;关于ext-2.2 目录的位置;
根据步骤3 当中所示的软连接地址把下载的包放置到对应位置即可;
其他集群管理工具安装的oozie大致一样;&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">如下图所示,无法正常显示UI界面</summary></entry><entry><title type="html">Hue</title><link href="http://0.0.0.0/2020/03/16/hue/" rel="alternate" type="text/html" title="Hue" /><published>2020-03-16T18:56:06+08:00</published><updated>2020-03-16T18:56:06+08:00</updated><id>http://0.0.0.0/2020/03/16/hue</id><content type="html" xml:base="http://0.0.0.0/2020/03/16/hue/">&lt;p&gt;HUE是一个开源的Apache Hadoop UI系统，早期由Cloudera开发，后来贡献给开源社区。它是基于Python Web框架Django实现的。通过使用Hue我们可以通过浏览器方式操纵Hadoop集群。例如put、get、执行MapReduce Job等等&lt;/p&gt;

&lt;h2 id=&quot;安装&quot;&gt;安装&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;官网提供的只是源码只能编译安装(太耗时)&lt;/li&gt;
  &lt;li&gt;直接使用CDH 的发行版本&lt;a href=&quot;https://docs.cloudera.com/documentation/enterprise/6/release-notes/topics/rg_cm_6_version_download.html#cm_6_version_download&quot;&gt;cm_6_version_download&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Docker 或者 kubernetes 部署 (优选)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;docker-方式部署&quot;&gt;Docker 方式部署&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;关于镜像
    &lt;ul&gt;
      &lt;li&gt;由于官方镜像实在是太大网络不好的根本很难正常下载;&lt;/li&gt;
      &lt;li&gt;这里使用阿里云镜像仓库进行FROM 构建&lt;/li&gt;
      &lt;li&gt;在从阿里云镜像拉取会快很多&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# cat Dockerfile
FROM gethue/hue:latest
ENV US jevic

....
docker pull registry.cn-shenzhen.aliyuncs.com/jevic/hue:v1
docker tag registry.cn-shenzhen.aliyuncs.com/jevic/hue:v1 hue
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;为了修改配置文件方便,可将配置文件进行挂载；&lt;/li&gt;
  &lt;li&gt;挂载之前先将镜像的配置文件目录拷贝出来&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# docker run -it hue /bin/bash
另外打开一个终端: 
# docker cp hue:/usr/share/hue/desktop/conf /opt/hue/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;启动hue
    &lt;ul&gt;
      &lt;li&gt;如果使用默认桥接网络你需要显示的指明hostname:&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--add-host=db1.jevic.cn:192.168.1.1&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;否则容器内部无法进行域名解析&lt;/li&gt;
      &lt;li&gt;这里使用host 模式所以无需指定&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# cat run.hue.sh
docker run -it -d \
--name hue \
--network host \
-v /opt/hue/conf:/usr/share/hue/desktop/conf \
hue
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;修改hue的元数据库为mysql&quot;&gt;修改hue的元数据库为mysql&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;默认使用sqlite&lt;/li&gt;
  &lt;li&gt;如果不修改为Mysql hue 访问是会出现 &lt;code class=&quot;highlighter-rouge&quot;&gt;Database is locked&lt;/code&gt; 错误&lt;/li&gt;
  &lt;li&gt;需要注意: 一定要提前创建好 hue 数据库;之前在安装Ambari 时已经创建了所以此处不再列出;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;修改hueini-配置&quot;&gt;修改hue.ini 配置&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;需要修改两处配置项,参考图例&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hdp-hue-mysql.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    name=mysqldb
    engine=mysql
    host=db1.jevic.cn
    port=3306
    user=hue
    password=Hue@123456
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hdp-hue-mysql02.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    engine=mysql
    host=db1.jevic.cn
    port=3306
    user=hue
    password=Hue@123456
    name=hue
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;初始化数据库&quot;&gt;初始化数据库&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root@mdb2:/usr/share/hue/build/env# ./bin/hue syncdb
root@mdb2:/usr/share/hue/build/env# ./bin/hue migrate
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hue-init-mysql.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;重启服务:
 docker restart hue&lt;/p&gt;

&lt;p&gt;其他的配置项根据需要逐一调整即可,具体参数示例可参考&lt;a href=&quot;https://docs.gethue.com/administrator/configuration/connectors/&quot;&gt;官方文档&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;参考文档
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.jianshu.com/p/087404300cda&quot;&gt;Hue&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/zlslch/p/6819622.html?utm_source=itdadao&amp;amp;utm_medium=referral&quot;&gt;Hue 问题汇总&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Jevic</name></author><summary type="html">HUE是一个开源的Apache Hadoop UI系统，早期由Cloudera开发，后来贡献给开源社区。它是基于Python Web框架Django实现的。通过使用Hue我们可以通过浏览器方式操纵Hadoop集群。例如put、get、执行MapReduce Job等等</summary></entry><entry><title type="html">Ambari-Cluster配置(三)</title><link href="http://0.0.0.0/2020/03/07/ambari-cluster/" rel="alternate" type="text/html" title="Ambari-Cluster配置(三)" /><published>2020-03-07T20:35:06+08:00</published><updated>2020-03-07T20:35:06+08:00</updated><id>http://0.0.0.0/2020/03/07/ambari-cluster</id><content type="html" xml:base="http://0.0.0.0/2020/03/07/ambari-cluster/">&lt;h1 id=&quot;ambari-集群配置&quot;&gt;Ambari 集群配置&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hdp-install-01.png&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hdp-install-02.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;选择你需要安装的服务然后进入到配置界面&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;调整配置项&quot;&gt;调整配置项&lt;/h2&gt;
&lt;h3 id=&quot;hadoop-hue-依赖配置&quot;&gt;hadoop hue 依赖配置&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;检查确认是否有下列配置项,后面hue 要使用;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.gethue.com/administrator/configuration/connectors/#hdfs&quot;&gt;hue for HDFS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## core-site.xml
hadoop.proxyuser.falcon.groups=*
hadoop.proxyuser.falcon.hosts=*
hadoop.proxyuser.hbase.groups=*
hadoop.proxyuser.hbase.hosts=*
hadoop.proxyuser.hcat.groups=*
hadoop.proxyuser.hcat.hosts=*
hadoop.proxyuser.httpfs.groups=*
hadoop.proxyuser.httpfs.hosts=*
hadoop.proxyuser.hue.groups=*
hadoop.proxyuser.hue.hosts=*
hadoop.proxyuser.root.hosts=*
hadoop.proxyuser.root.groups=*
hadoop.proxyuser.yarn.hosts=*
hadoop.proxyuser.yarn.groups=*
hadoop.proxyuser.mapred.hosts=*
hadoop.proxyuser.mapred.groups=*

## hdfs-site.xml
# 关闭权限
dfs.permissions.enabled=false
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hdp-install-hadoop.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;hive&quot;&gt;Hive&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;连接数据库时使用,ambari 页面会有提示根据提示进行操作即可&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@dt1 ~]# ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java-5.1.48-bin.jar
Using python  /usr/bin/python
Setup ambari-server
Copying /usr/share/java/mysql-connector-java-5.1.48-bin.jar to /var/lib/ambari-server/resources
If you are updating existing jdbc driver jar for mysql with mysql-connector-java-5.1.48-bin.jar. Please remove the old driver jar, from all hosts. Restarting services that need the driver, will automatically copy the new jar to the hosts.
JDBC driver was successfully initialized.
Ambari Server 'setup' completed successfully.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hdp-install-hive.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;oozie&quot;&gt;Oozie&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.gethue.com/administrator/configuration/connectors/#apache-oozie&quot;&gt;hue oozie&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ambari 初始化安装时添加下列参数&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## oozie-site.xml
oozie.service.ProxyUserService.proxyuser.hive.groups=*
oozie.service.ProxyUserService.proxyuser.hive.hosts=*
oozie.service.ProxyUserService.proxyuser.hue.groups=*
oozie.service.ProxyUserService.proxyuser.hue.hosts=*
oozie.processing.timezone=GMT+0800
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hdp-install-oozie.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;最终安装结果如下图&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hdp-install-end.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;hadoop-ha&quot;&gt;Hadoop HA&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;ambari 默认安装hadoop时,没有启用HA 高可用,所以当安装完成后需要再次点击启用HA&lt;/li&gt;
  &lt;li&gt;参考&lt;a href=&quot;http://www.louisvv.com/archives/1490.html&quot;&gt;Ambari Hadoop安装启用HA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hdp-hadoop-ha-01.png&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hdp-hadoop-ha-02.png&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hdp-hadoop-ha-03.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;剩下的步骤根据提示一步步操作即可!&lt;/p&gt;

&lt;h2 id=&quot;yarn-ha&quot;&gt;yarn HA&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;与hadoop ha 一样点击开启HA,根据步骤操作即可&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;hadoop-httpfs&quot;&gt;hadoop-httpfs&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yum install -y hadoop-httpfs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;安装完成后,无法正常启动;原因是由于缺失相关目录:
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/hadoop-httpfs-01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;打补丁:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;下载 &lt;a href=&quot;https://github.com/jevic/bigdata/blob/master/ambari/hadoop-httpfs_3.x_patch.tar.gz&quot;&gt;hadoop-httpfs_3.x_patch.tar.gz&lt;/a&gt;;解压后执行patch.sh&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;启动hadoop-httpfs&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## root用户操作
# mkdir -p /var/run/hadoop/httpfs
# chmod 777 /var/run/hadoop/httpfs
# /usr/hdp/current/hadoop-httpfs/etc/rc.d/init.d/hadoop-httpfs start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Jevic</name></author><summary type="html">Ambari 集群配置</summary></entry><entry><title type="html">Ambari-Server&amp;amp;agent安装配置(二)</title><link href="http://0.0.0.0/2020/03/07/ambari-server-install/" rel="alternate" type="text/html" title="Ambari-Server&amp;agent安装配置(二)" /><published>2020-03-07T18:56:06+08:00</published><updated>2020-03-07T18:56:06+08:00</updated><id>http://0.0.0.0/2020/03/07/ambari-server-install</id><content type="html" xml:base="http://0.0.0.0/2020/03/07/ambari-server-install/">&lt;h2 id=&quot;数据库配置&quot;&gt;数据库配置&lt;/h2&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;说明：数据库表名设置为大小写不敏感，修改mysql数据库配置文件my.cnf 即可

# mysql -u root -p123456 -e &quot;show variables like 'lower_case_table_names';&quot;
mysql: [Warning] Using a password on the command line interface can be insecure.
+------------------------+-------+
| Variable_name          | Value |
+------------------------+-------+
| lower_case_table_names | 1     |
+------------------------+-------+
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;创建数据库&quot;&gt;创建数据库&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;根据你需要安装的服务创建对应的数据库及配置访问信息;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;create database ambari character set utf8;
GRANT ALL PRIVILEGES ON ambari.* TO 'ambari'@'%' IDENTIFIED BY 'Ambari_123';
FLUSH PRIVILEGES;
create database hive character set latin1;
GRANT ALL PRIVILEGES ON hive.* TO 'hive'@'%' IDENTIFIED BY 'Hive@123';
FLUSH PRIVILEGES;
create database oozie character set utf8;
GRANT ALL PRIVILEGES ON oozie.* TO 'oozie'@'%' IDENTIFIED BY 'Oozie@123';
FLUSH PRIVILEGES;
create database ranger character set utf8;
GRANT ALL PRIVILEGES ON rangeradmin.* TO 'rangeradmin'@'%' IDENTIFIED BY 'Ranger@123';
FLUSH PRIVILEGES;
create database superset character set utf8;
GRANT ALL PRIVILEGES ON superset.* TO 'superset'@'%' IDENTIFIED BY 'Superset@123';
FLUSH PRIVILEGES;
create database hbase character set latin1;
GRANT ALL PRIVILEGES ON hbase.* TO 'hbase'@'%' IDENTIFIED BY 'Hbase@123';
FLUSH PRIVILEGES;

## hue 
create database hue character set utf8;
GRANT ALL PRIVILEGES ON hue.* TO 'hue'@'%' IDENTIFIED BY 'Hue@123456';
FLUSH PRIVILEGES;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;主机初始化&quot;&gt;主机初始化&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;JDK 安装&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;主机名配置
        &lt;ul&gt;
          &lt;li&gt;1.1.1.1 node.xxx.xx&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;双机互相&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    ssh-keygen -t rsa
    ssh-copy-id NODE_NAME
    ## 也可以使用sshpass 去除密码输入提示
    yum install -y sshpass
    sshpass PASSWORD -e ssh-copy-id NODE_NAME 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;初始化脚本:
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/jevic/bigdata/blob/master/ambari/initos.sh&quot;&gt;initos.sh&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ambari-server&quot;&gt;ambari-server&lt;/h2&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Current Version: 2.6.5.0-292 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;公共仓库]
http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.5.0
http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.22/repos/centos7


&lt;span class=&quot;c&quot;&gt;## &lt;/span&gt;
yum install ambari-server &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;## jdbc 驱动下载地址 &lt;/span&gt;
https://cdn.mysql.com//Downloads/Connector-J/mysql-connector-java-5.1.48.tar.gz
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;root@jevic-t01 ~]# &lt;span class=&quot;nb&quot;&gt;grep &lt;/span&gt;server.jdbc.driver.path /etc/ambari-server/conf/ambari.properties 
server.jdbc.driver.path&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/usr/share/java/mysql-connector-java-5.1.48-bin.jar


&lt;span class=&quot;c&quot;&gt;## 初始化安装&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;root@dt1 ~]# ambari-server setup
Using python  /usr/bin/python
Setup ambari-server
Checking SELinux...
SELinux status is &lt;span class=&quot;s1&quot;&gt;'disabled'&lt;/span&gt;
Customize user account &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;ambari-server daemon &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;y/n] &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;? y
Enter user account &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;ambari-server daemon &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;root&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:ambari
Adjusting ambari-server permissions and ownership...
Checking firewall status...
Checking JDK...
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;1] Oracle JDK 1.8 + Java Cryptography Extension &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;JCE&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; Policy Files 8
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;2] Oracle JDK 1.7 + Java Cryptography Extension &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;JCE&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; Policy Files 7
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;3] Custom JDK
&lt;span class=&quot;o&quot;&gt;==============================================================================&lt;/span&gt;
Enter choice &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;: 3
WARNING: JDK must be installed on all hosts and JAVA_HOME must be valid on all hosts.
WARNING: JCE Policy files are required &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;configuring Kerberos security. If you plan to use Kerberos,please make sure JCE Unlimited Strength Jurisdiction Policy Files are valid on all hosts.
Path to JAVA_HOME: /usr/local/java
Validating JDK on Ambari Server...done.
Checking GPL software agreement...
GPL License &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;LZO: https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html
Enable Ambari Server to download and install GPL Licensed LZO packages &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;y/n] &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;? n
Completing setup...
Configuring database...
Enter advanced database configuration &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;y/n] &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;? y
Configuring database...
&lt;span class=&quot;o&quot;&gt;==============================================================================&lt;/span&gt;
Choose one of the following options:
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;1] - PostgreSQL &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Embedded&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;2] - Oracle
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;3] - MySQL / MariaDB
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;4] - PostgreSQL
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;5] - Microsoft SQL Server &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Tech Preview&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;6] - SQL Anywhere
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;7] - BDB
&lt;span class=&quot;o&quot;&gt;==============================================================================&lt;/span&gt;
Enter choice &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;: 3
Hostname &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;localhost&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;: db1.jevic.cn
Port &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;3306&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:
Database name &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;ambari&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;: ambari
Username &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;ambari&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:
Enter Database Password &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;bigdata&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:
Re-enter password:
Configuring ambari database...
Configuring remote database connection properties...
WARNING: Before starting Ambari Server, you must run the following DDL against the database to create the schema: /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql
Proceed with configuring remote database connection properties &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;y/n] &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;y&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;?
Extracting system views...
ambari-admin-2.6.2.2.1.jar
...........
Adjusting ambari-server permissions and ownership...
Ambari Server &lt;span class=&quot;s1&quot;&gt;'setup'&lt;/span&gt; completed successfully.



&lt;span class=&quot;c&quot;&gt;## 将Ambari数据库脚本导入到数据库&lt;/span&gt;
mysql &lt;span class=&quot;nt&quot;&gt;-uambari&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-pxxx&lt;/span&gt;
use ambari&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql


&lt;span class=&quot;c&quot;&gt;## 启动ambari server&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# ambari-server start&lt;/span&gt;

在浏览器中访问ip:8080，默认登录名：admin 密码:admin
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;ambari-agent&quot;&gt;ambari-agent&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;配置yum 源
yum -y install ambari-agent

#ambari-agent 打ssl认证有问题，需要关闭
grep -q &quot;^force_https_protocol=PROTOCOL_TLSv1_2&quot; /etc/ambari-agent/conf/ambari-agent.ini ||sed -i 's@\[security\]@&amp;amp;\nforce_https_protocol=PROTOCOL_TLSv1_2@g' /etc/ambari-agent/conf/ambari-agent.ini

grep -q &quot;^verify=diable&quot; /etc/python/cert-verification.cfg || sed -i 's@\[https\]@&amp;amp;\nverify=diable@g' /etc/python/cert-verification.cfg 

/usr/sbin/ambari-agent reset ServiceNAME
/usr/sbin/ambari-agent start 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;后记&quot;&gt;后记&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;以下是在安装ambari 2.7.4时遇到的问题(安装方式一样)&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;初始化集群加入主机,状态一直为: preparing&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;解决方案: sudo chown -R ambari /var/run/ambari-server&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;HDFS 开启HA时报错 500&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;500 status code received on GET method for API: /api/v1/stacks/HDP/versions/2.4/recommendations 
Error message: Error occured during stack advisor command invocation: Cannot create /var/run/ambari-server/stack-recommendations&lt;/p&gt;

&lt;p&gt;解决方案：sudo chown -R ambari /var/run/ambari-server&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;ntpd 服务无法开机自启动
&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/hdp/ambari-init-ntpd.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;解决方案: systemctl disable chronyd&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">数据库配置 ``` 说明：数据库表名设置为大小写不敏感，修改mysql数据库配置文件my.cnf 即可</summary></entry><entry><title type="html">Ambari-本地Yum源配置(一)</title><link href="http://0.0.0.0/2020/03/06/ambari-yum/" rel="alternate" type="text/html" title="Ambari-本地Yum源配置(一)" /><published>2020-03-06T18:56:06+08:00</published><updated>2020-03-06T18:56:06+08:00</updated><id>http://0.0.0.0/2020/03/06/ambari-yum</id><content type="html" xml:base="http://0.0.0.0/2020/03/06/ambari-yum/">&lt;h2 id=&quot;ambari概述&quot;&gt;Ambari概述&lt;/h2&gt;
&lt;p&gt;Apache Ambari是一种基于Web的工具，支持Apache Hadoop集群的创建、管理和监控。Ambari已支持大多数Hadoop组件，包括HDFS、MapReduce、Hive、Pig、 Hbase、Zookeeper、Sqoop和Hcatalog等；除此之外，Ambari还支持Spark、Storm等计算框架及资源调度平台YARN。&lt;/p&gt;

&lt;p&gt;Apache Ambari 从集群节点和服务收集大量信息，并把它们表现为容易使用的，集中化的接口：Ambari Web.&lt;/p&gt;

&lt;p&gt;Ambari Web显示诸如服务特定的摘要、图表以及警报信息。可通过Ambari Web对Hadoop集群进行创建、管理、监视、添加主机、更新服务配置等；也可以利用Ambari Web执行集群管理任务，例如启用 Kerberos 安全以及执行Stack升级。任何用户都可以查看Ambari Web特性。拥有administrator-level 角色的用户可以访问比 operator-level 或 view-only 的用户能访问的更多选项。例如，Ambari administrator 可以管理集群安全，一个 operator 用户可以监控集群，而 view-only 用户只能访问系统管理员授予他的必要的权限。&lt;/p&gt;

&lt;h2 id=&quot;ambari体系结构&quot;&gt;Ambari体系结构&lt;/h2&gt;
&lt;p&gt;Ambari 自身也是一个分布式架构的软件，主要由两部分组成：Ambari Server 和 Ambari Agent。简单来说，用户通过Ambari Server通知 Ambari Agent 安装对应的软件；Agent 会定时地发送各个机器每个软件模块的状态给 Ambari Server，最终这些状态信息会呈现在 Ambari 的 GUI，方便用户了解到集群的各种状态，并进行相应的维护。&lt;/p&gt;

&lt;p&gt;Ambari Server 从整个集群上收集信息。每个主机上都有 Ambari Agent, Ambari Server 通过 Ambari Agent 控制每部主机。&lt;/p&gt;

&lt;h2 id=&quot;配置本地yum源&quot;&gt;配置本地YUM源&lt;/h2&gt;
&lt;h2 id=&quot;参考文档&quot;&gt;参考文档&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;https://docs.cloudera.com/HDPDocuments&lt;/li&gt;
  &lt;li&gt;https://docs.cloudera.com/HDPDocuments/Ambari-2.7.5.0/bk_ambari-installation/content/ambari_repositories.html&lt;/li&gt;
  &lt;li&gt;https://docs.cloudera.com/HDPDocuments/Ambari-2.7.5.0/bk_ambari-installation/content/hdp_315_repositories.html&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;目录结构&quot;&gt;目录结构&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@192-168-5-12 ~]# mkdir -p /tmp/temp
 
 
wget -N http://192.168.12.62/ambari/ambari2.6.2.2/HDP-2.6.5.0-centos7-rpm.tar.gz -P /tmp/temp/
wget -N  http://192.168.12.62/ambari/ambari2.6.2.2/HDP-GPL-2.6.5.0-centos7-gpl.tar.gz -P /tmp/temp/
wget -N  http://192.168.12.62/ambari/ambari2.6.2.2/HDP-UTILS-1.1.0.22-centos7.tar.gz -P /tmp/temp/
wget -N  http://192.168.12.62/ambari/ambari2.6.2.2/ambari-2.6.2.2-centos7.tar.gz -P /tmp/temp/
 
 
[root@192-168-5-12 ~]# for file in `ls -1 /tmp/temp/*.tar.gz` ; do tar -xzvf $file -C /tmp/temp/ ; done ;
 
 
 
[root@192-168-5-12 ~]#  mkdir -p /data/wwwroot/yum/{ambari,hdp,hdp-utils,hdp-gpl}
 
 
mv /tmp/temp/ambari/centos7/2.6.2.2-1/* /data/wwwroot/yum/ambari/
mv /tmp/temp/HDP/centos7/2.6.5.0-292/* /data/wwwroot/yum/hdp/
mv /tmp/temp/HDP-GPL/centos7/2.6.5.0-292/* /data/wwwroot/yum/hdp-gpl/
mv /tmp/temp/HDP-UTILS/centos7/1.1.0.22/* /data/wwwroot/yum//hdp-utils/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@yum ambari2.7.4]# pwd
/data/wwwroot/yum/ambari2.7.4
[root@yum ambari2.7.4]# tree -d -L 2
.
├── ambari
│   ├── ambari
│   ├── repodata
│   ├── RPM-GPG-KEY
│   ├── smartsense
│   └── tars
├── hdp
│   ├── accumulo
│   ├── atlas
│   ├── bigtop-jsvc
│   ├── bigtop-tomcat
│   ├── datafu
│   ├── druid
│   ├── hadoop
│   ├── hbase
│   ├── hdp-select
│   ├── hive
│   ├── hive_warehouse_connector
│   ├── kafka
│   ├── knox
│   ├── livy
│   ├── oozie
│   ├── phoenix
│   ├── pig
│   ├── ranger
│   ├── repodata
│   ├── RPM-GPG-KEY
│   ├── shc
│   ├── spark2
│   ├── spark_atlas_connector
│   ├── spark_schema_registry
│   ├── sqoop
│   ├── storm
│   ├── superset
│   ├── tez
│   ├── vrpms
│   ├── zeppelin
│   └── zookeeper
├── hdp-gpl
│   ├── hadooplzo
│   ├── repodata
│   ├── RPM-GPG-KEY
│   └── vrpms
└── hdp-utils
    ├── openblas
    ├── repodata
    ├── RPM-GPG-KEY
    └── snappy

48 directories
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;nginx-server配置&quot;&gt;nginx server配置&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
server {
        listen       80;
        server_name  localhost;
        location / {
            #root   /data/wwwroot/yum;
	    root /data/wwwroot/yum ;
            charset utf-8;
	    autoindex on;
            # set to on means use localtime
            autoindex_localtime on;
            # show size with unit 'MB' instead of 'Byte'
            autoindex_exact_size off;
            index  index.html index.htm;
        }
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
    }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;repo文件&quot;&gt;repo文件&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@s03 yum.repos.d]# cat ambari.repo
#VERSION_NUMBER=2.7.4.0-118
[ambari-2.7.4.0]
#json.url = http://public-repo-1.hortonworks.com/HDP/hdp_urlinfo.json
name=ambari Version - ambari-2.7.4.0
#baseurl=http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.7.4.0
baseurl=http://192.168.12.70/ambari2.7.4/ambari/
gpgcheck=1
#gpgkey=http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.7.4.0/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins
gpgkey=http://192.168.12.70/ambari2.7.4/ambari/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins
enabled=1
priority=1


[root@s03 yum.repos.d]# cat hdp*repo

#VERSION_NUMBER=3.1.4.0-315
[HDP-GPL-3.1.4.0]
name=HDP-GPL Version - HDP-GPL-3.1.4.0
#baseurl=http://public-repo-1.hortonworks.com/HDP-GPL/centos7/3.x/updates/3.1.4.0
baseurl=http://192.168.12.70/ambari2.7.4/hdp-gpl
gpgcheck=1
#gpgkey=http://public-repo-1.hortonworks.com/HDP-GPL/centos7/3.x/updates/3.1.4.0/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins
gpgkey=http://192.168.12.70/ambari2.7.4/hdp-gpl/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins
enabled=1
priority=1

#VERSION_NUMBER=3.1.4.0-315
[HDP-3.1.4.0]
name=HDP Version - HDP-3.1.4.0
#baseurl=http://public-repo-1.hortonworks.com/HDP/centos7/3.x/updates/3.1.4.0
baseurl=http://192.168.12.70/ambari2.7.4/hdp/
gpgcheck=1
#gpgkey=http://public-repo-1.hortonworks.com/HDP/centos7/3.x/updates/3.1.4.0/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins
gpgkey=http://192.168.12.70/ambari2.7.4/hdp/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins
enabled=1
priority=1


[HDP-UTILS-1.1.0.22]
name=HDP-UTILS Version - HDP-UTILS-1.1.0.22
#baseurl=http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.22/repos/centos7
baseurl=http://192.168.12.70/ambari2.7.4/hdp-utils
gpgcheck=1
#gpgkey=http://public-repo-1.hortonworks.com/HDP/centos7/3.x/updates/3.1.4.0/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins
gpgkey=http://192.168.12.70/ambari2.7.4/hdp-utils/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins
enabled=1
priority=1

[HDP-UTILS-1.1.0.22]
name=Hortonworks Data Platform Utils Version - HDP-UTILS-1.1.0.22
#baseurl=http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.22/repos/centos7
baseurl=http://192.168.12.70/ambari2.7.4/hdp-utils
gpgcheck=1
enabled=0
priority=1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Jevic</name></author><summary type="html">Ambari概述 Apache Ambari是一种基于Web的工具，支持Apache Hadoop集群的创建、管理和监控。Ambari已支持大多数Hadoop组件，包括HDFS、MapReduce、Hive、Pig、 Hbase、Zookeeper、Sqoop和Hcatalog等；除此之外，Ambari还支持Spark、Storm等计算框架及资源调度平台YARN。</summary></entry><entry><title type="html">Elastic Stack 7.x 初识</title><link href="http://0.0.0.0/2019/11/06/elk-7-release/" rel="alternate" type="text/html" title="Elastic Stack 7.x 初识" /><published>2019-11-06T18:56:06+08:00</published><updated>2019-11-06T18:56:06+08:00</updated><id>http://0.0.0.0/2019/11/06/elk-7-release</id><content type="html" xml:base="http://0.0.0.0/2019/11/06/elk-7-release/">&lt;h3 id=&quot;概述&quot;&gt;概述&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;2019年04月25日 &lt;a href=&quot;https://www.elastic.co/cn/blog/elastic-stack-7-0-0-released&quot;&gt;Elastic Stack 7.0.0 重磅发布&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;2019年10月02日 &lt;a href=&quot;https://www.elastic.co/cn/blog/elastic-stack-7-4-0-released&quot;&gt;Elastic Stack 7.4.0 重磅发布&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;关系型数据库与 Elasticsearch 的抽象与类比
    &lt;ul&gt;
      &lt;li&gt;在7.0 版本之前,一个index 可以设置多个 &lt;code class=&quot;highlighter-rouge&quot;&gt;Types&lt;/code&gt;;&lt;/li&gt;
      &lt;li&gt;7.0 以后一个索引只能创建一个 &lt;code class=&quot;highlighter-rouge&quot;&gt;Type =&amp;gt; &quot;_doc&quot;&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;RDBMS&lt;/th&gt;
      &lt;th&gt;Elasticsearch&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Table&lt;/td&gt;
      &lt;td&gt;Index(Type)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Row&lt;/td&gt;
      &lt;td&gt;Document&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Column&lt;/td&gt;
      &lt;td&gt;Filed&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Schema&lt;/td&gt;
      &lt;td&gt;Mapping&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;SQL&lt;/td&gt;
      &lt;td&gt;DSL&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;关键特性&quot;&gt;关键特性&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;全新设计和导航……还有夜间模式&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/cn/blog/a-new-era-for-cluster-coordination-in-elasticsearch&quot;&gt;Elasticsearch 集群协调迎来新时代&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/cn/blog/improving-node-resiliency-with-the-real-memory-circuit-breaker&quot;&gt;使用真实内存断路器提高节点弹性&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/cn/subscriptions&quot;&gt;Elastic Stack 订阅&lt;/a&gt;
 核心安全功能 免费、免费、免费!!&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;安装配置&quot;&gt;安装配置&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;详细的 安装配置说明可参考 &lt;a href=&quot;https://www.jevic.cn/2017/01/23/elk-elasticsearch-install-5x/&quot;&gt;Elasticsearch 5.x 集群配置&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Download 7.4.2
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.4.2-linux-x86_64.tar.gz&quot;&gt;elasticsearch&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://artifacts.elastic.co/downloads/kibana/kibana-7.4.2-linux-x86_64.tar.gz&quot;&gt;kibana&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://artifacts.elastic.co/downloads/logstash/logstash-7.4.2.tar.gz&quot;&gt;logstash&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Beat&lt;/code&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.4.2-linux-x86_64.tar.gz&quot;&gt;filebeat&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-7.4.2-linux-x86_64.tar.gz&quot;&gt;metricbeat&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://artifacts.elastic.co/downloads/beats/auditbeat/auditbeat-7.4.2-linux-x86_64.tar.gz&quot;&gt;auditbeat&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://artifacts.elastic.co/downloads/beats/heartbeat/heartbeat-7.4.2-linux-x86_64.tar.gz&quot;&gt;heartbeat&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;elasticsearch&quot;&gt;Elasticsearch&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;此处使用的版本为: &lt;code class=&quot;highlighter-rouge&quot;&gt;7.4.2&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;提示: OpenJDK 已经内置 &lt;code class=&quot;highlighter-rouge&quot;&gt;$ES_PATH/jdk&lt;/code&gt; &lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/current/setup.html#jvm-version&quot;&gt;JAVA (JVM)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;系统配置&quot;&gt;系统配置&lt;/h5&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@jevic ~]# cat /etc/security/limits.conf
* soft nofile 65536
* hard nofile 65536
* soft nproc unlimited
* hard nproc unlimited
es soft memlock unlimited
es hard memlock unlimited

[root@jevic ~]# cat /etc/security/limits.d/20-nproc.conf
# Default limit for number of user's processes to prevent
# accidental fork bombs.
# See rhbz #432903 for reasoning.

*          soft    nproc     102400
root       soft    nproc     unlimited
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;elasticsearchyml&quot;&gt;elasticsearch.yml&lt;/h5&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cluster.name: JevicTestDB
node.name: node194
node.master: true
node.data: true
path.data: /es-data1/data
bootstrap.memory_lock: true
network.host: 192.168.0.194
http.port: 9200
discovery.zen.minimum_master_nodes: 2
discovery.seed_hosts: [&quot;node194&quot;, &quot;node198&quot;, &quot;node204&quot;]
#discovery.seed_providers: unicast_hosts.txt
## 重试间隔
discovery.find_peers_interval: 1s
cluster.initial_master_nodes: [&quot;node194&quot;, &quot;node198&quot;, &quot;node204&quot;]
### sql插件支持
http.cors.enabled: true
http.cors.allow-origin: &quot;*&quot;
#### 必须停用xpack sql才可以使用elasticsearch-sql
xpack.sql.enabled: false
### 开启认证:
### 初始化认证: $ES_PATH/bin/elasticsearch-setup-passwords interactive
#xpack.security.enabled: true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;kibana&quot;&gt;Kibana&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;server.name: kibana
server.host: &quot;0&quot;
elasticsearch.hosts: [ &quot;http://elasticsearch:9200&quot; ]
### 开启认证
#xpack.security.enabled: true
#elasticsearch.username: &quot;kibana&quot;
#elasticsearch.password: &quot;123456&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;logstash&quot;&gt;Logstash&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;收集 NGINX 日志&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;日志格式&quot;&gt;日志格式&lt;/h5&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;log_format  json '{&quot;cip&quot;:&quot;$remote_addr&quot;,'
                            '&quot;timestamp&quot;:&quot;$time_iso8601&quot;,'
                            '&quot;rtime&quot;:$request_time,'
                            '&quot;upres_time&quot;:$upstream_response_time,'
                            '&quot;sbyte&quot;:$body_bytes_sent,'
                            '&quot;host&quot;:&quot;$http_host&quot;,'
                            '&quot;request&quot;:&quot;$request&quot;,'
                            '&quot;scheme&quot;:&quot;$scheme&quot;,'
                            '&quot;length&quot;:&quot;$content_length&quot;,'
                            '&quot;server&quot;:&quot;$upstream_addr&quot;,'
                            '&quot;method&quot;:&quot;$request_method&quot;,'
                            '&quot;status&quot;:$status}';
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;pipe-配置&quot;&gt;pipe 配置&lt;/h5&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;input{
    file {
        path =&amp;gt; [ &quot;/var/log/nginx/es_access.log&quot; ]
        start_position =&amp;gt; &quot;beginning&quot;
        codec =&amp;gt; &quot;json&quot;
    }
}

filter {
  date {
    match =&amp;gt; [ &quot;timestamp&quot;, &quot;ISO8601&quot; ]
    target =&amp;gt; &quot;@timestamp&quot;
  }
  mutate {
    split =&amp;gt; { &quot;request&quot; =&amp;gt; &quot; &quot; }
    add_field =&amp;gt; { &quot;url&quot; =&amp;gt; &quot;%{[request][1]}&quot;}
  }
  mutate {
    remove_field =&amp;gt; [ &quot;path&quot;, &quot;tags&quot;, &quot;request&quot;]
  }
}

output {
    #elasticsearch {
    #    hosts =&amp;gt; [ &quot;192.168.0.194:9200&quot; ]
    #    index =&amp;gt; &quot;nginx-%{+YYYY.MM.dd}&quot;
    #}
     stdout {
	       codec =&amp;gt; rubydebug
     }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;ps: &lt;a href=&quot;https://www.elastic.co/guide/en/logstash/current/plugins-filters-mutate.html&quot;&gt;filters-mutate&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;扩展阅读&quot;&gt;扩展阅读&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/cn/blog/how-to-monitor-nginx-web-servers-with-the-elastic-stack&quot;&gt;如何使用 Elastic Stack 监测 Nginx Web 服务器&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/cn/blog/monitoring-kafka-with-elasticsearch-kibana-and-beats&quot;&gt;通过 Elasticsearch、Kibana 和 Beats 监测 Kafka&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;关于 &lt;a href=&quot;https://github.com/NLPchina/elasticsearch-sql/wiki&quot;&gt;elasticsearch-sql&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/lmenezes/cerebro&quot;&gt;cerebro&lt;/a&gt; 插件的安装部署请移步Github&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Jevic</name></author><summary type="html">概述 2019年04月25日 Elastic Stack 7.0.0 重磅发布 2019年10月02日 Elastic Stack 7.4.0 重磅发布</summary></entry><entry><title type="html">Kubernetes Pod 异常排查处理</title><link href="http://0.0.0.0/2019/08/30/kubernetes-pod-error/" rel="alternate" type="text/html" title="Kubernetes Pod 异常排查处理" /><published>2019-08-30T18:56:06+08:00</published><updated>2019-08-30T18:56:06+08:00</updated><id>http://0.0.0.0/2019/08/30/kubernetes-pod-error</id><content type="html" xml:base="http://0.0.0.0/2019/08/30/kubernetes-pod-error/">&lt;blockquote&gt;
  &lt;p&gt;一般来说，无论 Pod 处于什么异常状态，都可以执行以下命令来查看 Pod 的状态&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get pod &amp;lt;pod-name&amp;gt; -o yaml 查看 Pod 的配置是否正确
kubectl describe pod &amp;lt;pod-name&amp;gt; 查看 Pod 的事件
kubectl logs &amp;lt;pod-name&amp;gt; [-c &amp;lt;container-name&amp;gt;] 查看容器日志
这些事件和日志通常都会有助于排查 Pod 发生的问题。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;pod-一直处于-pending-状态&quot;&gt;Pod 一直处于 Pending 状态&lt;/h3&gt;
&lt;p&gt;Pending 说明 Pod 还没有调度到某个 Node 上面。可以通过 &lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl describe pod &amp;lt;pod-name&amp;gt;&lt;/code&gt;命令查看到当前 Pod 的事件，进而判断为什么没有调度。可能的原因包括&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;资源不足，集群内所有的 Node 都不满足该 Pod 请求的 CPU、内存、GPU 等资源&lt;/li&gt;
  &lt;li&gt;HostPort 已被占用，通常推荐使用 Service 对外开放服务端口&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pod-一直处于-waiting-或-containercreating-状态&quot;&gt;Pod 一直处于 Waiting 或 ContainerCreating 状态&lt;/h3&gt;
&lt;p&gt;首先还是通过 &lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl describe pod &amp;lt;pod-name&amp;gt;&lt;/code&gt; 命令查看到当前 Pod 的事件。可能的原因包括&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;镜像拉取失败，比如
    &lt;ul&gt;
      &lt;li&gt;配置了错误的镜像&lt;/li&gt;
      &lt;li&gt;Kubelet 无法访问镜像（国内环境访问 gcr.io 需要特殊处理）&lt;/li&gt;
      &lt;li&gt;私有镜像的密钥配置错误&lt;/li&gt;
      &lt;li&gt;镜像太大，拉取超时（可以适当调整 kubelet 的 –image-pull-progress-deadline 和 –runtime-request-timeout 选项）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;CNI 网络错误，一般需要检查 CNI 网络插件的配置，比如
    &lt;ul&gt;
      &lt;li&gt;无法配置 Pod 网络&lt;/li&gt;
      &lt;li&gt;无法分配 IP 地址&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;容器无法启动，需要检查是否打包了正确的镜像或者是否配置了正确的容器参数&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pod-处于-imagepullbackoff-状态&quot;&gt;Pod 处于 ImagePullBackOff 状态&lt;/h3&gt;
&lt;p&gt;这通常是镜像名称配置错误或者私有镜像的密钥配置错误导致。这种情况可以使用 docker pull &lt;image&gt; 来验证镜像是否可以正常拉取。&lt;/image&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果是私有镜像，需要首先创建一个 docker-registry 类型的 Secret&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create secret docker-registry my-secret --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAIL
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;然后在容器中引用这个 Secret&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spec:
  containers:
  - name: private-reg-container
    image: &amp;lt;your-private-image&amp;gt;
  imagePullSecrets:
  - name: my-secret
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;pod-一直处于-crashloopbackoff-状态&quot;&gt;Pod 一直处于 CrashLoopBackOff 状态&lt;/h3&gt;
&lt;p&gt;CrashLoopBackOff 状态说明容器曾经启动了，但又异常退出了。此时可以先查看一下容器的日志&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl logs &amp;lt;pod-name&amp;gt;
kubectl logs --previous &amp;lt;pod-name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;这里可以发现一些容器退出的原因，比如
    &lt;ul&gt;
      &lt;li&gt;容器进程退出&lt;/li&gt;
      &lt;li&gt;健康检查失败退出&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;此时如果还未发现线索，还可以到容器内执行命令来进一步查看退出原因&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl exec cassandra -- cat /var/log/cassandra/system.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;如果还是没有线索，那就需要 SSH 登录该 Pod 所在的 Node 上，查看 Kubelet 或者 Docker 的日志进一步排查了&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 查询 Node
kubectl get pod &amp;lt;pod-name&amp;gt; -o wide
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;pod-处于-error-状态&quot;&gt;Pod 处于 Error 状态&lt;/h3&gt;
&lt;p&gt;通常处于 Error 状态说明 Pod 启动过程中发生了错误。常见的原因包括&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;依赖的 ConfigMap、Secret 或者 PV 等不存在&lt;/li&gt;
  &lt;li&gt;请求的资源超过了管理员设置的限制，比如超过了 LimitRange 等&lt;/li&gt;
  &lt;li&gt;违反集群的安全策略，比如违反了 PodSecurityPolicy 等&lt;/li&gt;
  &lt;li&gt;容器无权操作集群内的资源，比如开启 RBAC 后，需要为 ServiceAccount 配置角色绑定&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pod-处于-terminating-或-unknown-状态&quot;&gt;Pod 处于 Terminating 或 Unknown 状态&lt;/h3&gt;
&lt;p&gt;从 v1.5 开始，Kubernetes 不会因为 Node 失联而删除其上正在运行的 Pod，而是将其标记为 Terminating 或 Unknown 状态。想要删除这些状态的 Pod 有三种方法：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;从集群中删除该 Node。使用公有云时，kube-controller-manager 会在 VM 删除后自动删除对应的 Node。而在物理机部署的集群中，需要管理员手动删除 Node（如 kubectl delete node &lt;node-name&gt;。&lt;/node-name&gt;&lt;/li&gt;
  &lt;li&gt;Node 恢复正常。Kubelet 会重新跟 kube-apiserver 通信确认这些 Pod 的期待状态，进而再决定删除或者继续运行这些 Pod。&lt;/li&gt;
  &lt;li&gt;用户强制删除。用户可以执行 &lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl delete pods &amp;lt;pod&amp;gt; --grace-period=0 --force&lt;/code&gt; 强制删除 Pod。除非明确知道 Pod 的确处于停止状态（比如 Node 所在 VM 或物理机已经关机），否则不建议使用该方法。特别是 StatefulSet 管理的 Pod，强制删除容易导致脑裂或者数据丢失等问题。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pod-行为异常&quot;&gt;Pod 行为异常&lt;/h3&gt;
&lt;p&gt;这里所说的行为异常是指 Pod 没有按预期的行为执行，比如没有运行 podSpec 里面设置的命令行参数。这一般是 podSpec yaml 文件内容有误，可以尝试使用 –validate 参数重建容器，比如&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl delete pod mypod
kubectl create --validate -f mypod.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;也可以查看创建后的 podSpec 是否是对的，比如&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get pod mypod -o yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;修改静态-pod-的-manifest-后未自动重建&quot;&gt;修改静态 Pod 的 Manifest 后未自动重建&lt;/h3&gt;
&lt;p&gt;Kubelet 使用 inotify 机制检测 /etc/kubernetes/manifests 目录（可通过 Kubelet 的 –pod-manifest-path 选项指定）中静态 Pod 的变化，并在文件发生变化后重新创建相应的 Pod。但有时也会发生修改静态 Pod 的 Manifest 后未自动创建新 Pod 的情景，此时一个简单的修复方法是重启 Kubelet。&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">一般来说，无论 Pod 处于什么异常状态，都可以执行以下命令来查看 Pod 的状态</summary></entry><entry><title type="html">kubernetes 1.13.8 二进制手动部署</title><link href="http://0.0.0.0/2019/08/19/kubernetes-1.13.8/" rel="alternate" type="text/html" title="kubernetes 1.13.8 二进制手动部署" /><published>2019-08-19T18:56:06+08:00</published><updated>2019-08-19T18:56:06+08:00</updated><id>http://0.0.0.0/2019/08/19/kubernetes-1.13.8</id><content type="html" xml:base="http://0.0.0.0/2019/08/19/kubernetes-1.13.8/">&lt;blockquote&gt;
  &lt;p&gt;2019 都过大半了, 一直比较忙,也有点懒…. 1.13 都出来很久了,还是决定折腾一把!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;通读一遍先熟悉了过程在实际操作!!!&lt;/li&gt;
  &lt;li&gt;通读一遍先熟悉了过程在实际操作!!!&lt;/li&gt;
  &lt;li&gt;通读一遍先熟悉了过程在实际操作!!!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;阅读前可参考之前的 &lt;a href=&quot;https://www.jevic.cn/2018/09/23/kuberentes-1.10.10/&quot;&gt;二进制手动部署kubernetes 1.10.10&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;虚拟化平台 vmware vsphere esxi;
下面各节点配置均为 4核、8GB、系统盘40GB,内存必须4G+;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;OS&lt;/th&gt;
      &lt;th&gt;IP&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Docker&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;内核版本&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;角色&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;CentOS 7.6.1810&lt;/td&gt;
      &lt;td&gt;192.168.1.230&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;19.03.1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;4.4.189&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Master/etcd01&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;-&lt;/td&gt;
      &lt;td&gt;192.168.1.231&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Master/etcd02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;-&lt;/td&gt;
      &lt;td&gt;192.168.1.232&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Master/etcd03&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;-&lt;/td&gt;
      &lt;td&gt;192.168.1.233&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Node01&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;-&lt;/td&gt;
      &lt;td&gt;192.168.1.234&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Node02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;-&lt;/td&gt;
      &lt;td&gt;192.168.1.235&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Node03&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;所有配置及证书生成等都在master01 节点上操作完成, 然后在同步配置到各个节点;&lt;/li&gt;
  &lt;li&gt;本文所有的配置文件及脚本均放置在 &lt;a href=&quot;https://github.com/jevic/kshell/tree/master/kubernetes/1.13.8&quot;&gt;github kshell&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;系统初始化&quot;&gt;系统初始化&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;这里不多说,还是和以前一样,直接复制脚本执行即可完成初始化配置.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
init&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
setenforce 0
sed &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'s/SELINUX=enforcing/SELINUX=disalbe/g'&lt;/span&gt; /etc/sysconfig/selinux

&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; /etc/security/limits.conf &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;EOF&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;
* soft nofile 65536
* hard nofile 65536
* soft nproc unlimited
* hard nproc unlimited
&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;EOF

&lt;/span&gt;sed &lt;span class=&quot;nt&quot;&gt;-ri&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'/^[^#]*swap/s@^@#@'&lt;/span&gt; /etc/fstab
swapoff &lt;span class=&quot;nt&quot;&gt;-a&lt;/span&gt;

systemctl stop firewalld &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; systemctl disable firewalld


&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; /etc/sysctl.conf &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;EOF&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;
net.bridge.bridge-nf-call-iptables=1
net.bridge.bridge-nf-call-ip6tables=1
net.ipv4.ip_forward=1
net.ipv4.tcp_tw_recycle=0
vm.swappiness=0
vm.overcommit_memory=1
vm.panic_on_oom=0
fs.inotify.max_user_watches=89100
fs.file-max=52706963
fs.nr_open=52706963
net.ipv6.conf.all.disable_ipv6=1
net.netfilter.nf_conntrack_max=2310720
&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;EOF

&lt;/span&gt;sysctl &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt;

yum install &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; wget
wget &lt;span class=&quot;nt&quot;&gt;-O&lt;/span&gt; /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
yum install &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; epel-release
yum install &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; conntrack ipvsadm ipset jq sysstat curl iptables libseccomp ntpdate telnet iproute git lrzsz
ntpdate cn.pool.ntp.org
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

kernel&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
rpm &lt;span class=&quot;nt&quot;&gt;--import&lt;/span&gt; https://www.elrepo.org/RPM-GPG-KEY-elrepo.org
rpm &lt;span class=&quot;nt&quot;&gt;-Uvh&lt;/span&gt; http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm
yum &lt;span class=&quot;nt&quot;&gt;--enablerepo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;elrepo-kernel install kernel-lt-devel kernel-lt &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;## 默认启动的顺序是从0开始，新内核是从头插入（目前位置在0，而4.4的是在1），所以需要选择0&lt;/span&gt;
grub2-set-default 0
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

ipvs&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
:&amp;gt; /etc/modules-load.d/ipvs.conf
&lt;span class=&quot;nv&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=(&lt;/span&gt;
ip_vs
ip_vs_lc
ip_vs_wlc
ip_vs_rr
ip_vs_wrr
ip_vs_lblc
ip_vs_lblcr
ip_vs_dh
ip_vs_sh
ip_vs_fo
ip_vs_nq
ip_vs_sed
ip_vs_ftp
nf_conntrack
  &lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;kernel_module &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[@]&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;do&lt;/span&gt;
    /sbin/modinfo &lt;span class=&quot;nt&quot;&gt;-F&lt;/span&gt; filename &lt;span class=&quot;nv&quot;&gt;$kernel_module&lt;/span&gt; |&amp;amp; &lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-qv&lt;/span&gt; ERROR &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$kernel_module&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; /etc/modules-load.d/ipvs.conf &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; :
&lt;span class=&quot;k&quot;&gt;done
&lt;/span&gt;systemctl &lt;span class=&quot;nb&quot;&gt;enable&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--now&lt;/span&gt; systemd-modules-load.service
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

docker&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
yum install &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; yum-utils device-mapper-persistent-data lvm2
yum-config-manager &lt;span class=&quot;nt&quot;&gt;--add-repo&lt;/span&gt; http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
yum &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; install docker-ce
systemctl start docker
systemctl stop docker

&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; /etc/docker/daemon.json &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;EOF&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;
{
  &quot;registry-mirrors&quot;: [&quot;https://dlvqhrac.mirror.aliyuncs.com&quot;]
}
&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;EOF
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

init_history&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;/etc/profile &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;EOF&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;
## 设置history格式
export HISTTIMEFORMAT=&quot;[%Y-%m-%d %H:%M:%S] [`who am i 2&amp;gt;/dev/null| awk '{print &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$NF&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;}'|sed -e 's/[()]//g'`] &quot;
## 实时记录用户在shell中执行的每一条命令
export PROMPT_COMMAND='\
if [ -z &quot;\&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$OLD_PWD&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot; ];then
    export OLD_PWD=\&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$PWD&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;;
    fi;
    if [ ! -z &quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$\&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;LAST_CMD&quot; ] &amp;amp;&amp;amp; [ &quot;\&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;history &lt;/span&gt;1&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot; != &quot;\&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$LAST_CMD&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot; ]; then
        logger -t `whoami`_shell_cmd &quot;[\&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$OLD_PWD&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;]\&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;history &lt;/span&gt;1&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;;
        fi ;
        export LAST_CMD=&quot;\&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;history &lt;/span&gt;1&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;;
        export OLD_PWD=\&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$PWD&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;;'
&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;EOF
&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; /etc/profile
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;## 初始化系统&lt;/span&gt;
init
&lt;span class=&quot;c&quot;&gt;## 内核升级&lt;/span&gt;
kernel
&lt;span class=&quot;c&quot;&gt;## ipvs 内核模块加载&lt;/span&gt;
ipvs
&lt;span class=&quot;c&quot;&gt;## 安装docker&lt;/span&gt;
docker
&lt;span class=&quot;c&quot;&gt;## 配置历史命令记录&lt;/span&gt;
init_history
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;执行完成后,reboot 重启机器即可, 或者可以直接init 0 关机先创建个虚拟机快照&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;cfssl&quot;&gt;cfssl&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;install_cfssl.sh&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;

Download&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#download cfssl&lt;/span&gt;
curl &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; /usr/local/bin/cfssl https://pkg.cfssl.org/R1.2/cfssl_linux-amd64
&lt;span class=&quot;c&quot;&gt;#download cfssljson&lt;/span&gt;
curl &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; /usr/local/bin/cfssljson https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64

chmod +x /usr/local/bin/cfssl
chmod +x /usr/local/bin/cfssljson
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

init&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
	mv cfssl_linux-amd64 /usr/local/bin/cfssl
	mv cfssljson_linux-amd64 /usr/local/bin/cfssljson
	chmod +x /usr/local/bin/cfssl
	chmod +x /usr/local/bin/cfssljson
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in
   &lt;/span&gt;down&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
   Download &lt;span class=&quot;p&quot;&gt;;;&lt;/span&gt;
   init&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
   init &lt;span class=&quot;p&quot;&gt;;;&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
   &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;down | init&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;esac&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;etcd&quot;&gt;etcd&lt;/h2&gt;
&lt;h3 id=&quot;证书配置&quot;&gt;证书配置&lt;/h3&gt;
&lt;h4 id=&quot;etcd-csrjson&quot;&gt;etcd-csr.json&lt;/h4&gt;
&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;key&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;algo&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;rsa&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;size&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2048&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;names&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;O&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;etcd&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;OU&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;etcd Security&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;L&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Shengzhen&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;ST&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Shengzhen&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;C&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;CN&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;CN&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;etcd&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;hosts&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;127.0.0.1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;localhost&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;192.168.1.230&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;192.168.1.231&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;192.168.1.232&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;etcd-gencertjson&quot;&gt;etcd-gencert.json&lt;/h4&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;signing&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;default&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;usages&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;signing&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;key encipherment&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;server auth&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;client auth&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;expiry&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;175200h&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;etcd-root-ca-csrjson&quot;&gt;etcd-root-ca-csr.json&lt;/h4&gt;
&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;key&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;algo&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;rsa&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;size&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4096&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;names&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;O&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;etcd&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;OU&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;etcd Security&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;L&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Shengzhen&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;ST&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Shengzhen&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;C&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;CN&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;CN&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;etcd-root-ca&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;key_etcdsh&quot;&gt;key_etcd.sh&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;生成证书&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cfssl gencert --initca=true etcd-root-ca-csr.json | cfssljson --bare etcd-root-ca
cfssl gencert --ca etcd-root-ca.pem --ca-key etcd-root-ca-key.pem --config etcd-gencert.json etcd-csr.json | cfssljson --bare etcd
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;etcdconf&quot;&gt;etcd.conf&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;同步到其他节点后,修改对应的NAME和监听IP地址即可!!!!&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# [member]
ETCD_NAME=etcd1
ETCD_DATA_DIR=&quot;/var/lib/etcd/etcd1.etcd&quot;
ETCD_WAL_DIR=&quot;/var/lib/etcd/wal&quot;
ETCD_SNAPSHOT_COUNT=&quot;100&quot;
ETCD_HEARTBEAT_INTERVAL=&quot;100&quot;
ETCD_ELECTION_TIMEOUT=&quot;1000&quot;
ETCD_LISTEN_PEER_URLS=&quot;https://192.168.1.230:2380&quot;
ETCD_LISTEN_CLIENT_URLS=&quot;https://192.168.1.230:2379,http://127.0.0.1:2379&quot;
ETCD_MAX_SNAPSHOTS=&quot;5&quot;
ETCD_MAX_WALS=&quot;5&quot;
#ETCD_CORS=&quot;&quot;
# [cluster]
ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;https://192.168.1.230:2380&quot;
ETCD_ADVERTISE_CLIENT_URLS=&quot;https://192.168.1.230:2379&quot;
# if you use different ETCD_NAME (e.g. test), set ETCD_INITIAL_CLUSTER value for this name, i.e. &quot;test=http://...&quot;
ETCD_INITIAL_CLUSTER=&quot;etcd1=https://192.168.1.230:2380,etcd2=https://192.168.1.231:2380,etcd3=https://192.168.1.232:2380&quot;
ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;
ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot;
#ETCD_DISCOVERY=&quot;&quot;
#ETCD_DISCOVERY_SRV=&quot;&quot;
#ETCD_DISCOVERY_FALLBACK=&quot;proxy&quot;
#ETCD_DISCOVERY_PROXY=&quot;&quot;
#ETCD_STRICT_RECONFIG_CHECK=&quot;false&quot;
#ETCD_AUTO_COMPACTION_RETENTION=&quot;0&quot;
# [proxy]
#ETCD_PROXY=&quot;off&quot;
#ETCD_PROXY_FAILURE_WAIT=&quot;5000&quot;
#ETCD_PROXY_REFRESH_INTERVAL=&quot;30000&quot;
#ETCD_PROXY_DIAL_TIMEOUT=&quot;1000&quot;
#ETCD_PROXY_WRITE_TIMEOUT=&quot;5000&quot;
#ETCD_PROXY_READ_TIMEOUT=&quot;0&quot;
# [security]
ETCD_CERT_FILE=&quot;/etc/etcd/ssl/etcd.pem&quot;
ETCD_KEY_FILE=&quot;/etc/etcd/ssl/etcd-key.pem&quot;
ETCD_CLIENT_CERT_AUTH=&quot;true&quot;
ETCD_TRUSTED_CA_FILE=&quot;/etc/etcd/ssl/etcd-root-ca.pem&quot;
ETCD_AUTO_TLS=&quot;true&quot;
ETCD_PEER_CERT_FILE=&quot;/etc/etcd/ssl/etcd.pem&quot;
ETCD_PEER_KEY_FILE=&quot;/etc/etcd/ssl/etcd-key.pem&quot;
ETCD_PEER_CLIENT_CERT_AUTH=&quot;true&quot;
ETCD_PEER_TRUSTED_CA_FILE=&quot;/etc/etcd/ssl/etcd-root-ca.pem&quot;
ETCD_PEER_AUTO_TLS=&quot;true&quot;
# [logging]
#ETCD_DEBUG=&quot;false&quot;
# examples for -log-package-levels etcdserver=WARNING,security=DEBUG
#ETCD_LOG_PACKAGE_LEVELS=&quot;&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;etcdservice&quot;&gt;etcd.service&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
Description=Etcd Server
After=network.target
After=network-online.target
Wants=network-online.target
[Service]
Type=notify
WorkingDirectory=/var/lib/etcd/
EnvironmentFile=-/etc/etcd/etcd.conf
User=etcd
# set GOMAXPROCS to number of processors
ExecStart=/bin/bash -c &quot;GOMAXPROCS=$(nproc) /usr/local/bin/etcd --name=\&quot;${ETCD_NAME}\&quot; --data-dir=\&quot;${ETCD_DATA_DIR}\&quot; --listen-client-urls=\&quot;${ETCD_LISTEN_CLIENT_URLS}\&quot;&quot;
Restart=on-failure
LimitNOFILE=65536
[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;installsh&quot;&gt;install.sh&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;ETCD_VERSION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;3.3.12&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 下载 Etcd 二进制文件&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;function &lt;/span&gt;download&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;etcd-v&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ETCD_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;-linux-amd64.tar.gz&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
        &lt;/span&gt;wget https://github.com/coreos/etcd/releases/download/v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ETCD_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/etcd-v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ETCD_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;-linux-amd64&lt;/span&gt;.tar.gz
        &lt;span class=&quot;nb&quot;&gt;tar&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-zxvf&lt;/span&gt; etcd-v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ETCD_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;-linux-amd64&lt;/span&gt;.tar.gz
    &lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

preinstall&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    getent group etcd &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;/dev/null &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; groupadd &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; etcd
    getent passwd etcd &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;/dev/null &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; useradd &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-g&lt;/span&gt; etcd &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; /var/lib/etcd &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; /sbin/nologin &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;etcd user&quot;&lt;/span&gt; etcd
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

install&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[32mINFO: Copy etcd...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;tar&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-zxf&lt;/span&gt; etcd-v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ETCD_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;-linux-amd64&lt;/span&gt;.tar.gz
    cp etcd-v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ETCD_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;-linux-amd64&lt;/span&gt;/etcd&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; /usr/local/bin
    rm &lt;span class=&quot;nt&quot;&gt;-rf&lt;/span&gt; etcd-v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ETCD_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;-linux-amd64&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[32mINFO: Copy etcd config...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
    cp &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; conf /etc/etcd
    chown &lt;span class=&quot;nt&quot;&gt;-R&lt;/span&gt; etcd:etcd /etc/etcd
    chmod &lt;span class=&quot;nt&quot;&gt;-R&lt;/span&gt; 755 /etc/etcd/ssl
    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[32mINFO: Copy etcd systemd config...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
    cp etcd.service /lib/systemd/system
    systemctl daemon-reload
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

postinstall&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/var/lib/etcd&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
        &lt;/span&gt;mkdir /var/lib/etcd
        chown &lt;span class=&quot;nt&quot;&gt;-R&lt;/span&gt; etcd:etcd /var/lib/etcd
    &lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

preinstall
install
postinstall
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;testsh&quot;&gt;test.sh&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export ETCDCTL_API=3
etcdctl --cacert=/etc/etcd/ssl/etcd-root-ca.pem --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem --endpoints=https://192.168.1.230:2379,https://192.168.1.231:2379,https://192.168.1.232:2379 endpoint health
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;文件列表&quot;&gt;文件列表&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# tree
.
├── conf
│   ├── etcd.conf
│   └── ssl
│       ├── etcd.csr
│       ├── etcd-csr.json
│       ├── etcd-gencert.json
│       ├── etcd-key.pem
│       ├── etcd.pem
│       ├── etcd-root-ca.csr
│       ├── etcd-root-ca-csr.json
│       ├── etcd-root-ca-key.pem
│       ├── etcd-root-ca.pem
│       └── key_etcd.sh
├── etcd.service
├── etcd-v3.3.12-linux-amd64.tar.gz
├── install.sh
└── test.sh

2 directories, 15 files
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;kubernetes&quot;&gt;kubernetes&lt;/h2&gt;
&lt;h3 id=&quot;证书配置-1&quot;&gt;证书配置&lt;/h3&gt;
&lt;p&gt;新版本已经逐渐使用 TLS + RBAC 配置，所以本次安装将会启动大部分 TLS + RBAC 配置，包括 kube-controler-manager、kube-scheduler 组件不再连接本地 kube-apiserver 的 8080 非认证端口，kubelet 等组件 API 端点关闭匿名访问，启动 RBAC 认证等；为了满足这些认证，需要签署以下证书&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;k8s-root-ca-csr.json 集群 CA 根证书&lt;/li&gt;
  &lt;li&gt;k8s-gencert.json 用于生成其他证书的标准配置&lt;/li&gt;
  &lt;li&gt;kube-apiserver-csr.json apiserver TLS 认证端口需要的证书&lt;/li&gt;
  &lt;li&gt;kube-controller-manager-csr.json controller manager 连接 apiserver 需要使用的证书，同时本身 10257 端口也会使用此证书&lt;/li&gt;
  &lt;li&gt;kube-scheduler-csr.json scheduler 连接 apiserver 需要使用的证书，同时本身 10259 端口也会使用此证书&lt;/li&gt;
  &lt;li&gt;kube-proxy-csr.json proxy 组件连接 apiserver 需要使用的证书&lt;/li&gt;
  &lt;li&gt;kubelet-api-admin-csr.json apiserver 反向连接 kubelet 组件 10250 端口需要使用的证书(例如执行 kubectl logs)&lt;/li&gt;
  &lt;li&gt;admin-csr.json 集群管理员(kubectl)连接 apiserver 需要使用的证书&lt;/li&gt;
  &lt;li&gt;metrics-server-csr.json metrics-server 需要配置的证书,用来获取集群资源信息;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;::::::::::::::
admin-csr.json
::::::::::::::
{
    &quot;CN&quot;: &quot;system:masters&quot;,
    &quot;hosts&quot;: [],
    &quot;key&quot;: {
        &quot;algo&quot;: &quot;rsa&quot;,
        &quot;size&quot;: 2048
    },
    &quot;names&quot;: [
        {
            &quot;C&quot;: &quot;CN&quot;,
            &quot;ST&quot;: &quot;Shengzhen&quot;,
            &quot;L&quot;: &quot;Shengzhen&quot;,
            &quot;O&quot;: &quot;system:masters&quot;,
            &quot;OU&quot;: &quot;System&quot;
        }
    ]
}

::::::::::::::
k8s-gencert.json
::::::::::::::
{
    &quot;signing&quot;: {
        &quot;default&quot;: {
            &quot;expiry&quot;: &quot;175200h&quot;
        },
        &quot;profiles&quot;: {
            &quot;kubernetes&quot;: {
                &quot;usages&quot;: [
                    &quot;signing&quot;,
                    &quot;key encipherment&quot;,
                    &quot;server auth&quot;,
                    &quot;client auth&quot;
                ],
                &quot;expiry&quot;: &quot;175200h&quot;
            }
        }
    }
}

::::::::::::::
k8s-root-ca-csr.json
::::::::::::::
{
    &quot;CN&quot;: &quot;kubernetes&quot;,
    &quot;key&quot;: {
        &quot;algo&quot;: &quot;rsa&quot;,
        &quot;size&quot;: 4096
    },
    &quot;names&quot;: [
        {
            &quot;C&quot;: &quot;CN&quot;,
            &quot;ST&quot;: &quot;Shengzhen&quot;,
            &quot;L&quot;: &quot;Shengzhen&quot;,
            &quot;O&quot;: &quot;kubernetes&quot;,
            &quot;OU&quot;: &quot;System&quot;
        }
    ],
    &quot;ca&quot;: {
        &quot;expiry&quot;: &quot;175200h&quot;
    }
}

::::::::::::::
kube-apiserver-csr.json
::::::::::::::
{
    &quot;CN&quot;: &quot;kubernetes&quot;,
    &quot;hosts&quot;: [
        &quot;127.0.0.1&quot;,
        &quot;10.254.0.1&quot;,
        &quot;localhost&quot;,
        &quot;*.master.kubernetes.node&quot;,
        &quot;kubernetes&quot;,
        &quot;kubernetes.default&quot;,
        &quot;kubernetes.default.svc&quot;,
        &quot;kubernetes.default.svc.cluster&quot;,
        &quot;kubernetes.default.svc.cluster.local&quot;
    ],
    &quot;key&quot;: {
        &quot;algo&quot;: &quot;rsa&quot;,
        &quot;size&quot;: 2048
    },
    &quot;names&quot;: [
        {
            &quot;C&quot;: &quot;CN&quot;,
            &quot;ST&quot;: &quot;Shengzhen&quot;,
            &quot;L&quot;: &quot;Shengzhen&quot;,
            &quot;O&quot;: &quot;kubernetes&quot;,
            &quot;OU&quot;: &quot;System&quot;
        }
    ]
}

::::::::::::::
kube-controller-manager-csr.json
::::::::::::::
{
  &quot;CN&quot;: &quot;system:kube-controller-manager&quot;,
  &quot;hosts&quot;: [
    &quot;127.0.0.1&quot;,
    &quot;localhost&quot;,
    &quot;*.master.kubernetes.node&quot;
  ],
  &quot;key&quot;: {
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  },
  &quot;names&quot;: [
    {
      &quot;C&quot;: &quot;CN&quot;,
      &quot;ST&quot;: &quot;Shengzhen&quot;,
      &quot;L&quot;: &quot;Shengzhen&quot;,
      &quot;O&quot;: &quot;system:kube-controller-manager&quot;,
      &quot;OU&quot;: &quot;System&quot;
    }
  ]
}

::::::::::::::
kubelet-api-admin-csr.json
::::::::::::::
{
    &quot;CN&quot;: &quot;system:kubelet-api-admin&quot;,
    &quot;hosts&quot;: [],
    &quot;key&quot;: {
        &quot;algo&quot;: &quot;rsa&quot;,
        &quot;size&quot;: 2048
    },
    &quot;names&quot;: [
        {
            &quot;C&quot;: &quot;CN&quot;,
            &quot;ST&quot;: &quot;Shengzhen&quot;,
            &quot;L&quot;: &quot;Shengzhen&quot;,
            &quot;O&quot;: &quot;system:kubelet-api-admin&quot;,
            &quot;OU&quot;: &quot;System&quot;
        }
    ]
}

::::::::::::::
kube-proxy-csr.json
::::::::::::::
{
    &quot;CN&quot;: &quot;system:kube-proxy&quot;,
    &quot;hosts&quot;: [],
    &quot;key&quot;: {
        &quot;algo&quot;: &quot;rsa&quot;,
        &quot;size&quot;: 2048
    },
    &quot;names&quot;: [
        {
            &quot;C&quot;: &quot;CN&quot;,
            &quot;ST&quot;: &quot;Shengzhen&quot;,
            &quot;L&quot;: &quot;Shengzhen&quot;,
            &quot;O&quot;: &quot;system:kube-proxy&quot;,
            &quot;OU&quot;: &quot;System&quot;
        }
    ]
}

::::::::::::::
kube-scheduler-csr.json
::::::::::::::
{
  &quot;CN&quot;: &quot;system:kube-scheduler&quot;,
  &quot;hosts&quot;: [
    &quot;127.0.0.1&quot;,
    &quot;localhost&quot;,
    &quot;*.master.kubernetes.node&quot;
  ],
  &quot;key&quot;: {
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  },
  &quot;names&quot;: [
    {
      &quot;C&quot;: &quot;CN&quot;,
      &quot;ST&quot;: &quot;Shengzhen&quot;,
      &quot;L&quot;: &quot;Shengzhen&quot;,
      &quot;O&quot;: &quot;system:kube-scheduler&quot;,
      &quot;OU&quot;: &quot;System&quot;
    }
  ]
}

::::::::::::::
metrics-server-csr.json
::::::::::::::
{
  &quot;CN&quot;: &quot;aggregator&quot;,
  &quot;hosts&quot;: [],
  &quot;key&quot;: {
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  },
  &quot;names&quot;: [
    {
      &quot;C&quot;: &quot;CN&quot;,
      &quot;ST&quot;: &quot;Shengzhen&quot;,
      &quot;L&quot;: &quot;Shengzhen&quot;,
      &quot;O&quot;: &quot;aggregator&quot;,
      &quot;OU&quot;: &quot;System&quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;最后使用下面脚本命令生成证书&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;::::::::::::::
key.sh
::::::::::::::
cfssl gencert --initca=true k8s-root-ca-csr.json | cfssljson --bare k8s-root-ca

for targetName in kube-apiserver kube-controller-manager kube-scheduler kube-proxy kubelet-api-admin admin metrics-server; do
    cfssl gencert --ca k8s-root-ca.pem --ca-key k8s-root-ca-key.pem --config k8s-gencert.json --profile kubernetes $targetName-csr.json | cfssljson --bare $targetName
done
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;生成配置文件&quot;&gt;生成配置文件&lt;/h3&gt;
&lt;p&gt;集群搭建需要预先生成一系列配置文件，生成配置需要预先安装 kubectl 命令；其中配置文件及其作用如下:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;bootstrap.kubeconfig kubelet TLS Bootstarp 引导阶段需要使用的配置文件&lt;/li&gt;
  &lt;li&gt;kube-controller-manager.kubeconfig controller manager 组件开启安全端口及 RBAC 认证所需配置&lt;/li&gt;
  &lt;li&gt;kube-scheduler.kubeconfig scheduler 组件开启安全端口及 RBAC 认证所需配置&lt;/li&gt;
  &lt;li&gt;kube-proxy.kubeconfig proxy 组件连接 apiserver 所需配置文件&lt;/li&gt;
  &lt;li&gt;audit-policy.yaml apiserver RBAC 审计日志配置文件&lt;/li&gt;
  &lt;li&gt;bootstrap.secret.yaml kubelet TLS Bootstarp 引导阶段使用 Bootstrap Token 方式引导，需要预先创建此 Token&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;执行下列命令生成上述配置文件&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 指定 apiserver 地址
KUBE_APISERVER=&quot;https://127.0.0.1:6443&quot;

# 生成 Bootstrap Token
BOOTSTRAP_TOKEN_ID=$(head -c 6 /dev/urandom | md5sum | head -c 6)
BOOTSTRAP_TOKEN_SECRET=$(head -c 16 /dev/urandom | md5sum | head -c 16)
BOOTSTRAP_TOKEN=&quot;${BOOTSTRAP_TOKEN_ID}.${BOOTSTRAP_TOKEN_SECRET}&quot;
echo &quot;Bootstrap Tokne: ${BOOTSTRAP_TOKEN}&quot;

# 生成 kubelet tls bootstrap 配置
echo &quot;Create kubelet bootstrapping kubeconfig...&quot;
kubectl config set-cluster kubernetes \
  --certificate-authority=k8s-root-ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=bootstrap.kubeconfig
kubectl config set-credentials &quot;system:bootstrap:${BOOTSTRAP_TOKEN_ID}&quot; \
  --token=${BOOTSTRAP_TOKEN} \
  --kubeconfig=bootstrap.kubeconfig
kubectl config set-context default \
  --cluster=kubernetes \
  --user=&quot;system:bootstrap:${BOOTSTRAP_TOKEN_ID}&quot; \
  --kubeconfig=bootstrap.kubeconfig
kubectl config use-context default --kubeconfig=bootstrap.kubeconfig

# 生成 kube-controller-manager 配置文件
echo &quot;Create kube-controller-manager kubeconfig...&quot;
kubectl config set-cluster kubernetes \
  --certificate-authority=k8s-root-ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=kube-controller-manager.kubeconfig
kubectl config set-credentials &quot;system:kube-controller-manager&quot; \
  --client-certificate=kube-controller-manager.pem \
  --client-key=kube-controller-manager-key.pem \
  --embed-certs=true \
  --kubeconfig=kube-controller-manager.kubeconfig
kubectl config set-context default \
  --cluster=kubernetes \
  --user=system:kube-controller-manager \
  --kubeconfig=kube-controller-manager.kubeconfig
kubectl config use-context default --kubeconfig=kube-controller-manager.kubeconfig

# 生成 kube-scheduler 配置文件
echo &quot;Create kube-scheduler kubeconfig...&quot;
kubectl config set-cluster kubernetes \
  --certificate-authority=k8s-root-ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=kube-scheduler.kubeconfig
kubectl config set-credentials &quot;system:kube-scheduler&quot; \
  --client-certificate=kube-scheduler.pem \
  --client-key=kube-scheduler-key.pem \
  --embed-certs=true \
  --kubeconfig=kube-scheduler.kubeconfig
kubectl config set-context default \
  --cluster=kubernetes \
  --user=system:kube-scheduler \
  --kubeconfig=kube-scheduler.kubeconfig
kubectl config use-context default --kubeconfig=kube-scheduler.kubeconfig

# 生成 kube-proxy 配置文件
echo &quot;Create kube-proxy kubeconfig...&quot;
kubectl config set-cluster kubernetes \
  --certificate-authority=k8s-root-ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=kube-proxy.kubeconfig
kubectl config set-credentials &quot;system:kube-proxy&quot; \
  --client-certificate=kube-proxy.pem \
  --client-key=kube-proxy-key.pem \
  --embed-certs=true \
  --kubeconfig=kube-proxy.kubeconfig
kubectl config set-context default \
  --cluster=kubernetes \
  --user=system:kube-proxy \
  --kubeconfig=kube-proxy.kubeconfig
kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig

# 生成 apiserver RBAC 审计配置文件
cat &amp;gt;&amp;gt; audit-policy.yaml &amp;lt;&amp;lt;EOF
# Log all requests at the Metadata level.
apiVersion: audit.k8s.io/v1
kind: Policy
rules:
- level: Metadata
EOF

# 生成 tls bootstrap token secret 配置文件
cat &amp;gt;&amp;gt; bootstrap.secret.yaml &amp;lt;&amp;lt;EOF
apiVersion: v1
kind: Secret
metadata:
  # Name MUST be of form &quot;bootstrap-token-&amp;lt;token id&amp;gt;&quot;
  name: bootstrap-token-${BOOTSTRAP_TOKEN_ID}
  namespace: kube-system
# Type MUST be 'bootstrap.kubernetes.io/token'
type: bootstrap.kubernetes.io/token
stringData:
  # Human readable description. Optional.
  description: &quot;The default bootstrap token.&quot;
  # Token ID and secret. Required.
  token-id: ${BOOTSTRAP_TOKEN_ID}
  token-secret: ${BOOTSTRAP_TOKEN_SECRET}
  # Expiration. Optional.
  expiration: $(date -d'+2 day' -u +&quot;%Y-%m-%dT%H:%M:%SZ&quot;)
  # Allowed usages.
  usage-bootstrap-authentication: &quot;true&quot;
  usage-bootstrap-signing: &quot;true&quot;
  # Extra groups to authenticate the token as. Must start with &quot;system:bootstrappers:&quot;
#  auth-extra-groups: system:bootstrappers:worker,system:bootstrappers:ingress
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;master-安装&quot;&gt;Master 安装&lt;/h3&gt;
&lt;h4 id=&quot;安装脚本&quot;&gt;安装脚本&lt;/h4&gt;
&lt;p&gt;master 节点上需要三个组件: kube-apiserver、kube-controller-manager、kube-scheduler&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;主要步骤如下:
    &lt;ul&gt;
      &lt;li&gt;下载二进制文件&lt;/li&gt;
      &lt;li&gt;配置命令及创建链接&lt;/li&gt;
      &lt;li&gt;复制conf 目录到/etc/kubernetes&lt;/li&gt;
      &lt;li&gt;复制service 文件&lt;/li&gt;
      &lt;li&gt;创建相关目录&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 下载 hyperkube&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;function &lt;/span&gt;download_k8s&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;hyperkube_v&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KUBE_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
        &lt;/span&gt;wget https://storage.googleapis.com/kubernetes-release/release/v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KUBE_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/bin/linux/amd64/hyperkube &lt;span class=&quot;nt&quot;&gt;-O&lt;/span&gt; hyperkube_v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KUBE_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
        chmod +x hyperkube_v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KUBE_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;function &lt;/span&gt;install_k8s&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[32mINFO: Copy hyperkube...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
    cp hyperkube_v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KUBE_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; /usr/bin/hyperkube

    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[32mINFO: Create symbolic link...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /usr/bin &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; hyperkube &lt;span class=&quot;nt&quot;&gt;--make-symlinks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[32mINFO: Copy kubernetes config...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
    cp &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; conf /etc/kubernetes

    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[32mINFO: Copy kubernetes systemd config...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
    cp systemd/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;.service /lib/systemd/system

    systemctl daemon-reload
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;function &lt;/span&gt;postinstall&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/var/log/kube-audit&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
        &lt;/span&gt;mkdir /var/log/kube-audit
    &lt;span class=&quot;k&quot;&gt;fi

    if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/var/lib/kubelet&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
        &lt;/span&gt;mkdir /var/lib/kubelet
    &lt;span class=&quot;k&quot;&gt;fi
    if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/usr/libexec&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
        &lt;/span&gt;mkdir /usr/libexec
    &lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

install_k8s
postinstall
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;hyperkube 是一个多合一的可执行文件，通过 –make-symlinks 会在当前目录生成 kubernetes 各个组件的软连接&lt;/p&gt;

&lt;h4 id=&quot;目录结构&quot;&gt;目录结构&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;├── apiserver
├── audit-policy.yaml
├── bootstrap.kubeconfig
├── bootstrap.secret.yaml
├── controller-manager
├── json
│   ├── admin-csr.json
│   ├── k8s-gencert.json
│   ├── k8s-root-ca-csr.json
│   ├── key.sh
│   ├── kube-apiserver-csr.json
│   ├── kube-controller-manager-csr.json
│   ├── kubelet-api-admin-csr.json
│   ├── kube-proxy-csr.json
│   ├── kube-scheduler-csr.json
│   └── metrics-server-csr.json
├── kube-controller-manager.kubeconfig
├── kubelet
├── kube-proxy.kubeconfig
├── kube-scheduler.kubeconfig
├── proxy
├── scheduler
├── ssl
│   ├── admin-key.pem
│   ├── admin.pem
│   ├── genconfig.sh
│   ├── k8s-root-ca-key.pem
│   ├── k8s-root-ca.pem
│   ├── kube-apiserver-key.pem
│   ├── kube-apiserver.pem
│   ├── kube-controller-manager-key.pem
│   ├── kube-controller-manager.pem
│   ├── kubelet-api-admin-key.pem
│   ├── kubelet-api-admin.pem
│   ├── kube-proxy-key.pem
│   ├── kube-proxy.pem
│   ├── kube-scheduler-key.pem
│   ├── kube-scheduler.pem
│   ├── metrics-server-key.pem
│   └── metrics-server.pem
└── tls.sh

2 directories, 40 files
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;systemd&quot;&gt;systemd&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;::::::::::::::
kube-apiserver.service
::::::::::::::
[Unit]
Description=Kubernetes API Server
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=network.target
After=etcd.service

[Service]
EnvironmentFile=-/etc/kubernetes/apiserver
User=root
ExecStart=/usr/local/bin/kube-apiserver \
	    $KUBE_LOGTOSTDERR \
	    $KUBE_LOG_LEVEL \
	    $KUBE_ETCD_SERVERS \
	    $KUBE_API_ADDRESS \
	    $KUBE_API_PORT \
	    $KUBELET_PORT \
	    $KUBE_ALLOW_PRIV \
	    $KUBE_SERVICE_ADDRESSES \
	    $KUBE_ADMISSION_CONTROL \
	    $KUBE_API_ARGS
Restart=on-failure
Type=notify
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target

::::::::::::::
kube-controller-manager.service
::::::::::::::
[Unit]
Description=Kubernetes Controller Manager
Documentation=https://github.com/GoogleCloudPlatform/kubernetes

[Service]
EnvironmentFile=-/etc/kubernetes/controller-manager
User=root
ExecStart=/usr/local/bin/kube-controller-manager \
	    $KUBE_LOGTOSTDERR \
	    $KUBE_LOG_LEVEL \
	    $KUBE_MASTER \
	    $KUBE_CONTROLLER_MANAGER_ARGS
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target


::::::::::::::
kube-scheduler.service
::::::::::::::
[Unit]
Description=Kubernetes Scheduler Plugin
Documentation=https://github.com/GoogleCloudPlatform/kubernetes

[Service]
EnvironmentFile=-/etc/kubernetes/scheduler
User=root
ExecStart=/usr/local/bin/kube-scheduler \
	    $KUBE_LOGTOSTDERR \
	    $KUBE_LOG_LEVEL \
	    $KUBE_MASTER \
	    $KUBE_SCHEDULER_ARGS
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;核心配置文件&quot;&gt;核心配置文件&lt;/h4&gt;

&lt;h5 id=&quot;apiserver&quot;&gt;apiserver&lt;/h5&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;###
# kubernetes system config
#
# The following values are used to configure the kube-apiserver
#

# The address on the local server to listen to.
KUBE_API_ADDRESS=&quot;--advertise-address=192.168.1.230 --bind-address=0.0.0.0&quot;

# The port on the local server to listen on.
KUBE_API_PORT=&quot;--secure-port=6443&quot;

# Port minions listen on
# KUBELET_PORT=&quot;--kubelet-port=10250&quot;

# Comma separated list of nodes in the etcd cluster
KUBE_ETCD_SERVERS=&quot;--etcd-servers=https://192.168.1.230:2379,https://192.168.1.231:2379,https://192.168.1.232:2379&quot;

# Address range to use for services
KUBE_SERVICE_ADDRESSES=&quot;--service-cluster-ip-range=10.254.0.0/16&quot;

# default admission control policies
KUBE_ADMISSION_CONTROL=&quot;--enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,Priority,ResourceQuota&quot;

# Add your own!
KUBE_API_ARGS=&quot; --allow-privileged=true \
                --anonymous-auth=false \
                --alsologtostderr \
                --apiserver-count=3 \
                --audit-log-maxage=30 \
                --audit-log-maxbackup=3 \
                --audit-log-maxsize=100 \
                --audit-log-path=/var/log/kube-audit/audit.log \
                --audit-policy-file=/etc/kubernetes/audit-policy.yaml \
                --authorization-mode=Node,RBAC \
                --client-ca-file=/etc/kubernetes/ssl/k8s-root-ca.pem \
                --enable-bootstrap-token-auth \
                --enable-garbage-collector \
                --enable-logs-handler \
                --endpoint-reconciler-type=lease \
                --etcd-cafile=/etc/etcd/ssl/etcd-root-ca.pem \
                --etcd-certfile=/etc/etcd/ssl/etcd.pem \
                --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem \
                --etcd-compaction-interval=0s \
                --event-ttl=168h0m0s \
                --kubelet-https=true \
                --kubelet-certificate-authority=/etc/kubernetes/ssl/k8s-root-ca.pem \
                --kubelet-client-certificate=/etc/kubernetes/ssl/kubelet-api-admin.pem \
                --kubelet-client-key=/etc/kubernetes/ssl/kubelet-api-admin-key.pem \
                --kubelet-timeout=3s \
                --runtime-config=api/all=true \
                --service-node-port-range=30000-50000 \
                --service-account-key-file=/etc/kubernetes/ssl/k8s-root-ca.pem \
                --tls-cert-file=/etc/kubernetes/ssl/kube-apiserver.pem \
                --tls-private-key-file=/etc/kubernetes/ssl/kube-apiserver-key.pem \
                --requestheader-client-ca-file=/etc/kubernetes/ssl/k8s-root-ca.pem \
                --requestheader-allowed-names=aggregator \
                --enable-aggregator-routing=true \
                --requestheader-group-headers=X-Remote-Group \
                --requestheader-extra-headers-prefix=X-Remote-Extra- \
                --requestheader-username-headers=X-Remote-User \
                --proxy-client-cert-file=/etc/kubernetes/ssl/metrics-server.pem \
                --proxy-client-key-file=/etc/kubernetes/ssl/metrics-server-key.pem \
                --v=2&quot;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h6 id=&quot;配置说明&quot;&gt;配置说明&lt;/h6&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;配置项&lt;/th&gt;
      &lt;th&gt;说明&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;–client-ca-file&lt;/td&gt;
      &lt;td&gt;定义客户端 CA&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;–endpoint-reconciler-type&lt;/td&gt;
      &lt;td&gt;master endpoint 策略&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;–kubelet-client-certificate、–kubelet-client-key&lt;/td&gt;
      &lt;td&gt;master 反向连接 kubelet 使用的证书&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;–service-account-key-file&lt;/td&gt;
      &lt;td&gt;service account 签名 key(用于有效性验证)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;–tls-cert-file、–tls-private-key-file&lt;/td&gt;
      &lt;td&gt;master apiserver 6443 端口证书&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h6 id=&quot;metrics-server-配置说明&quot;&gt;metrics-server 配置说明&lt;/h6&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;--requestheader-client-ca-file:ca 证书
--requestheader-allowed-names:  客户端证书常用名称列表。允许在--requestheader-username-headers指定的标头中提供用户名，如果为空，则允许在--requestheader-client-ca文件中通过当局验证的任何客户端证书
--requestheader-extra-headers-prefix:  要检查的请求标头前缀列表
--requestheader-group-headers:  要检查组的请求标头列表
--requestheader-username-headers:  要检查用户名的请求标头列表
--proxy-client-cert-file:  用于证明aggregator或kube-apiserver在请求期间发出呼叫的身份的客户端证书
--proxy-client-key-file:  用于证明聚合器或kube-apiserver的身份的客户端证书的私钥，当它必须在请求期间调用时使用。包括将请求代理给用户api-server和调用webhook admission插件
--enable-aggregator-routing=true:  打开aggregator路由请求到endpoints IP，而不是集群IP
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;controller-manager&quot;&gt;controller-manager&lt;/h5&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;###
# The following values are used to configure the kubernetes controller-manager

# defaults from config and apiserver should be adequate

#Add your own!
KUBE_CONTROLLER_MANAGER_ARGS=&quot;  --address=127.0.0.1 \
                                --authentication-kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig \
                                --authorization-kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig \
                                --bind-address=0.0.0.0 \
                                --cluster-name=kubernetes \
                                --cluster-signing-cert-file=/etc/kubernetes/ssl/k8s-root-ca.pem \
                                --cluster-signing-key-file=/etc/kubernetes/ssl/k8s-root-ca-key.pem \
                                --client-ca-file=/etc/kubernetes/ssl/k8s-root-ca.pem \
                                --controllers=*,bootstrapsigner,tokencleaner \
                                --deployment-controller-sync-period=10s \
                                --experimental-cluster-signing-duration=175200h0m0s \
                                --enable-garbage-collector=true \
                                --kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig \
                                --leader-elect=true \
                                --node-monitor-grace-period=20s \
                                --node-monitor-period=5s \
                                --port=10252 \
                                --pod-eviction-timeout=2m0s \
                                --requestheader-client-ca-file=/etc/kubernetes/ssl/k8s-root-ca.pem \
                                --terminated-pod-gc-threshold=50 \
                                --tls-cert-file=/etc/kubernetes/ssl/kube-controller-manager.pem \
                                --tls-private-key-file=/etc/kubernetes/ssl/kube-controller-manager-key.pem \
                                --root-ca-file=/etc/kubernetes/ssl/k8s-root-ca.pem \
                                --secure-port=10257 \
                                --service-cluster-ip-range=10.254.0.0/16 \
                                --service-account-private-key-file=/etc/kubernetes/ssl/k8s-root-ca-key.pem \
                                --use-service-account-credentials=true \
                                --v=2&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;controller manager 将不安全端口 10252 绑定到 127.0.0.1 确保 kuebctl get cs 有正确返回；将安全端口 10257 绑定到 0.0.0.0 公开，提供服务调用；由于 controller manager 开始连接 apiserver 的 6443 认证端口，所以需要 –use-service-account-credentials 选项来让 controller manager 创建单独的 service account(默认 system:kube-controller-manager 用户没有那么高权限)&lt;/p&gt;

&lt;h5 id=&quot;scheduler&quot;&gt;scheduler&lt;/h5&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;###
# kubernetes scheduler config

# default config should be adequate

# Add your own!
KUBE_SCHEDULER_ARGS=&quot;   --address=127.0.0.1 \
                        --authentication-kubeconfig=/etc/kubernetes/kube-scheduler.kubeconfig \
                        --authorization-kubeconfig=/etc/kubernetes/kube-scheduler.kubeconfig \
                        --bind-address=0.0.0.0 \
                        --client-ca-file=/etc/kubernetes/ssl/k8s-root-ca.pem \
                        --kubeconfig=/etc/kubernetes/kube-scheduler.kubeconfig \
                        --requestheader-client-ca-file=/etc/kubernetes/ssl/k8s-root-ca.pem \
                        --secure-port=10259 \
                        --leader-elect=true \
                        --port=10251 \
                        --tls-cert-file=/etc/kubernetes/ssl/kube-scheduler.pem \
                        --tls-private-key-file=/etc/kubernetes/ssl/kube-scheduler-key.pem \
                        --v=2&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;最后各个master 节点执行安装脚本, 修改配置文件对应的IP,启动即可!&lt;/p&gt;

&lt;h4 id=&quot;验证安装&quot;&gt;验证安装&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# kubectl get cs
NAME                 STATUS    MESSAGE             ERROR
controller-manager   Healthy   ok
scheduler            Healthy   ok
etcd-0               Healthy   {&quot;health&quot;:&quot;true&quot;}
etcd-1               Healthy   {&quot;health&quot;:&quot;true&quot;}
etcd-2               Healthy   {&quot;health&quot;:&quot;true&quot;}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;node-安装&quot;&gt;Node 安装&lt;/h3&gt;
&lt;h4 id=&quot;first_installsh&quot;&gt;first_install.sh&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;## 初始化 node 节点&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 下载 hyperkube&lt;/span&gt;
download_k8s&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;hyperkube_v&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KUBE_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
        &lt;/span&gt;wget https://storage.googleapis.com/kubernetes-release/release/v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KUBE_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/bin/linux/amd64/hyperkube &lt;span class=&quot;nt&quot;&gt;-O&lt;/span&gt; hyperkube_v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KUBE_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
        chmod +x hyperkube_v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KUBE_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

install_k8s&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[32mINFO: Copy hyperkube...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
    cp hyperkube_v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KUBE_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; /usr/bin/hyperkube

    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[32mINFO: Create symbolic link...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /usr/bin &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; hyperkube &lt;span class=&quot;nt&quot;&gt;--make-symlinks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[32mINFO: Copy kubernetes config...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
    cp &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; conf /etc/kubernetes

    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[32mINFO: Copy kubernetes systemd config...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
    cp systemd/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;.service /lib/systemd/system

    systemctl daemon-reload
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

nginx_proxy&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;## master节点如有更改请手动更新配置&lt;/span&gt;
   &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[32mINFO: Copy kubernetes nginx-proxy HA config...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
   cp &lt;span class=&quot;nt&quot;&gt;-a&lt;/span&gt; nginx /etc/
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

postinstall&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/var/log/kube-audit&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
        &lt;/span&gt;mkdir /var/log/kube-audit
    &lt;span class=&quot;k&quot;&gt;fi

    if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/var/lib/kubelet&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
        &lt;/span&gt;mkdir /var/lib/kubelet
    &lt;span class=&quot;k&quot;&gt;fi
    if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/usr/libexec&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
        &lt;/span&gt;mkdir /usr/libexec
    &lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;## coredns support&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/var/lib/resolve&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;then
	&lt;/span&gt;mkdir &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; /var/lib/resolve/
        ln &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; /etc/resolv.conf /var/lib/resolve/resolv.conf
    &lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

install_k8s
postinstall
nginx_proxy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;systemd-1&quot;&gt;systemd&lt;/h4&gt;
&lt;h5 id=&quot;kubeletservice&quot;&gt;kubelet.service&lt;/h5&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
Description=Kubernetes Kubelet Server
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=docker.service
Requires=docker.service

[Service]
WorkingDirectory=/var/lib/kubelet
EnvironmentFile=-/etc/kubernetes/kubelet
ExecStart=/usr/local/bin/kubelet \
	    $KUBE_LOGTOSTDERR \
	    $KUBE_LOG_LEVEL \
	    $KUBELET_API_SERVER \
	    $KUBELET_ADDRESS \
	    $KUBELET_PORT \
	    $KUBELET_HOSTNAME \
	    $KUBE_ALLOW_PRIV \
	    $KUBELET_ARGS
Restart=on-failure
KillMode=process

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;kube-proxyservice&quot;&gt;kube-proxy.service&lt;/h5&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
Description=Kubernetes Kube-Proxy Server
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=network.target

[Service]
EnvironmentFile=-/etc/kubernetes/proxy
ExecStart=/usr/local/bin/kube-proxy \
	    $KUBE_LOGTOSTDERR \
	    $KUBE_LOG_LEVEL \
	    $KUBE_MASTER \
	    $KUBE_PROXY_ARGS
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;核心配置文件-1&quot;&gt;核心配置文件&lt;/h4&gt;
&lt;h5 id=&quot;kubelet&quot;&gt;kubelet&lt;/h5&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;###
# kubernetes kubelet (minion) config

# The address for the info server to serve on (set to 0.0.0.0 or &quot;&quot; for all interfaces)
KUBELET_ADDRESS=&quot;--node-ip=IP&quot;

# The port for the info server to serve on
# KUBELET_PORT=&quot;--port=10250&quot;

# You may leave this blank to use the actual hostname
KUBELET_HOSTNAME=&quot;--hostname-override=NODE&quot;

# location of the api-server
# KUBELET_API_SERVER=&quot;&quot;

# Add your own!
KUBELET_ARGS=&quot;  --address=0.0.0.0 \
                --allow-privileged \
                --anonymous-auth=false \
                --authentication-token-webhook=true \
                --authorization-mode=Webhook \
                --bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \
                --client-ca-file=/etc/kubernetes/ssl/k8s-root-ca.pem \
                --network-plugin=cni \
                --cgroup-driver=cgroupfs \
                --cert-dir=/etc/kubernetes/ssl \
                --cluster-dns=10.254.0.2 \
                --cluster-domain=cluster.local \
                --cni-conf-dir=/etc/cni/net.d \
                --eviction-soft=imagefs.available&amp;lt;15%,memory.available&amp;lt;512Mi,nodefs.available&amp;lt;15%,nodefs.inodesFree&amp;lt;10% \
                --eviction-soft-grace-period=imagefs.available=3m,memory.available=1m,nodefs.available=3m,nodefs.inodesFree=1m \
                --eviction-hard=imagefs.available&amp;lt;10%,memory.available&amp;lt;256Mi,nodefs.available&amp;lt;10%,nodefs.inodesFree&amp;lt;5% \
                --eviction-max-pod-grace-period=30 \
                --image-gc-high-threshold=80 \
                --image-gc-low-threshold=70 \
                --image-pull-progress-deadline=30s \
                --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \
                --minimum-image-ttl-duration=720h0m0s \
                --node-labels=node.kubernetes.io/k8s-node=true \
                --pod-infra-container-image=gcr.azk8s.cn/google_containers/pause-amd64:3.1 \
                --port=10250 \
                --rotate-certificates \
                --rotate-server-certificates \
                --resolv-conf=/var/lib/resolve/resolv.conf \
                --fail-swap-on=false \
                --v=2&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h5 id=&quot;proxy&quot;&gt;proxy&lt;/h5&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;###
# kubernetes proxy config
# default config should be adequate
# Add your own!
KUBE_PROXY_ARGS=&quot;   --bind-address=0.0.0.0 \
                    --cleanup-ipvs=true \
                    --cluster-cidr=10.254.0.0/16 \
                    --hostname-override=NODE \
                    --healthz-bind-address=0.0.0.0 \
                    --healthz-port=10256 \
                    --masquerade-all=true \
                    --proxy-mode=ipvs \
                    --ipvs-min-sync-period=5s \
                    --ipvs-sync-period=5s \
                    --ipvs-scheduler=wrr \
                    --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig \
                    --logtostderr=true \
                    --v=2&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;nginx-代理ha&quot;&gt;nginx 代理(HA)&lt;/h4&gt;
&lt;p&gt;为了保证 apiserver 的 HA，需要在每个 node 上部署 nginx 来反向代理(tcp)所有 apiserver；然后 kubelet、kube-proxy 组件连接本地 127.0.0.1:6443 访问 apiserver，以确保任何 master 挂掉以后 node 都不会受到影响&lt;/p&gt;

&lt;h5 id=&quot;nginxconf&quot;&gt;nginx.conf&lt;/h5&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;error_log stderr notice;

worker_processes auto;
events {
  	multi_accept on;
  	use epoll;
  	worker_connections 1024;
}

stream {
    upstream kube_apiserver {
        least_conn;
        server 192.168.1.230:6443;
        server 192.168.1.231:6443;
        server 192.168.1.232:6443;
    }

    server {
        listen        0.0.0.0:6443;
        proxy_pass    kube_apiserver;
        proxy_timeout 10m;
        proxy_connect_timeout 1s;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h5 id=&quot;nginx-proxyservice&quot;&gt;nginx-proxy.service&lt;/h5&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
Description=kubernetes apiserver docker wrapper
Wants=docker.socket
After=docker.service

[Service]
User=root
PermissionsStartOnly=true
ExecStart=/usr/bin/docker run -p 127.0.0.1:6443:6443 \
                              -v /etc/nginx:/etc/nginx \
                              --name nginx-proxy \
                              --net=host \
                              --restart=on-failure:5 \
                              --memory=512M \
                              nginx:1.14.2-alpine
ExecStartPre=-/usr/bin/docker rm -f nginx-proxy
ExecStop=/usr/bin/docker stop nginx-proxy
Restart=always
RestartSec=15s
TimeoutStartSec=30s

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;tls-bootstrap&quot;&gt;TLS Bootstrap&lt;/h4&gt;
&lt;p&gt;由于 kubelet 组件是采用 TLS Bootstrap 启动，所以需要预先创建相关配置 在&lt;code class=&quot;highlighter-rouge&quot;&gt;master&lt;/code&gt;节点操作执行即可!&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;tls.sh&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 创建用于 tls bootstrap 的 token secret
kubectl create -f bootstrap.secret.yaml

# 为了能让 kubelet 实现自动更新证书，需要配置相关 clusterrolebinding

# 允许 kubelet tls bootstrap 创建 csr 请求
kubectl create clusterrolebinding create-csrs-for-bootstrapping \
    --clusterrole=system:node-bootstrapper \
    --group=system:bootstrappers

# 自动批准 system:bootstrappers 组用户 TLS bootstrapping 首次申请证书的 CSR 请求
kubectl create clusterrolebinding auto-approve-csrs-for-group \
    --clusterrole=system:certificates.k8s.io:certificatesigningrequests:nodeclient \
    --group=system:bootstrappers

# 自动批准 system:nodes 组用户更新 kubelet 自身与 apiserver 通讯证书的 CSR 请求
kubectl create clusterrolebinding auto-approve-renewals-for-nodes \
    --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeclient \
    --group=system:nodes

# 在 kubelet server 开启 api 认证的情况下，apiserver 反向访问 kubelet 10250 需要此授权(eg: kubectl logs)
kubectl create clusterrolebinding system:kubelet-api-admin \
    --clusterrole=system:kubelet-api-admin \
    --user=system:kubelet-api-admin
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;最后依次执行:
    &lt;ul&gt;
      &lt;li&gt;bash first_install.sh&lt;/li&gt;
      &lt;li&gt;修改kubelet,proxy 配置文件hostname 和 IP地址&lt;/li&gt;
      &lt;li&gt;每个node 先启动 nginx-proxy.service&lt;/li&gt;
      &lt;li&gt;最后在各node 节点依次启动kubelet、kube-proxy 即可&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;kubelet-server-证书&quot;&gt;kubelet server 证书&lt;/h4&gt;
&lt;p&gt;注意: 新版本 kubelet server 的证书自动签发已经被关闭(看 issue 好像是由于安全原因)，所以对于 kubelet server 的证书仍需要手动签署&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# kubectl get csr
NAME                                                   AGE   REQUESTOR                  CONDITION
csr-99l77                                              10s   system:node:docker4.node   Pending
node-csr-aGwaNKorMc0MZBYOuJsJGCB8Bg8ds97rmE3oKBTV-_E   11s   system:bootstrap:5d820b    Approved,Issued
# kubectl certificate approve csr-99l77
certificatesigningrequest.certificates.k8s.io/csr-99l77 approved
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;验证节点&quot;&gt;验证节点&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# kubectl get node -o wide
NAME         STATUS   ROLES    AGE    VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION                CONTAINER-RUNTIME
k8s-node01   NotReady    &amp;lt;none&amp;gt;   1m   v1.13.8   192.168.1.233   &amp;lt;none&amp;gt;        CentOS Linux 7 (Core)   4.4.189-1.el7.elrepo.x86_64   docker://19.3.1
k8s-node02   NotReady    &amp;lt;none&amp;gt;   1m   v1.13.8   192.168.1.234   &amp;lt;none&amp;gt;        CentOS Linux 7 (Core)   4.4.189-1.el7.elrepo.x86_64   docker://19.3.1
k8s-node03   NotReady    &amp;lt;none&amp;gt;   1m   v1.13.8   192.168.1.235   &amp;lt;none&amp;gt;        CentOS Linux 7 (Core)   4.4.189-1.el7.elrepo.x86_64   docker://19.3.1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;此时查看节点状态,是处于 &lt;code class=&quot;highlighter-rouge&quot;&gt;NotReady&lt;/code&gt;的，这是因为没有安装网络插件导致的. 暂时忽略,下面开始逐个部署&lt;code class=&quot;highlighter-rouge&quot;&gt;Addons&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;addons&quot;&gt;Addons&lt;/h2&gt;
&lt;h3 id=&quot;calico&quot;&gt;calico&lt;/h3&gt;
&lt;p&gt;当 node 全部启动后，由于网络组件(CNI)未安装会显示为 NotReady 状态；下面将部署 Calico 作为网络组件，完成跨节点网络通讯；具体安装文档可以参考 &lt;a href=&quot;https://docs.projectcalico.org/v3.6/getting-started/kubernetes/installation/calico#installing-with-the-etcd-datastore&quot;&gt;Calico&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这里我选择使用etcd 作为后端数据存储&lt;/p&gt;

&lt;h4 id=&quot;下载示例文件&quot;&gt;下载示例文件&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl \
https://docs.projectcalico.org/v3.6/getting-started/kubernetes/installation/hosted/calico.yaml \
-O
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;初始化修改配置&quot;&gt;初始化修改配置&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/jevic/kshell/blob/master/kubernetes/1.13.8/calico/init.sh&quot;&gt;init.sh&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;ETCD_CERT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; /etc/etcd/ssl/etcd.pem | base64 | tr &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;ETCD_KEY&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; /etc/etcd/ssl/etcd-key.pem | base64 | tr &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;ETCD_CA&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; /etc/etcd/ssl/etcd-root-ca.pem | base64 | tr &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;ETCD_ENDPOINTS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;https://192.168.1.230:2379,https://192.168.1.231:2379,https://192.168.1.232:2379&quot;&lt;/span&gt;

sed &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;s@.*etcd_endpoints:.*@&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\ \ &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;etcd_endpoints:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\ \&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ETCD_ENDPOINTS&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;@gi&quot;&lt;/span&gt; calico.yaml
sed &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;s@.*etcd-cert:.*@&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\ \ &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;etcd-cert:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\ &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ETCD_CERT&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;@gi&quot;&lt;/span&gt; calico.yaml
sed &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;s@.*etcd-key:.*@&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\ \ &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;etcd-key:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\ &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ETCD_KEY&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;@gi&quot;&lt;/span&gt; calico.yaml
sed &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;s@.*etcd-ca:.*@&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\ \ &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;etcd-ca:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\ &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ETCD_CA&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;@gi&quot;&lt;/span&gt; calico.yaml
sed &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'s@.*etcd_ca:.*@\ \ etcd_ca:\ &quot;/calico-secrets/etcd-ca&quot;@gi'&lt;/span&gt; calico.yaml
sed &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'s@.*etcd_cert:.*@\ \ etcd_cert:\ &quot;/calico-secrets/etcd-cert&quot;@gi'&lt;/span&gt; calico.yaml
sed &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'s@.*etcd_key:.*@\ \ etcd_key:\ &quot;/calico-secrets/etcd-key&quot;@gi'&lt;/span&gt; calico.yaml

&lt;span class=&quot;nv&quot;&gt;POD_CIDR&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;10.20.0.0/16&quot;&lt;/span&gt;
sed &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;s?192.168.0.0/16?&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$POD_CIDR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;?g&quot;&lt;/span&gt; calico.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;部署&quot;&gt;部署&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; kubectl apply -f calico.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;此时,查看节点状态已经正常运行&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; # kubectl get node
NAME         STATUS   ROLES    AGE     VERSION
k8s-node01   Ready    &amp;lt;none&amp;gt;   5m   v1.13.8
k8s-node02   Ready    &amp;lt;none&amp;gt;   5m   v1.13.8
k8s-node03   Ready    &amp;lt;none&amp;gt;   5m   v1.13.8
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;coredns&quot;&gt;coredns&lt;/h3&gt;

&lt;p&gt;其他组件全部完成后我们应当部署集群 DNS 使 service 等能够正常解析；集群 DNS 这里采用 coredns，具体安装文档参考  &lt;a href=&quot;https://github.com/coredns/deployment/tree/master/kubernetes&quot;&gt;coredns/deploy&lt;/a&gt;; coredns 完整配置&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;coredns.yaml&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apiVersion: v1
kind: ServiceAccount
metadata:
  name: coredns
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: system:coredns
rules:
- apiGroups:
  - &quot;&quot;
  resources:
  - endpoints
  - services
  - pods
  - namespaces
  verbs:
  - list
  - watch
- apiGroups:
  - &quot;&quot;
  resources:
  - nodes
  verbs:
  - get
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: system:coredns
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:coredns
subjects:
- kind: ServiceAccount
  name: coredns
  namespace: kube-system
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: coredns
  namespace: kube-system
data:
  Corefile: |
    .:53 {
        errors
        health
        ready
        kubernetes cluster.local in-addr.arpa ip6.arpa {
          pods insecure
          fallthrough in-addr.arpa ip6.arpa
        }
        prometheus :9153
        forward . /etc/resolv.conf
        cache 30
        loop
        reload
        loadbalance
    }
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: coredns
  namespace: kube-system
  labels:
    k8s-app: kube-dns
    kubernetes.io/name: &quot;CoreDNS&quot;
spec:
  replicas: 2
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  selector:
    matchLabels:
      k8s-app: kube-dns
  template:
    metadata:
      labels:
        k8s-app: kube-dns
    spec:
      priorityClassName: system-cluster-critical
      serviceAccountName: coredns
      tolerations:
        - key: &quot;CriticalAddonsOnly&quot;
          operator: &quot;Exists&quot;
      nodeSelector:
        beta.kubernetes.io/os: linux
      containers:
      - name: coredns
        image: coredns/coredns:1.5.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;部署DNS 自动扩容
在大规模集群的情况下，可能需要集群 DNS 自动扩容，具体文档请参考 &lt;a href=&quot;https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/dns-horizontal-autoscaler&quot;&gt;DNS Horizontal Autoscaler&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;dns-horizontal-autoscaler.yaml&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Copyright 2016 The Kubernetes Authors.
#
# Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

kind: ServiceAccount
apiVersion: v1
metadata:
  name: kube-dns-autoscaler
  namespace: kube-system
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: system:kube-dns-autoscaler
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
rules:
  - apiGroups: [&quot;&quot;]
    resources: [&quot;nodes&quot;]
    verbs: [&quot;list&quot;]
  - apiGroups: [&quot;&quot;]
    resources: [&quot;replicationcontrollers/scale&quot;]
    verbs: [&quot;get&quot;, &quot;update&quot;]
  - apiGroups: [&quot;extensions&quot;]
    resources: [&quot;deployments/scale&quot;, &quot;replicasets/scale&quot;]
    verbs: [&quot;get&quot;, &quot;update&quot;]
# Remove the configmaps rule once below issue is fixed:
# kubernetes-incubator/cluster-proportional-autoscaler#16
  - apiGroups: [&quot;&quot;]
    resources: [&quot;configmaps&quot;]
    verbs: [&quot;get&quot;, &quot;create&quot;]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: system:kube-dns-autoscaler
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
subjects:
  - kind: ServiceAccount
    name: kube-dns-autoscaler
    namespace: kube-system
roleRef:
  kind: ClusterRole
  name: system:kube-dns-autoscaler
  apiGroup: rbac.authorization.k8s.io

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kube-dns-autoscaler
  namespace: kube-system
  labels:
    k8s-app: kube-dns-autoscaler
    kubernetes.io/cluster-service: &quot;true&quot;
    addonmanager.kubernetes.io/mode: Reconcile
spec:
  selector:
    matchLabels:
      k8s-app: kube-dns-autoscaler
  template:
    metadata:
      labels:
        k8s-app: kube-dns-autoscaler
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      priorityClassName: system-cluster-critical
      containers:
      - name: autoscaler
        image: gcr.azk8s.cn/google_containers/cluster-proportional-autoscaler-amd64:1.1.2-r2
        resources:
            requests:
                cpu: &quot;20m&quot;
                memory: &quot;10Mi&quot;
        command:
          - /cluster-proportional-autoscaler
          - --namespace=kube-system
          - --configmap=kube-dns-autoscaler
          # Should keep target in sync with cluster/addons/dns/kube-dns.yaml.base
          - --target=Deployment/coredns
          # When cluster is using large nodes(with more cores), &quot;coresPerReplica&quot; should dominate.
          # If using small nodes, &quot;nodesPerReplica&quot; should dominate.
          - --default-params={&quot;linear&quot;:{&quot;coresPerReplica&quot;:256,&quot;nodesPerReplica&quot;:16,&quot;preventSinglePointFailure&quot;:true}}
          - --logtostderr=true
          - --v=2
      tolerations:
      - key: &quot;CriticalAddonsOnly&quot;
        operator: &quot;Exists&quot;
      serviceAccountName: kube-dns-autoscaler
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;metrics-server&quot;&gt;metrics-server&lt;/h3&gt;
&lt;p&gt;从 v1.8 开始，资源使用情况的监控可以通过 Metrics API的形式获取，具体的组件为Metrics Server，用来替换之前的heapster，heapster从1.11开始逐渐被废弃。
Metrics-Server是集群核心监控数据的聚合器，从 Kubernetes1.8 开始，它作为一个 Deployment对象默认部署在由kube-up.sh脚本创建的集群中&lt;/p&gt;

&lt;p&gt;这里需要强调一点: 由于&lt;code class=&quot;highlighter-rouge&quot;&gt;metrics-server&lt;/code&gt; 默认开启的是 &lt;code class=&quot;highlighter-rouge&quot;&gt;ClusterIP 443&lt;/code&gt;, 导致在部署&lt;code class=&quot;highlighter-rouge&quot;&gt;traefik&lt;/code&gt;的时候 节点端口冲突,无法正常使用! 如果要用到 &lt;code class=&quot;highlighter-rouge&quot;&gt;traefik&lt;/code&gt; 可尝试调整端口部署;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;部署此服务,需要单独配置证书文件,在前面我们已经提前生成了，且已经在apiserver 加了对应的配置,此处不再叙述;&lt;/li&gt;
  &lt;li&gt;clone 项目 &lt;a href=&quot;https://github.com/kubernetes-incubator/metrics-server&quot;&gt;metrics-server&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;metrics-server/deploy/1.8+/ 修改yaml 文件
    &lt;ul&gt;
      &lt;li&gt;resource-reader.yaml&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;```
  …..
  rules:&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;apiGroups:
    &lt;ul&gt;
      &lt;li&gt;””
resources:&lt;/li&gt;
      &lt;li&gt;pods&lt;/li&gt;
      &lt;li&gt;nodes&lt;/li&gt;
      &lt;li&gt;nodes/stats&lt;/li&gt;
      &lt;li&gt;namespaces ## 增加此项
verbs:&lt;/li&gt;
      &lt;li&gt;get&lt;/li&gt;
      &lt;li&gt;list&lt;/li&gt;
      &lt;li&gt;watch
```
        &lt;ul&gt;
          &lt;li&gt;metrics-server-deployment.yaml&lt;/li&gt;
        &lt;/ul&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; ......
 containers:
  - name: metrics-server
    image: gcr.azk8s.cn/google_containers/metrics-server-amd64:v0.3.3
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
    command:
    - /metrics-server
    - --kubelet-insecure-tls ## 新增
    - --kubelet-preferred-address-types=InternalIP ## 新增
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;说明：
    &lt;ul&gt;
      &lt;li&gt;增加了–kubelet-preferred-address-types=InternalIP和–kubelet-insecure-tls参数&lt;/li&gt;
      &lt;li&gt;否则metrics server可能会从kubelet拿不到监控数据;&lt;/li&gt;
      &lt;li&gt;具体报错可以通过kubectl log metrics-server-5687578d67-tx8m4 -n kube-system命令查看&lt;/li&gt;
      &lt;li&gt;默认镜像拉取的 &lt;code class=&quot;highlighter-rouge&quot;&gt;k8s.gcr.io&lt;/code&gt;仓库, 此处要改为&lt;code class=&quot;highlighter-rouge&quot;&gt;gcr.azk8s.cn/google_containers/&lt;/code&gt; 这个需要注意!!!! 否则无法拉取镜像&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# kubectl top node
NAME         CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
k8s-node01   270m         6%     1483Mi          19%
k8s-node02   220m         5%     1409Mi          18%
k8s-node03   250m         6%     1576Mi          20%
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;部署完成后, 可通过&lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl top node&lt;/code&gt; 或者 &lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl top pods&lt;/code&gt; 查看资源利用信息&lt;/p&gt;

&lt;h3 id=&quot;helm&quot;&gt;helm&lt;/h3&gt;
&lt;p&gt;关于 &lt;code class=&quot;highlighter-rouge&quot;&gt;helm&lt;/code&gt; 的安装配置请查看我之前的文档 &lt;a href=&quot;https://www.jevic.cn/2018/10/13/helm/&quot;&gt;Kubernetes helm 包管理工具&lt;/a&gt;,此处不在叙述.&lt;/p&gt;

&lt;h3 id=&quot;nginx-ingress&quot;&gt;nginx-ingress&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;helm install stable/nginx-ingress --set controller.hostNetwork=true,rbac.create=true --name nginx-ingress --namespace kube-system
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get svc -n kube-system
NAME                            TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE
nginx-ingress-controller        LoadBalancer   10.254.23.90     &amp;lt;pending&amp;gt;     80:34529/TCP,443:32750/TCP   30m
nginx-ingress-default-backend   ClusterIP      10.254.114.103   &amp;lt;none&amp;gt;        80/TCP                       30m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;部署后查看状态,可以看到此处为 &lt;code class=&quot;highlighter-rouge&quot;&gt;LoadBalancer&lt;/code&gt;,需要将类型改为 &lt;code class=&quot;highlighter-rouge&quot;&gt;NodePort&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl edit svc nginx-ingress-controller -n kube-system
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;demo-ingress.yaml&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: nginx-ingress-demo
  namespace: default
spec:
  rules:
  - host: test.nginx.com
    http:
      paths:
      - backend:
          serviceName: nginx-demo
          servicePort: 80
        path: /
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;关于 ingress 的使用 我们后面将使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;Rancher&lt;/code&gt; 进行图形化的管理操作;&lt;/p&gt;

&lt;h3 id=&quot;traefik-ingress&quot;&gt;traefik-ingress&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;关于 &lt;code class=&quot;highlighter-rouge&quot;&gt;traefik&lt;/code&gt; 的部署和应用,请查看之前的教程 &lt;a href=&quot;https://www.jevic.cn/2018/10/25/ingresss-traefik/&quot;&gt;kubernetes nginx-ingress and traefik&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;另外前面部署了 &lt;code class=&quot;highlighter-rouge&quot;&gt;metrics-server&lt;/code&gt;，会导致 443 端口被占用的报错问题, 所以可以在前面部署 &lt;code class=&quot;highlighter-rouge&quot;&gt;metrics-server&lt;/code&gt; 的时候修改下端口;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;rancher-dashboard&quot;&gt;Rancher Dashboard&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;关于导入配置查看之前的文档 &lt;a href=&quot;https://www.jevic.cn/2018/11/25/rancher-dashboard-kubernetes/&quot;&gt;Rancher Dashboard 管理kubernetes集群
&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;运行Rancher 服务端&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker run -d --restart=unless-stopped \
--name rancher \
-p 80:80 -p 443:443 \
-v /var/lib/rancher:/var/lib/rancher/ \
-v /var/log/rancher/auditlog:/var/log/auditlog \
-e AUDIT_LEVEL=3 \
rancher/rancher:stable
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jevic/images/master/kubernetes/rancher-kubernetes.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;转载请注明出处，本文采用 &lt;a href=&quot;http://creativecommons.org/licenses/by-nc-nd/4.0/&quot;&gt;CC4.0&lt;/a&gt; 协议授权&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">2019 都过大半了, 一直比较忙,也有点懒…. 1.13 都出来很久了,还是决定折腾一把!</summary></entry><entry><title type="html">kubernetes RBAC 用户角色访问控制（二）</title><link href="http://0.0.0.0/2019/06/10/kubernetes-rbac/" rel="alternate" type="text/html" title="kubernetes RBAC 用户角色访问控制（二）" /><published>2019-06-10T18:56:06+08:00</published><updated>2019-06-10T18:56:06+08:00</updated><id>http://0.0.0.0/2019/06/10/kubernetes-rbac</id><content type="html" xml:base="http://0.0.0.0/2019/06/10/kubernetes-rbac/">&lt;blockquote&gt;
  &lt;p&gt;RBAC &lt;code class=&quot;highlighter-rouge&quot;&gt;(基于角色的访问控制)&lt;/code&gt;使用 rbac.authorization.k8s.io API 组来实现权限控制，RBAC 允许管理员通过 Kubernetes API 动态的配置权限策略。在 1.8 版本后默认启用,开启 RBAC 授权模式需要在 apiserver 组件中指定 –authorization-mode=RBAC 选项；&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;关于 kubernetes 手动安装移步查看 &lt;a href=&quot;https://www.jevic.cn/2019/08/19/kubernetes-1.13.8/&quot;&gt;kubernetes 1.13.8 二进制手动部署&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;关于 RBAC授权的基础概念参考 &lt;a href=&quot;http://docs.kubernetes.org.cn/148.html&quot;&gt;Kubernetes中使用RBAC授权&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;创建用户&quot;&gt;创建用户&lt;/h2&gt;
&lt;h3 id=&quot;devops&quot;&gt;devops&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#首先先创建一个用于签发证书的 json

{
  &quot;CN&quot;: &quot;devops&quot;,
  &quot;hosts&quot;: [],
  &quot;key&quot;: {
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  },
  &quot;names&quot;: [
    {
      &quot;C&quot;: &quot;CN&quot;,
      &quot;ST&quot;: &quot;Shenzhen&quot;,
      &quot;L&quot;: &quot;Shenzhen&quot;,
      &quot;O&quot;: &quot;k8s&quot;,
      &quot;OU&quot;: &quot;System&quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cfssl gencert --ca=/etc/kubernetes/ssl/k8s-root-ca.pem --ca-key=/etc/kubernetes/ssl/k8s-root-ca-key.pem --config=/etc/kubernetes/json/k8s-gencert.json -profile=kubernetes devops-csr.json | cfssljson -bare devops
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;devopskubeconfig&quot;&gt;devops.kubeconfig&lt;/h3&gt;
&lt;p&gt;创建一个kubeconfig文件，以供kubectl 使用;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#我这里的server 为127.0.0.1,可根据实际IP修改即可

kubectl config set-cluster kubernetes \
--certificate-authority=/etc/kubernetes/ssl/k8s-root-ca.pem \
--embed-certs=true \
--namespace=default \
--server=https://127.0.0.1:6443 \
--kubeconfig=devops.kubeconfig


kubectl config set-credentials devops \
--client-certificate=devops.pem \
--client-key=devops-key.pem \
--embed-certs=true \
--namespace=default \
--kubeconfig=devops.kubeconfig

kubectl config set-context kubernetes \
--cluster=kubernetes \
--user=devops \
--namespace=default \
--kubeconfig=devops.kubeconfig

kubectl config use-context kubernetes \
--namespace=default \
--kubeconfig=devops.kubeconfig
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;clusterrole&quot;&gt;ClusterRole&lt;/h2&gt;
&lt;p&gt;本示例创建的是一个权限针对 pods 只读且范围为Cluster 集群的用户; 所以需要先创建一个只读的ClusterRole&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create clusterrole cluster-devops-reader --verb=get,list,watch --resource=pods,pods/exec,pods/attach,svc --dry-run -o yaml &amp;gt; clusterrole-demo.yaml

## 可根据需要调整资源和权限 

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  creationTimestamp: null
  name: cluster-devops-reader
rules:
- apiGroups:
  - &quot;&quot;
  resources:
  - pods
  - pods/attach
  - pods/exec
  - pods/portforward
  - pods/proxy
  - services
  - services/proxy
  verbs:
  - create
  - get
  - list
  - patch
  - update
  - watch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;clusterrolebinding&quot;&gt;ClusterRoleBinding&lt;/h2&gt;
&lt;p&gt;用户以及集群的权限都已经配置, 下面开始绑定 ClusterRoleBinding&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# kubectl create clusterrolebinding devops-readallpods --clusterrole=cluster-devops-reader --user=devops --dry-run -o yaml
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  creationTimestamp: null
  name: devops-readallpods
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-devops-reader
subjects:
- apiGroup: rbac.authorization.k8s.io
  kind: User
  name: devops
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;保存为 devops-readallpods.yaml 执行 kubectl create -f devops-readallpods.yaml 创建即可&lt;/p&gt;

&lt;h2 id=&quot;测试权限&quot;&gt;测试权限&lt;/h2&gt;
&lt;p&gt;将 &lt;code class=&quot;highlighter-rouge&quot;&gt;devops.kubeconfig&lt;/code&gt; 文件复制到 任何一个节点 ~/.kube/config 或者直接使用 –kubeconfig 选项测试&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@k8s-node02 .kube]# pwd
/root/.kube
[root@k8s-node02 .kube]# ls
cache  config  http-cache
[root@k8s-node02 .kube]# cd
[root@k8s-node02 ~]# kubectl get pods
NAME                                READY   STATUS    RESTARTS   AGE
apple-app                           1/1     Running   3          11d
jevic-app-deploy-65df48dfc6-4nzd8   1/1     Running   3          11d
jevic-app-deploy-65df48dfc6-9d6rw   1/1     Running   0          8d
jevic-app-deploy-65df48dfc6-nptln   1/1     Running   3          10d
myapp                               1/1     Running   3          11d
[root@k8s-node02 ~]# kubectl delete pods/myapp
Error from server (Forbidden): pods &quot;myapp&quot; is forbidden: User &quot;devops&quot; cannot delete resource &quot;pods&quot; in API group &quot;&quot; in the namespace &quot;default&quot;
[root@k8s-node02 ~]#
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;转载请注明出处，本文采用 &lt;a href=&quot;http://creativecommons.org/licenses/by-nc-nd/4.0/&quot;&gt;CC4.0&lt;/a&gt; 协议授权&lt;/p&gt;</content><author><name>Jevic</name></author><summary type="html">RBAC (基于角色的访问控制)使用 rbac.authorization.k8s.io API 组来实现权限控制，RBAC 允许管理员通过 Kubernetes API 动态的配置权限策略。在 1.8 版本后默认启用,开启 RBAC 授权模式需要在 apiserver 组件中指定 –authorization-mode=RBAC 选项；</summary></entry></feed>